'''
MIT License

Copyright (c) 2018 LiamZ96

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
'''
'''Authors: Jacob Wakefield'''


from gevent import monkey
from Server import app
import webbrowser
from gevent.pywsgi import WSGIServer
from gevent.pool import Pool as gPool
PORT = 5000


def main():
    pool = gPool(1000)  # create thread pool with a limit of 1000
    http_server = WSGIServer(('0.0.0.0', PORT), app,
                             spawn=pool)  # create wsgi server

    url = "http://localhost:"+str(PORT)+"/"
    webbrowser.open(url, new=2)  # Opens in new tab if possible
    http_server.serve_forever()


if __name__ == "__main__":
    main()
'''
MIT License

Copyright (c) 2018 LiamZ96

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
'''
# Requirements in this file: 3.1.1, 3.2.3
# Authors: Jacob Wakefield

from . import routes
import os
from flask import Flask, render_template, send_from_directory

app = Flask(__name__, instance_relative_config=True)
app.config.from_mapping(
    SECRET_KEY='dev',
    DATABASE=os.path.join(app.instance_path, 'flaskr.sqlite'),
    TEMPLATES_AUTO_RELOAD=True
)

app.config.from_pyfile('config.py', silent=True)

# ensure the instance folder exists
try:
    os.makedirs(app.instance_path)
except OSError:
    pass

# import routes after the app is created
'''
MIT License

Copyright (c) 2018 LiamZ96

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
'''
# Requirements in this file: 3.1.2, 3.1.4, 3.1.5, 3.1.11, 3.2.7, 3.3.2
# Authors: Jacob Wakefield, Noah Zeilmann, McKenna Gates, Liam Zay

from . import app
from flask import render_template, send_from_directory, request, url_for, redirect, jsonify
from werkzeug.utils import secure_filename
from lib.counting import *
from lib.stitching import *
import os
import datetime
import json
from PIL import Image

ALLOWED_IMAGE_EXTENSIONS = set(['jpg', 'jpeg'])
ALLOWED_VIDEO_EXTENSIONS = set(['mp4', 'avi'])

"""
    Description: a function used to see if the uploaded file is in a valid format.
    @Param filename - name of the file being uploaded.
    @Param extensionList - set of allowed file extensions.
    @return a boolean indicating whether the image is in an acceptable format or not.
"""


def isFileAllowed(filename, extensionList):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in extensionList


def setupUploadDir():
    # create new folder to hold users data for run
    uploadDir = 'Server/resources/uploads'
    now = datetime.datetime.now()
    newFolder = now.strftime("%Y-%m-%dT%H-%M-%S")
    newDir = uploadDir + "/" + newFolder
    os.mkdir(newDir)
    subfolders = ['images', 'videos', 'maps', 'results']
    for folder in subfolders:
        subDir = newDir + "/" + folder
        os.mkdir(subDir)
    return newDir

# route for serving static resources (images/js/css)
@app.route('/resources/<path:path>')
def sendJs(path):
    return send_from_directory('resources', path)


@app.route('/')
@app.route('/index')
def index():
    return render_template('index.html')


@app.route('/error')
def error():
    errorMessage = request.args['errorMessage']
    return render_template('error.html', error=errorMessage)


@app.route('/uploadImages', methods=["POST"])
def uploadImages():
    images = request.files.getlist("images")

    newDir = setupUploadDir()

    for i in images:
        # redirect to error page if the image is in an unacceptable
        if(isFileAllowed(i.filename, ALLOWED_IMAGE_EXTENSIONS) == False):
            return jsonify({"status": 1, "msg": "One or more of the images that were uploaded are in the incorrect format. Accepted formats: "+(", ".join(ALLOWED_IMAGE_EXTENSIONS))})

        print("Image is permitted: "+str(isFileAllowed(i.filename,
                                                       ALLOWED_IMAGE_EXTENSIONS)))  # see if the image format is allowed
        # escape the filename
        print("Secure filename: "+str(secure_filename(i.filename)))

        imgPath = newDir + "/images/" + str(secure_filename(i.filename))
        i.save(imgPath)

    # redirect to homepage
    return jsonify({"status": 0, "msg": "Success", "location": newDir.replace("Server/resources/uploads", "")})


@app.route('/uploadVideo', methods=["POST"])
def uploadVideo():
    video = request.files['video']

    newDir = setupUploadDir()

    # redirect to the error page if the video is not the correct format
    if(isFileAllowed(video.filename, ALLOWED_VIDEO_EXTENSIONS) == False):
        return jsonify({"status": 1, "msg": "The uploaded video is in the incorrect format. Accepted formats: "+(", ".join(ALLOWED_VIDEO_EXTENSIONS))})

    print("Video is permitted: "+str(isFileAllowed(video.filename,
                                                   ALLOWED_VIDEO_EXTENSIONS)))  # see if the image format is allowed
    # escape the filename
    print("Secure filename: "+str(secure_filename(video.filename)))

    # place video in a unique directory
    vidPath = newDir + "/videos/" + str(secure_filename(video.filename))
    video.save(vidPath)
    return jsonify({"status": 0, "msg": "Success"})  # redirect to homepage


# accepts a path to the image directory to use for stitching
@app.route('/getStitchedImage/<path:directory>')
def getStitchedImage(directory):
    dirPrefix = "Server/resources/uploads/"
    stitcher = Stitching()

    stitcher.twoRoundStitch(dirPrefix + directory +
                            "/images/", dirPrefix + directory + "/maps/")
    return render_template('stitched.html', direct=directory)

# accepts a path to the stitched image directory
@app.route('/getResults/<path:directory>')
def getResults(directory):
    magLevel = request.args.get('magLevel')
    if(magLevel == "4x"):
        magLevel = HoughConfig.OBJX4
    else:
        magLevel = HoughConfig.OBJX10
    resultsDirectory = directory.split("/")[0]
    serverDirectory = 'Server/resources/uploads/' + directory
    count = Counting(serverDirectory)
    circles = count.getColorBeads(magLevel)
    count.makeBeadsCSV()
    return render_template('results.html', colorBeads=circles, waterBeads=count.waterBeads, mapLocation=directory, resultsDirectory=resultsDirectory)
'''
MIT License

Copyright (c) 2018 LiamZ96

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
'''
# Requirements in this file: 3.1.7, 3.1.8, 3.1.9, 3.1.10, 3.2.4, 3.2.5, 3.3.1
# Authors: Jacob Wakefield, McKenna Gates

import cv2
import numpy as np
from matplotlib import pyplot as plt
import random
import math
import itertools
import csv
from enum import Enum
from os import listdir, path

"""
    Description: an enum class to handle the HoughCircle configuration values that are used in cv2.HoughCircles().
"""


class HoughConfig(Enum):

    # 4x magnification
    OBJX4 = {"dp": 1, "minDist": 40, "param1": 50,
             "param2": 55, "minRadius": 0, "maxRadius": 75}

    # 10x magnification
    OBJX10 = {"dp": 1, "minDist": 60, "param1": 65,
              "param2": 68, "minRadius": 0, "maxRadius": 125}


"""
    Description: a class to deal with counting microbeads in a stitched image.
"""


class Counting:

    def __init__(self, imagePath):
        self.imagePath = imagePath
        self.grayScaleMap = cv2.imread(
            imagePath, 0)  # create grayscale cv2 img
        self.colorMap = cv2.imread(imagePath)  # create color cv2 img
        self.colorBeads = []
        self.waterBeads = []

    """
        Description: a function that takes a map of images and counts the beads.
        @Param houghConfig - a HoughConfig object that contains the values for the HoughCircles() function
        @return an object containing information collected during the counting process.
    """

    def getColorBeads(self, houghConfig):
        houghConfig = houghConfig.value
        result = []

        img = self.grayScaleMap
        cimg = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
        blur = cv2.GaussianBlur(img, (5, 5), 0)
        circles = cv2.HoughCircles(blur, cv2.HOUGH_GRADIENT, dp=houghConfig["dp"], minDist=houghConfig["minDist"],
                                   param1=houghConfig["param1"], param2=houghConfig["param2"], minRadius=houghConfig["minRadius"], maxRadius=houghConfig["maxRadius"])

        circles = np.uint16(np.around(circles))
        for i in circles[0, :]:
            # i[0] is x coordinate, i[1] is y coordinate, i[2] is radius
            # draw the outer circle
            cv2.circle(cimg, (i[0], i[1]), i[2], (0, 255, 0), 2)
            # draw the center of the circle
            cv2.circle(cimg, (i[0], i[1]), 2, (0, 0, 255), 3)

            color = self.getBrightestColor(i)
            # if the bead is a water bead, leave it out.
            if(color[1] == False):
                self.colorBeads.append(color)
                result.append(color)
            else:
                self.waterBeads.append(color)
        imagePath = '/'.join(self.imagePath.split('/')[:-2]) + '/results/'
        imagePath += 'result_image.jpg'  # + str(fileNum) +'.jpg'
        cv2.imwrite(imagePath, cimg)

        return result

    """
        Description: a function that takes a cicle's RGB values and returns if it is water or not
        @param RGB - tuple containing the average red, green, and blue values of a circle
        @return a boolean that will be True if the circle is water
    """

    def isWater(self, RGB):
        red = RGB[0]
        green = RGB[1]
        blue = RGB[2]
        isWater = False

        maxRGBValue = 230
        minRGBValue = 3

        if red >= maxRGBValue and green >= maxRGBValue and blue >= maxRGBValue:
            isWater = True
        if red <= minRGBValue and green <= minRGBValue and blue <= minRGBValue:
            isWater = True
        return isWater

    """
        Description: a function that takes an array representing a circle's[x-coord of center, y-coord of center, radius]
                    and returns a list containing tuple with the bead's average RGB values of the top 10% and boolean isWater
        @param circleInfo - array that contains a circle's x and y coordinates of the center and the radius of the circle
        @param imageMap - a map (image) of the microscope images in color.
        @return a list containing tuple with average RGB values of top 10% from bead, boolean isWater, and x,y,radius value of the bead.
    """

    def getBrightestColor(self, circleInfo):
        img = self.colorMap
        imgY = img.shape[0]
        imgX = img.shape[1]
        x = circleInfo[0]
        y = circleInfo[1]
        radius = circleInfo[2]
        reds, greens, blues = [], [], []

        points = self.getPointsInCircle(radius, x, y)
        colorsList = []
        coordinates = list(points)

        for xCoord, yCoord in coordinates:
            if (xCoord >= imgX) or (yCoord >= imgY):
                pass
            else:
                bgrValue = img[yCoord, xCoord]
                RGB = (bgrValue[2], bgrValue[1], bgrValue[0])
                colorsList.append(RGB)

        sortedByRed = sorted(colorsList, key=lambda tup: tup[0], reverse=True)
        sortedByGreen = sorted(
            colorsList, key=lambda tup: tup[1], reverse=True)
        sortedByBlue = sorted(colorsList, key=lambda tup: tup[2], reverse=True)

        # may need to be adjusted
        tenPercent = math.floor(0.10 * len(colorsList))

        for i in range(0, tenPercent):
            reds.append(sortedByRed[i][0])
            greens.append(sortedByGreen[i][1])
            blues.append(sortedByBlue[i][2])

        average = (round(np.mean(reds), 2), round(
            np.mean(greens), 2), round(np.mean(blues), 2))
        isWater = self.isWater(average)
        # [[R,G,B], isWater, [x,y,radius]]
        return [[average[0], average[1], average[2]], isWater, [circleInfo[0], circleInfo[1], circleInfo[2]]]

    """
        Description: a function that takes a bead's radius and x and y coordinates of the center and returns coordinates of every point in
                    the bead
        @param radius - radius of bead
        @param centerX - X coordinate of the center of bead
        @param centerY - Y coordinate of the center of bead
        @return a zip of the coordinates within a circle
    """

    def getPointsInCircle(self, radius, centerX, centerY):
        a = np.arange(radius + 1)
        for x, y in zip(*np.where(a[:, np.newaxis]**2 + a**2 <= radius**2)):
            # x and y given here were assuming that the center was at 0,0 therefore you must add the actual center coordinates to give accurate ones back
            yield from set(((centerX + x, centerY + y), (centerX + x, centerY - y), (centerX - x, centerY + y), (centerX - x, centerY - y),))

    """
        Description: 
        @param 
        @param
        @param 
        @return 
    """

    def makeBeadsCSV(self):
        newPath = self.imagePath
        endIndex = newPath.rfind("/")
        newPath = newPath[:endIndex]
        newPath = newPath.replace("maps", "results")
        newPath = newPath + "/beads.csv"
        with open(newPath, mode='w', newline='') as beadFile:
            writer = csv.writer(beadFile, delimiter=',',
                                quotechar='"', quoting=csv.QUOTE_MINIMAL)
            colNames = ['Bead Number', 'Red Val', 'Green Val',
                        'Blue Val', 'X-Coord', 'Y-Coord', 'Radius']
            writer.writerow(colNames)
            i = 1
            for bead in self.colorBeads:
                r = bead[0][0]
                g = bead[0][1]
                b = bead[0][2]
                x = bead[2][0]
                y = bead[2][1]
                radius = bead[2][2]
                beadNum = i
                writer.writerow([beadNum, r, g, b, x, y, radius])
                i += 1
'''
MIT License

Copyright (c) 2018 LiamZ96

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
'''
# Requirements in this file: 3.1.6, 3.2.4, 3.2.6
# Authors: Noah Zeilmann, Josiah Carpenter

import cv2
import os
from matplotlib import pyplot as plt
import time
import sys
from PIL import Image, ExifTags
import shutil
import multiprocessing as mp
from collections import OrderedDict

"""
        Description: a class to deal with stitching images together and handling overlap of the images.
"""


class Stitching:
    def __init__(self):
        self.images = []
        self.sourceDirectory = ""
        self.resultsDirectory = ""
        self.results = []

    """
		Description: a function for creating a stitched image from ordered images.
		@return A stitched image.
	"""

    def stitchOrderedImages(self):
        # Create stitcher and stitch images
        stitcher = cv2.createStitcher(True)
        status, image = stitcher.stitch(self.images)

        if status == cv2.STITCHER_OK:
            # Get results directory
            imagePath = os.path.join(resultsDir, "stiched_image.jpg")

            # Check if results directory exist, if not create it
            if not os.path.exists(resultsDir):
                os.makedirs(resultsDir)

            # Save image in results directory
            cv2.imwrite(imagePath, image)

            return image
        else:
            print('Error during stiching')
            return False

    """
		Description: a function for creating a stitched image from unordered images.
		@return A stitched image.
	"""

    def collage(self, temp_path, file_name):
        images = []
        for file in os.listdir(temp_path):
            if(file.find('jpg') != -1 or file.find('JPG') != -1):
                images.append(Image.open(str(temp_path) + "/" + str(file)))
        widths, heights = zip(*(i.size for i in images))
        total_width = sum(widths)
        max_height = max(heights)

        new_im = Image.new('RGB', (total_width, max_height))

        x_offset = 0
        for im in images:
            new_im.paste(im, (x_offset, 0))
            x_offset += im.size[0]

        new_im.save(self.resultsDirectory + file_name)
        shutil.rmtree(temp_path)

    def twoRoundStitch(self, sourceDirectory, resultsDirectory):
        output = mp.Queue()
        # first we run the two rounds with WTA_K set to 4
        self.resultsDirectory = resultsDirectory
        self.setDirectory(sourceDirectory)

        pl = mp.Pool(processes=2)
        i1 = self.images
        i2 = self.images
        first_round = pl.starmap(self.stitchUnorderedImages, [
                                 (4, 1000, 0, i1), (2, 1000, 0, i2)])
        print(len(first_round[0]))
        final_images = pl.starmap(self.stitchUnorderedImages, [(
            4, 200, 200, first_round[0]), (2, 200, 200, first_round[1])])

        temp_dir = str(int(round(time.time())))
        temp_dir = temp_dir + "/"
        os.makedirs(temp_dir)

        img_number = 0
        for img in final_images[0]:
            cv2.imwrite(str(temp_dir) + str(img_number) + ".jpg", img)
            img_number += 1
        self.collage(temp_dir, "resultA.jpg")

        # now we run two round again but with WTA_K set to 2

        temp_dir = str(int(round(time.time())))
        temp_dir = temp_dir + "/"
        os.makedirs(temp_dir)

        img_number = 0
        for img in final_images[1]:
            cv2.imwrite(str(temp_dir) + str(img_number) + ".jpg", img)
            img_number += 1
        self.collage(temp_dir, "resultB.jpg")

    def stitchUnorderedImages(self, wtak, pSize, eThresh, images):
        orb = cv2.ORB_create(WTA_K=wtak, scaleFactor=1.1,
                             patchSize=pSize, edgeThreshold=eThresh)
        if(wtak == 4):
            bf = cv2.BFMatcher(cv2.NORM_HAMMING2, crossCheck=True)
        else:
            bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
        kpMap = OrderedDict()
        matchLevel = 0
        matchThreshold = 15
        parentKey = None
        completed_images = []

        # Iterate through images and detect keypoints for each image and store in dictonary
        for idx, img in enumerate(images):
            kp, desc = orb.detectAndCompute(img, None)
            if(len(kp) > 0):
                kpMap["image" + str(idx)] = (kp, desc, img)
            else:
                imagePath = os.path.join(
                    self.resultsDirectory, "stiched_"+str(idx) + ".jpg")
                completed_images.append(img)

        print("Initial count", len(kpMap))
        while (len(kpMap) > 1):
            # Get first kpMap key
            if(parentKey == None):
                parentKey = next(iter(kpMap))
            parentValue = kpMap[parentKey]
            allMatches = OrderedDict()
            if(matchLevel > len(kpMap)):
                matchThreshold += 10
            # Second Iteration to find all the matching keypoints for parentKeypoints
            test = kpMap.items()
            for childKey, childValue in kpMap.items():
                # Add all the matching keypoint a list
                if (parentKey != childKey):
                    good = []
                    matches = bf.match(parentValue[1], childValue[1])

                    # Get only good matches
                    for m in matches:
                        if m.distance < matchThreshold:
                            good.append(m)
                    allMatches[childKey] = good

            # Find value with best match
            bestKeyPoints = (None, [])
            for matchKey, matchValue in allMatches.items():
                if (len(bestKeyPoints[1]) < len(matchValue)):
                    bestKeyPoints = (matchKey, matchValue)

            if (len(bestKeyPoints[1]) == 0):
                matchLevel += 1
                matchThreshold += 10
                continue

            bestMatch = kpMap[bestKeyPoints[0]]

            # Sort them in the order of their distance.
            matches = sorted(bestKeyPoints[1], key=lambda x: x.distance)
            # Stitch best matching image with parentImage
            stitchedImg = self.__stitchImages(
                parentValue, bestMatch, matches, wtak, pSize, eThresh)
            if (len(stitchedImg) == 3):
                kpMap[parentKey] = stitchedImg
                matchLevel = 0
                matchThreshold = 0
                del kpMap[bestKeyPoints[0]]
            else:
                matchLevel += 1
            if(matchLevel > (len(kpMap) + 25)):
                matchLevel = 0
                matchThreshold = 15
                imagePath = os.path.join(
                    self.resultsDirectory, "stiched_"+str(parentKey) + ".jpg")
                completed_images.append(kpMap[parentKey][2])
                del kpMap[parentKey]
                parentKey = None

        # Check if results directory exist, if not create it

        return completed_images

    """
		Description: a function setting the directory for looking for images, this will only be used by a 
			commandline interface
		@param path - The directory in unix format
	"""

    def setDirectory(self, path):
        # Get directory of test images
        self.sourceDirectory = os.path.abspath(
            os.path.join(os.path.dirname(__file__), "..", path))

        # Read images and append to image array
        current_images = {}
        for file in os.listdir(self.sourceDirectory):
            if(file.find('jpg') != -1 or file.find('JPG') != -1):
                path = os.path.join(self.sourceDirectory, file)
                img = Image.open(path)
                exif = {ExifTags.TAGS[k]: v for k, v in img._getexif(
                ).items() if k in ExifTags.TAGS}
                current_images[path] = exif['DateTimeOriginal']
        sorted_by_value = sorted(current_images.items(), key=lambda kv: kv[1])
        for key in sorted_by_value:
            self.images.append(cv2.imread(key[0], cv2.IMREAD_COLOR))

    def setResultsDirectory(self, path):
        self.resultsDirectory = path

    def __stitchImages(self, firstImage, secondImage, matches, wtak, pSize, eThresh):
        # Create stitcher and stitch images
        stitcher = cv2.createStitcher(True)
        orb = cv2.ORB_create(WTA_K=wtak, scaleFactor=1.1,
                             patchSize=pSize, edgeThreshold=eThresh)
        if(wtak == 4):
            bf = cv2.BFMatcher(cv2.NORM_HAMMING2, crossCheck=True)
        else:
            bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
        try:
            status, image = stitcher.stitch([firstImage[2], secondImage[2]])
        except:
            return(firstImage, secondImage)
        kp, desc = orb.detectAndCompute(image, None)

        # print(status)

        if (status == 0):
            # Draw first 10 matches.
            img3 = cv2.drawMatches(
                firstImage[2], firstImage[0], secondImage[2], secondImage[0], matches[:10], None, flags=2)
            return (kp, desc, image)
        else:
            return (firstImage, secondImage)
"""
AEDS User Interface: This software allows the user to interact with the Audio Emotion Detection (AEDS)
	software through a GUI.
	This interface contains two text fields and two buttons.
	For information on how to properly use this  interface, please see the README file included with
	this document.
Authors: Base code written by Michael Knapp. Edits made by Humberto Colin, Bryan Jones, Timmothy Lane, Alex Shannon,
	and Mark Webb.
Related Software Requirements: FR.7, FR.8, FR.10, FR.11, EIR.1, EIR.2, EIR.3, EIR.4, EIR.5
"""


from tkinter import *
import tkinter as tk
import pyaudio
import Recording
import emotionProcessor
from tkinter import Menu
from tkinter import messagebox as mbox
import scikit_network
from statistics import stdev
import numpy as np
from profileManager import *
from os import *

# Hardcoded Variables
CHUNK = 1024
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 44100
wave_output_filename = "user_recording.wav"


# Code to create the window for the GUI.
# this class sets up the frame which is the entire window needed to fit the GUI buttons and lable's inside.

class Application(Frame):
    def __init__(self, master):
        Frame.__init__(self, master)
        self.grid(column=1, row=5)

        self.create_widgets()
        self.recorder = Recording.Recording(
            wave_output_filename, CHANNELS, RATE, CHUNK)
        self.processor = emotionProcessor.EmotionProcessor(
            wave_output_filename)
        self.recordingtest = False

   # class widgets.. this is where the code for each off six buttons two lable's and two text boxes are held.
   # Grid not pack is used.
   # grid= where is that button on label located in the frame.
   # each button has a command atribute that connects the button with a function that controls what the button does.

    def create_widgets(self):

        # Start button, which begins the recording process.
        # Related Software Requirements: EIR.1, EIR.2
        self.startButton = Button(self, text=" Start: recording          ",
                                  justify="center", command=self.recordAudio, bg="lightgray")
        self.startButton.grid(row=0, column=0)

        # Stop button, which ends the recording process and begins the process of metric extraction/comparison.
        # Related Software Requirements: EIR.4
        self.stopButton = Button(self, text=" Stop: recording          ",
                                 justify="center", command=self.endAudio, bg="lightgray")
        self.stopButton.grid(row=1, column=0)

        # Label for the output below "user Id or name".
        # Related Software Requirements: FR.7, FR.8
        self.label = Label(
            self, text="User Name:               ", font=13, justify="left")
        self.label.grid(column=1, row=0)

        # output for the User id
        self.user = StringVar()
        self.txt = Entry(self, textvariable=self.user, width=32)
        self.txt.grid(column=1, row=1)

        # Label for the GUI that Says " predicted emotion".
        self.label = Label(self, text="Predicted Emotion:    ",
                           font=13, justify="left")
        self.label.grid(column=1, row=2)

        # Output field for the label where the predicted emotion will be added when the kNN processed the audio matrics hopefully correctly.
        # Related Softare Requirements: FR.10, EIR.5
        self.emotionalPrediction = StringVar()
        self.text = Entry(
            self, textvariable=self.emotionalPrediction, width=32)
        self.text.grid(column=1, row=3)

        # this function was written by Alex

    def recordAudio(self):
        if(self.recordingtest == True):
            print("Already Recording!")
        else:
            self.recorder = Recording.Recording(
                wave_output_filename, CHANNELS, RATE, CHUNK)
            self.recorder.startAudio()
            self.emotionalPrediction.set("Recording..")
            self.recordingtest = True
        return self
    # End audio also needs a popup button.

    def endAudio(self):
        if(self.recordingtest == True):
            # Stop recording audio
            self.recorder.stopAudio()

            # Set the box containing the emotional prediction to be blank
            self.emotionalPrediction.set("Done Recording.")

            # Get the entered user name from the entry box
            self.userName = self.user.get()

            # Call the method to get the audio metrics
            self.audio_metrics = self.processor.collectMetrics()

            # Create a user profile object using the entered user name
            self.user_profile = profileManager(self.userName)

            # Access the profile for the given user
            self.user_profile.accessProfile()

            # Get the prediction from the scikit network
            self.predicted = scikit_network.compare_new(
                self.audio_metrics, self.user_profile)
            self.emotionalPrediction.set(self.predicted[0])

            # Delete the recorded audio file
            os.remove("user_recording.wav")

            # yes no box asking if returned emotion was correct
            question = ("Was predicted emotion " +
                        self.predicted[0] + " correct?")
            if mbox.askyesno("Emotion Prediction Assessment", question):
                self.user_profile.addtoProfile(
                    self.audio_metrics, self.predicted[0])
                self.recordingtest = False
            else:
                newtab = Tk()
                newtab.title("Wrong Emotion Correction")
                newtab.geometry("300x158")

                self.correction = StringVar(newtab)
                self.correction.set("Normal")

                emotions = OptionMenu(
                    newtab, self.correction, "Normal", "Excited", "Angry", "Nervous")
                emotions.grid(row=0, column=0)

                submitButton = Button(newtab, text="Submit Emotion", justify="center", command=lambda: [
                                      self.submit(), newtab.destroy()], bg="lightgray")
                submitButton.grid(row=1, column=0)

                newtab.mainloop()
        else:
            mbox.showerror("Incorrect button press!",
                           "You must be recording to stop. Please start/restart recording.")
        return self

    def submit(self):
        self.predicted = self.correction.get()
        self.user_profile.addtoProfile(self.audio_metrics, self.predicted)
        self.recordingtest = False


# Modify root window.
root = Tk()
root.title("Audio Control Interface")

# The size of the whole frame.

root.geometry("300x158")

# Background for the whole GUI

app = Application(root)

# kick off the event loop
root.mainloop()
import pyaudio
import wave
'''
The recording class was originally written by Humberto and heavily edited by Alex to allow for variable recording time, easily processed formatting,
and stopping the recording on demand.
Related Software Requirements: FR.1, HI.1, CI.1
'''
wave_output_filename = "user_recording.wav"


class Recording(object):
    def __init__(self, fname, channels, rate, CHUNK):
        self.fname = fname
        self.channels = channels
        self.rate = rate
        self.CHUNK = CHUNK
        self._p = pyaudio.PyAudio()
        self.wavefile = self._prep_file(self.fname)
        self._stream = None

    def __enter__(self):
        return self

    def __exit__(self, exception, value, traceback):
        self.close()

    def startAudio(self):
        self._stream = self._p.open(format=pyaudio.paInt16, channels=self.channels, rate=self.rate,
                                    input=True, frames_per_buffer=self.CHUNK, stream_callback=self.get_callback())
        print("recording...")

        self._stream.start_stream()
        return self

    def stopAudio(self):
        self._stream.stop_stream()
        print("done recording")
        self.close()
        return self

    def get_callback(self):
        def callback(in_data, frame_count, time_info, status):
            self.wavefile.writeframes(in_data)
            return in_data, pyaudio.paContinue
        return callback

    def close(self):
        self._stream.close()
        self._p.terminate()
        self.wavefile.close()

    def _prep_file(self, fname):
        waveFile = wave.open(self.fname, 'wb')
        waveFile.setnchannels(self.channels)
        waveFile.setsampwidth(self._p.get_sample_size(pyaudio.paInt16))
        waveFile.setframerate(self.rate)
        return waveFile
# emotionProcessor-threaded.py
# This is a variation of the emotionProcessor class.
# The main difference between the two classes is that this
# class utilizes python's threading module to collect the
# audio metrics.
# Since this proved to offer little to no performance gains
# while still expending extra resources, this class was not
# utilized in the final build of the software. This class
# may, however, prove to be useful to future researchers
# looking to improve the performance of the AEDS softare.
# This class is included purely for educational purposes.
# All alterations made to this class from emotionProcessor.py
# were made by Timmothy Lane.

from pyAudioAnalysis import audioBasicIO
from pyAudioAnalysis import audioFeatureExtraction
from scipy.io import wavfile
from scipy.fftpack import fft
import wave
import numpy
import math
from python_speech_features import mfcc
from python_speech_features import delta
from python_speech_features import logfbank
import scipy.io.wavfile as wav
from pydub import AudioSegment
from pydub.silence import split_on_silence
from statistics import *
import numpy as np
import multiprocessing
from multiprocessing import *
import threading


class EmotionProcessor(object):
    def __init__(self, fname):
        self.fname = fname

    def __enter__(self):
        return self

    def __exit__(self, exception, value, traceback):
        self.close()

# mfccProc: extracts the MFCCs from given audio
# Written by Timmothy Lane
# Creates 2d arrays for storage of the fbank feature, mfcc features
#   and the delta of MFCC features
# Written By: Timmothy Lane
    def mfccProc(self):
        (rate, sig) = audioBasicIO.readAudioFile(self.fname)
        # Create 2d array for MFCC features
        mfcc_feat = mfcc(sig, samplerate=44100, nfft=1103)
        # Create 2d array for the delta of MFCC features
        d_mfcc_feat = delta(mfcc_feat, 2)
        # Create 2d array for the log of fbank features
        fbank_feat = logfbank(sig, rate)
        return(mfcc_feat)

    def mfccProc2(self, results_dict):
        (rate, sig) = audioBasicIO.readAudioFile(self.fname)
        # Create 2d array for MFCC features
        mfcc_feat = mfcc(sig, samplerate=44100, nfft=1103)
        # Create 2d array for the delta of MFCC features
        d_mfcc_feat = delta(mfcc_feat, 2)
        # Create 2d array for the log of fbank features
        fbank_feat = logfbank(sig, rate)
        dev_array = []
        for i in mfcc_feat:
            temp = stdev(i)
            dev_array.append(temp)
        tone = stdev(dev_array)
        results_dict["tone"] = tone
        return(mfcc_feat)

    def pitchProc(self):
        [Fs, x] = audioBasicIO.readAudioFile(self.fname)
        info = audioFeatureExtraction.stFeatureExtraction(
            x, Fs, 0.050*Fs, 0.025*Fs)
        return info[0][1]

    def pitchProc2(self, results_dict):
        print("pitchProc2")
        [Fs, x] = audioBasicIO.readAudioFile(self.fname)
        info = audioFeatureExtraction.stFeatureExtraction(
            x, Fs, 0.050*Fs, 0.025*Fs)
        results_dict["pitch"] = info[0][1]
        return info[0][1]

    def volumeProc(self):
        freq, snd = wavfile.read(self.fname)
        snd = snd/(2.**15)
        s1 = snd[:]
        n = len(s1)
        p = fft(s1)  # take the fourier transform
        unique = int(math.ceil((n+1)/2.0))
        p = p[0:unique]
        p = abs(p)
        p = p/float(n)
        p = p**2
        if n % 2 > 0:
            p[1:len(p)] = p[1:len(p)]*2
        else:
            p[1:len(p)-1] = p[1:len(p)-1]*2
        freqArray = numpy.arange(0, unique, 1.0)*(freq/n)
        #numpy.set_printoptions(threshold = numpy.nan)
        #rms_val = sqrt(mean(s1**2))
        return(freqArray)

    def volumeProc2(self, results_dict):
        freq, snd = wavfile.read(self.fname)
        snd = snd/(2.**15)
        s1 = snd[:]
        n = len(s1)
        p = fft(s1)  # take the fourier transform
        unique = int(math.ceil((n+1)/2.0))
        p = p[0:unique]
        p = abs(p)
        p = p/float(n)
        p = p**2
        if n % 2 > 0:
            p[1:len(p)] = p[1:len(p)]*2
        else:
            p[1:len(p)-1] = p[1:len(p)-1]*2
        freqArray = numpy.arange(0, unique, 1.0)*(freq/n)
        #numpy.set_printoptions(threshold = numpy.nan)
        #rms_val = sqrt(mean(s1**2))
        results_dict["volume"] = freqArray
        return(freqArray)


# gapProc: function that allows the extraction of the gaps between
# consecutive words.
## Inputs: self
# Output: an array containing the lengths of every gap between words
# Written By: Michael Knapp and Timmothy Lane


    def gapProc(self):
        # def gapProc(self , lowest):
        sound_file = AudioSegment.from_wav(self.fname)
        audio_chunks = split_on_silence(sound_file,
                                        # must be silent for at least 100ms
                                        min_silence_len=1,
                                        # consider it silent if quieter than -16 dBFS
                                        silence_thresh=5)

        # List made to store all of the silence .wav chunks
        waveAry = []
        # List made to store the lengths of the silence chunks
        chunkLengthArray = []

        for i, chunk in enumerate(audio_chunks):
            out_file = ".//splitAudio//chunk{0}.wav".format(i)
            # waveAry.append(chunk)
            chunkLengthArray.append(len(chunk))

        # If there were no silences, set the mean variable to 0
        if len(chunkLengthArray) == 0:
            avgChunkLength = 0
            stdevChunkLength = 0
        # If thee is exactly 1 silence, set the stdev to 0
        #   and the average chunk length to the value of the only silence
        elif len(chunkLengthArray) == 1:
            stdevChunkLength = 0
            avgChunkLength = chunkLengthArray[0]
        # Otherwise calculate the mean gap and stdev of the gaps and store
        #   them in variables
        else:
            avgChunkLength = mean(chunkLengthArray)
            stdevChunkLength = stdev(chunkLengthArray)
        # Return the array containing the lengths of the gaps
        return(chunkLengthArray)

# gapProc: function that allows the extraction of the gaps between
# consecutive words.
## Inputs: self
# Output: an array containing the lengths of every gap between words
# Written By: Michael Knapp and Timmothy Lane
    def gapProc2(self, results_dict):
        # def gapProc(self , lowest):
        sound_file = AudioSegment.from_wav(self.fname)
        audio_chunks = split_on_silence(sound_file,
                                        # must be silent for at least 100ms
                                        min_silence_len=1,
                                        # consider it silent if quieter than -16 dBFS
                                        silence_thresh=5)

        # List made to store all of the silence .wav chunks
        waveAry = []
        # List made to store the lengths of the silence chunks
        chunkLengthArray = []

        for i, chunk in enumerate(audio_chunks):
            out_file = ".//splitAudio//chunk{0}.wav".format(i)
            # waveAry.append(chunk)
            chunkLengthArray.append(len(chunk))

        # If there were no silences, set the mean variable to 0
        if len(chunkLengthArray) == 0:
            avgChunkLength = 0
            stdevChunkLength = 0
        # If thee is exactly 1 silence, set the stdev to 0
        #   and the average chunk length to the value of the only silence
        elif len(chunkLengthArray) == 1:
            stdevChunkLength = 0
            avgChunkLength = chunkLengthArray[0]
        # Otherwise calculate the mean gap and stdev of the gaps and store
        #   them in variables
        else:
            avgChunkLength = mean(chunkLengthArray)
            stdevChunkLength = stdev(chunkLengthArray)
        # Return the array containing the lengths of the gaps
        results_dict["wordGap"] = chunkLengthArray
        return(chunkLengthArray)


# collectMetrics:
# Collects the audio metrics using the above methods,
# places them into a pandas array, and returns them
# for use by the software
# Written by: Bryan Jones

    def collectMetrics(self):
        print("Collecting Metrics")
        queue = Queue()
        results_dict = {"pitch": [], "volume": [],
                        "tone": [], "wordGap": [], "wordGaplen": []}
        process_list = []

        print("Creating process")
        p1 = threading.Thread(target=self.pitchProc2, args=(results_dict,))
        process_list.append(p1)
        p2 = threading.Thread(target=self.volumeProc2, args=(results_dict,))
        process_list.append(p2)
        p3 = threading.Thread(target=self.mfccProc2, args=(results_dict,))
        process_list.append(p3)
        p4 = threading.Thread(target=self.gapProc2, args=(results_dict,))
        process_list.append(p4)


#        p5 = Process()
        print("Starting process")
        for process in process_list:
            process.start()
        # p1.start()

        print("Ending Processes")
        for proc in process_list:
            proc.join()

        #pitch = self.pitchProc()
        pitch = results_dict["pitch"]
        pitch = stdev(pitch)

        #volume = self.volumeProc()
        volume = results_dict["volume"]
        volume = stdev(volume)

        '''tone = self.mfccProc()
        dev_array = []
        for i in tone:
            temp = stdev(i)
            dev_array.append(temp)
        tone = stdev(dev_array)'''

        tone = results_dict["tone"]

        #wordGap = self.gapProc()
        wordGap = results_dict["wordGap"]
        if(len(wordGap) != 0):
            wordGaplen = len(wordGap)
            wordGap = stdev(wordGap)
        else:
            wordGaplen = 0
            wordGap = 0

        user_profile = np.array([pitch, tone, volume, wordGap, wordGaplen])
        return(user_profile)
# scikit_network.py:
# Allows the AEDS software to make predictions about the user's
# emotional state by comparing new vocal metrics against previously
# stored metrics using the k-nearest neighbor algorithm.
# Related Software Requirements: FR.8, FR.9
# Authors: Bryan Jones and Mark Webb
import numpy as np
import pandas as pd
from sklearn.neighbors import KNeighborsClassifier
from profileManager import *


# compare_new(): Compares data pertaining to the new recording and compares
# it against the data retrieved from the user profile using the k-nearest
# neighbor algorithm to find the closest match for the new data.
# Inputs: Data conveying the vocal metrics from the recent audio recording,
# and the user profile.
# Outputs: The predicted emotional state of the user.
# Authors: Bryan Jones and Mark Webb
# Related Software Requirements: FR.8, FR.9
def compare_new(new_metrics, user_profile):
    # Changed the emotion data to use user profile data
    # Tim - 11/24
    emotion_data = user_profile.path
    df = pd.read_csv(emotion_data, header=None, sep=',', names=[
                     'Pitch', 'Tone', 'SPL', 'wordGap', 'WordGapLen', 'Emotion'])

    data = df.values
    y = df['Emotion']
    X = df[['Pitch', 'Tone', 'SPL', 'wordGap', 'WordGapLen']]

    # uses k nearest neighbor to find closest example
    knn = KNeighborsClassifier(n_neighbors=1)

    knn.fit(X, y)

    new_metrics = new_metrics.reshape(1, -1)
    return(knn.predict(new_metrics))
# emotionProcessor.py
# This class allows the software to extract vocal metrics
# from a given audio file using various methods.
# Libraries used to extract audio metrics include:
# -pyAudioAnalysis
# -scipy.io
# -python_speech_features
# -pydub
# Each method of the Emotion Processor class works
# with a different library to extract a specific
# audio metric. Each of these methods conatin
# documentation relating tothe author and how they work.
# Related Software Requirements: FR.3, FR.4, FR.5, FR.6


# Import libraries
from pyAudioAnalysis import audioBasicIO
from pyAudioAnalysis import audioFeatureExtraction
from scipy.io import wavfile
from scipy.fftpack import fft
import wave
import numpy
import math
from python_speech_features import mfcc
from python_speech_features import delta
from python_speech_features import logfbank
import scipy.io.wavfile as wav
from pydub import AudioSegment
from pydub.silence import split_on_silence
from statistics import *
import numpy as np


# Declaration of the EmotionProcessor class
class EmotionProcessor(object):

    # Initialization method used to create a new object of
    # the EmotionProcessor class.
    def __init__(self, fname):
        self.fname = fname

# Enter and exit methods used by the EmotionProcessor class.
    def __enter__(self):
        return self

    def __exit__(self, exception, value, traceback):
        self.close()


# mfccProc: extracts the MFCCs from given audio
# Written by Timmothy Lane
# Creates 2d arrays for storage of the fbank feature, mfcc features
# and the delta of MFCC features
# NOTE: code used to create 2 dimensional arrays for both the delta
# of MFCCs and log of the filterbank features are included, but commented
# out. These statements were included for use by future researchers who
# may want to experiment with the different metrics to improce accuracy.
##  Inputs: self
# Output: an array containing the Mel-Frequency Cepstrum Coefficients
# Related Software Requirements: FR.6
# Author: Timmothy Lane

    def mfccProc(self):
        (rate, sig) = audioBasicIO.readAudioFile(self.fname)
        # Create 2d array for MFCC features
        mfcc_feat = mfcc(sig, samplerate=44100, nfft=1103)
        # Create 2d array for the delta of MFCC features
        #d_mfcc_feat = delta(mfcc_feat, 2)
        # Create 2d array for the log of fbank features
        #fbank_feat = logfbank(sig,rate)
        # Return the Mel-Frequency Cepstrum Coefficients
        return(mfcc_feat)


# Description: This function extracts the pitch of the audio file and puts it into a list of short term measurements from the file
# Inputs:self
# Outputs: array of the pitches for the short term chunks
# Related Software Requirements: FR.3
# Author: Alex Shannon


    def pitchProc(self):
        [Fs, x] = audioBasicIO.readAudioFile(self.fname)
        info = audioFeatureExtraction.stFeatureExtraction(
            x, Fs, 0.050*Fs, 0.025*Fs)
        return info[0][1]

# Description: This function exctracts the metrics from the audio file that partain to the volume
# or Sound Pressure Level(SPL)
# Inputs:self
# Outputs: returns a numpy array called freqArray of the volume metrics from the audio file
# Related Software Requirements: FR.4
# Author: Humberto Colin

    def volumeProc(self):
        freq, snd = wavfile.read(self.fname)
        snd = snd/(2.**15)
        s1 = snd[:]
        n = len(s1)
        p = fft(s1)  # takes the fourier transform
        unique = int(math.ceil((n+1)/2.0))
        p = p[0:unique]
        p = abs(p)
        p = p/float(n)
        p = p**2
        if n % 2 > 0:
            p[1:len(p)] = p[1:len(p)]*2
        else:
            p[1:len(p)-1] = p[1:len(p)-1]*2
        # stores the values from the start to finish of the audio file
        freqArray = numpy.arange(0, unique, 1.0)*(freq/n)
        #numpy.set_printoptions(threshold = numpy.nan)
        #rms_val = sqrt(mean(s1**2))
        return(freqArray)


# gapProc: function that allows the extraction of the gaps between
# consecutive words.
##  Inputs: self
# Output: an array containing the lengths of every gap between words
# Related Software Requirements: FR.5
# Author: Michael Knapp and Timmothy Lane


    def gapProc(self):
        # def gapProc(self , lowest):
        sound_file = AudioSegment.from_wav(self.fname)
        audio_chunks = split_on_silence(sound_file,
                                        # must be silent for at least 100ms
                                        min_silence_len=1,
                                        # consider it silent if quieter than -16 dBFS
                                        silence_thresh=8)

        # List made to store all of the silence .wav chunks
        waveAry = []
        # List made to store the lengths of the silence chunks
        chunkLengthArray = []

        for i, chunk in enumerate(audio_chunks):
            out_file = ".//splitAudio//chunk{0}.wav".format(i)
            # waveAry.append(chunk)
            chunkLengthArray.append(len(chunk))

        # If there were no silences, set the mean variable to 0
        if len(chunkLengthArray) == 0:
            avgChunkLength = 0
            stdevChunkLength = 0
        # If thee is exactly 1 silence, set the stdev to 0
        #   and the average chunk length to the value of the only silence
        elif len(chunkLengthArray) == 1:
            stdevChunkLength = 0
            avgChunkLength = chunkLengthArray[0]
        # Otherwise calculate the mean gap and stdev of the gaps and store
        #   them in variables
        else:
            avgChunkLength = mean(chunkLengthArray)
            stdevChunkLength = stdev(chunkLengthArray)
        # Return the array containing the lengths of the gaps
        return(chunkLengthArray)


# collectMetrics:
# Collects the audio metrics using the above methods,
# places them into a pandas array, and returns them
# for use by the software
# Author: Bryan Jones

    def collectMetrics(self):
        pitch = self.pitchProc()
        pitch = stdev(pitch)

        volume = self.volumeProc()
        volume = stdev(volume)

        tone = self.mfccProc()
        dev_array = []
        for i in tone:
            temp = stdev(i)
            dev_array.append(temp)
        tone = stdev(dev_array)

        wordGap = self.gapProc()
        if(len(wordGap) != 0):
            wordGaplen = len(wordGap)
            wordGap = stdev(wordGap)
        else:
            wordGaplen = 0
            wordGap = 0

        user_profile = np.array([pitch, tone, volume, wordGap, wordGaplen])
        return(user_profile)
# profileManager.py: Contains the profileManager class that allows access
# and manipulations of user profiles for the Audio Emotion Detection System
# Contains the following methods:
# __init(self, userName)__: Initialization method
# accessProfile(self): Accesses uer profiles
# writeToProfile(self, newMetrics, Emotion): Updates user profiles
# generateProfile(self): Creates new user profiles
# More information regarding these methods are detailed above each method.
# Unless otherwise specified, every method within this class was written by Timmothy Lane
# Related Software Requirements: FR.2, FR.7, FR.8

from pathlib import Path
import os.path
from pandas import *
import csv


class profileManager:

    # Initalization class for the profile manager, which is called every time
    # a new profile object is created.
    # This method sets the file name and file path associated with a user
    # profile.
    # Related Software Requirements: FR.7
    def __init__(self, userName):
        # If receieved userName is empty or null
        if userName == "" or userName == None:
            # set the file path and name to match the generic file
            self.fileName = "generic.csv"
            self.path = "profiles/"+self.fileName
        # If a userName is provided
        else:
            # Set the file name and path to match the user name
            self.fileName = userName + ".csv"
            self.path = "profiles/"+self.fileName


# Method that accesses a user profile .csv file.
# Checks to see if a user profile .csv exists, and
# calls the generateProfile method if one does not.
# Creates a dataframe from the user profile so that
# the metrics can be easier accessed.
# Related Software Requirements: FR.8


    def accessProfile(self):
        # Use the path attribute to create a Path for the file
        self.file = Path(self.path)
        # If the file associated with the user  profile exists
        if self.file.exists():
            # Create a dataframe holding the information of the user profile using pandas
            self.oldMetrics = pandas.read_csv(self.path, header=None, sep=',', names=[
                                              'Pitch', 'Tone', 'SPL', 'wordGap', 'WordGapLen', 'Emotion'])
        # If a file does not exist for the user profile
        else:
            # Generate a new file for the user profile
            self.generateProfile()
            # Create a dataframe holding the information of the user profile using pandas
            self.oldMetrics = pandas.read_csv(self.path, header=None, sep=',', names=[
                                              'Pitch', 'Tone', 'SPL', 'wordGap', 'WordGapLen', 'Emotion'])


# Method that allows writing to the .csv associated with the user.
# Inputs: the new audio metrics and the corrosponding emotion
##  Outputs: None
# The method updates the row of the user profile with the corrosponding emotion
# with the new metrics
# Related Software Requirements: FR.2
# NOTE: This method overwrites the previous data and was depreciated for the
# new method "addtoProfile," which instead appends to the profile. This method
# was included for educational purposes.


    def writeToProfile(self, newMetrics, emotion):
        self.accessProfile()
        self.oldMetrics.loc[self.oldMetrics['Emotion']
                            == emotion, "Pitch"] = newMetrics[0]
        self.oldMetrics.loc[self.oldMetrics['Emotion']
                            == emotion, "Tone"] = newMetrics[1]
        self.oldMetrics.loc[self.oldMetrics['Emotion']
                            == emotion, "SPL"] = newMetrics[2]
        self.oldMetrics.loc[self.oldMetrics['Emotion']
                            == emotion, "wordGap"] = newMetrics[3]
        self.oldMetrics.loc[self.oldMetrics['Emotion']
                            == emotion, "WordGapLen"] = newMetrics[4]
        self.oldMetrics.to_csv(self.path, index=False, header=0)
        return self.path

# Method for genereating a new .csv file for a new user.
# Creates a new .csv and sets it's values to the same values
# found in the generic user profile.
# Related Software Requirements: FR.7
    def generateProfile(self):
        # Create a dataframe holding the information of the generic profile using pandas
        generic = pandas.read_csv("profiles/generic.csv", header=None, sep=',', names=[
                                  'Pitch', 'Tone', 'SPL', 'wordGap', 'WordGapLen', 'Emotion'])
        # Write the dataframe to a new .csv file that will be associated with the
        #   current user profile
        generic.to_csv(self.path, index=False, header=0)
        return self.path

# Method that allows for data to be appended to a user profile while not overwriting
# previous data
# Written By: Bryan Jones
# Related Software Requirements: FR.2
    def addtoProfile(self, newMetric, emotion):
        with open(self.path, 'a') as f:
            fields = [newMetric[0], newMetric[1], newMetric[2],
                      newMetric[3], newMetric[4], emotion]
            writer = csv.writer(f)
            writer.writerow(fields)
#!/bin/env python3

"""Entry point for the entire ACU Repository."""

from src.server import main

import argparse

ap = argparse.ArgumentParser()
ap.add_argument('-port', '-p', type=int, nargs='?',
                help="Port that server will bind to", default=8081)
args = ap.parse_args()
main(args.port)
from VirtualObjectDefinitions import DirectAPIVirtualObject
from pyhs100 import SmartPlug


class SmartPlugVO(DirectAPIVirtualObject):
    def __init__(self, ip):
        # TODO figure out what 'inter' argument is
        super.init(True, False, {}, ['ON', 'OFF'], ['Turn On', 'Turn Off'], [])
        self.ip = ip
        try:
            self.plug = SmartPlug(ip)
        except Exception as e:
            print(e)
        self.update('State', self.pull())

    def pull(self):
        self.update('State', self.plug.state)

    def execute(self, action):
        if action is 'Turn On':
            self.plug.turn_on()
        else:
            self.plug.turn_off()
        pass
import RPi.GPIO as gpio
from flask import Flask, request, abort
from twisted.web.server import Site
from twisted.web.wsgi import WSGIResource
from twisted.python import log
from twisted.internet import reactor
import requests
import os
#from device_security import *

gpio.setmode(gpio.BCM)
gpio.setup(20, gpio.OUT)
old_state = ''
app = Flask(__name__)
header = {'acu-id': 'red_led', 'hub-access-key': 'demo',
          'net-id': 'RSH-DemoNet', 'hub-id': 'RSH-Hub'}
fps = 30
hub_ip = 'http://192.168.86.123:8073/devices'
#sec = Security("RSH-DemoNet", "RSH-Hub", "red_led")


@app.route("/execute", methods=['POST'])
def execute():
    action = request.data
    # try:
    #     action = sec.decrypt_message(action)
    # except:
    #     print('Unathorized connection')
    #     abort(401)
    print("action: ", action)
    try:
        action = int(action)
        gpio.output(20, action)
    except:
        pass
    print("Done with execute")
    return "executed"


def getState():
    raw_state = gpio.input(20)
    global old_state
    global hub_ip
    if raw_state != old_state:
        old_state = raw_state
        print("raw state: ", raw_state)
        #raw_state = sec.encrypt_message(str(raw_state))
        request = requests.post(hub_ip, data=raw_state,
                                headers=header, timeout=0.1)
    reactor.callLater(1/fps, getState)


if __name__ == "__main__":
    # sec.extend_handshake()
    header["Auth-Code"] = str(base64.b64encode(sec.authCode), 'utf-8')
    port = 7778
    getState()
    wsgiResource = WSGIResource(reactor, reactor.getThreadPool(), app)
    reactor.listenTCP(port=port, factory=Site(
        wsgiResource), interface="0.0.0.0")
    reactor.run()
    gpio.cleanup()
#!/usr/bin/env python3
from flask import Flask, request, abort
from twisted.web.server import Site
from twisted.web.wsgi import WSGIResource
from twisted.python import log
from twisted.internet import reactor
import requests
import sys
#from device_security import *

from pyHS100 import SmartPlug

if len(sys.argv) < 2:
    print('usage: TUPLinkHS100_server.py <ip>')
    exit(1)

device = SmartPlug(sys.argv[1])
current_state = device.state
print(current_state)
old_state = ''

app = Flask(__name__)
header = {'acu-id': 'lamp', 'hub-access-key': 'demo',
          'net-id': 'RSH-DemoNet', 'hub-id': 'RSH-Hub'}
fps = 30
hub_ip = 'http://192.168.86.123:8073/devices'


@app.route("/execute", methods=['POST'])
def execute():
    action = request.data.decode()
    print("action: ", action)
    try:
        if (action == 'ON'):
            device.turn_on()
        elif (action == 'OFF'):
            device.turn_off()
    except:
        pass
    print("Done with execute")
    return "executed"


def getState():
    global old_state
    if device.state is not old_state:
        old_state = device.state
        print("raw state: ", device.state)
        request = requests.post(hub_ip, data=device.state,
                                headers=header, timeout=0.1)
    reactor.callLater(1/fps, getState)


if __name__ == "__main__":
    # sec.extend_handshake()
    port = 7070
    getState()
    wsgiResource = WSGIResource(reactor, reactor.getThreadPool(), app)
    reactor.listenTCP(port=port, factory=Site(
        wsgiResource), interface="0.0.0.0")
    reactor.run()
import json
hub = {"motion-sensor": {"VO Type": "Generic-HTTP",
                         "Classification": "Devices/Sensors/PIR-Motion-Detector",
                         "GUID": "92834h-2h87h3-9873h8h",
                         "Location": "Cheek, 213A",
                                    "Functional": False,    # sensors are False, actuators are True
                                    "Interpreter Type": "PUSH",
                                    "Mode": "Label",
                                    "Semantic Links": [],
                                    # derived from device script
                                    "States": ['0', '1'],
                                    "Actions": [],
                                    "Interpreter": {},
                         "Address": "http://192.168.86.121",  # device ip
                         "Headers": None,
                         "Params": None,
                         "Auth": None},
       "buzzer": {"VO Type": "Generic-HTTP",
                  "Classification": "Devices/Sensors/PIR-Motion-Detector",
                  "GUID": "92834h-2h87h3-9873h8h",
                  "Location": "Cheek, 213A",
                  "Functional": True,
                                    "Interpreter Type": "PUSH",
                                    "Mode": "Label",
                                    "Semantic Links": ['RSH-Hub:button'],
                                    "States": ['0', '1'],
                                    "Actions": ['0', '1'],
                                    "Interpreter": {},
                  "Address": "http://192.168.86.135:7778/execute",
                  "Headers": None,
                  "Params": None,
                  "Auth": None},
       "button": {"VO Type": "Generic-HTTP",
                  "Classification": "Devices/Sensors/PIR-Motion-Detector",
                  "GUID": "92834h-2h87h3-9873h8h",
                  "Location": "Cheek, 213A",
                  "Functional": False,    # sensors are False, actuators are True
                                    "Interpreter Type": "PUSH",
                                    "Mode": "Label",
                                    "Semantic Links": [],
                                    # derived from device script
                                    "States": ['0', '1'],
                                    "Actions": [],
                                    "Interpreter": {},
                  "Address": "http://192.168.86.133",  # device ip
                  "Headers": None,
                  "Params": None,
                  "Auth": None},
       "temperature-sensor": {"VO Type": "Generic-HTTP"},
       "Classification": "Devices/Sensors/Temperature-Sensor",
       "GUID": "92834h-2h87h3-9873h8h",
       "Location": "Cheek, 213A",
       "Functional": False,
       "Interpreter Type": "PUSH",
       "Mode": "Label",
       "Semantic Links": [],
       "States": ["Hot", "Ambient", "Cold"],
       "Actions": [],
       "Interpreter": {},
       "Address": "http://192.168.86.133",
       "Headers": None,
       "Params": None,
       "Auth": None
       }

with open('rshDemo_RSH-DemoNet_RSH-Hub.hub', 'w') as outfile:
    outfile.write(json.dumps(hub))
# sudo i2cdetect -y 1

import smbus2
import math
sm = smbus2.SMBus(1)

addr = 0x48


def convert(byte):
    vr = 5 * float(byte) / 255
    rt = 10000 * vr / (5 - vr)
    temp = 1 / (((math.log(rt / 10000)) / 3950) + (1 / (273.15+25)))
    return temp


while True:
    # print(sm.read_byte(addr))
    raw_data = sm.read_i2c_block_data(0x48, 0, 32)
    disp = list(map(lambda x: "{:02x}".format(x), raw_data))
    print("{}".format(disp))
    # print("{}".format(convert(sm.read_byte(0x48))))
from src.storage.database.acu_database import create_definition, nuke, example_db, session, find_acus_by_tag


def thread_test():
    from threading import Thread
    t1 = Thread(target=create_definition)


if __name__ == '__main__':
    nuke()
    example_db()
    # delete_definition('iqbal')
    # find_acus_by_tag('a')
    for acu in find_acus_by_tag('a'):
        print(acu.info())

    # user = session.query(User).first()
    # print(session.query(ACUDefinition).filter_by(user_id=user.id).all())
    # acus = find_acus_by_contributor('alex')
    # print(acus)
    session.close()  # Safe cleanup
import test.file_manager_test
import zipfile
import os
from os import path
from src.storage.file_manager import FileManager
import src.storage.database.acu_database as acu_database
import time

# from src.storage.database.entity import Base
# from src.storage.database.session import engine
# Base.metadata.create_all(engine)

acu_database.nuke()
acu_database.example_db()

for f in os.listdir('data/acu'):
    os.remove('data/acu/{}'.format(f))
for f in os.listdir('data/doc'):
    os.remove('data/doc/{}'.format(f))

print(os.getcwd())
fm = FileManager(path.relpath('./data'))
user = acu_database.find_contributor_by_name('alex')

with open('src.zip', 'rb', buffering=0) as f:
    fm.add_def('example1', user.id, f, classification=[
               'a', 'b', 'c'], version='0.1', description='Example one')
    fm.add_def('example2', user.id, f, classification=[
               'foo', 'bar'], version='0.1', description='Example two')
    time.sleep(2)
    fm.add_def('example1', user.id, f, version='0.2')
# print(fm.retrieve_doc('example'))
# fm.remove_def('example3', 1)
import sys
import json
from twisted.internet import reactor
from autobahn.twisted.websocket import WebSocketClientFactory, \
    WebSocketClientProtocol, \
    connectWS


class BroadcastClientProtocol(WebSocketClientProtocol):

    """
    Simple client that connects to a WebSocket server, send a HELLO
    message every 2 seconds and print everything it receives.
    """

    def sendHello(self):
        payload = {"file_request": "example1", "version": "0.2"}
        payload = json.dumps(payload)
        self.sendMessage(payload.encode('utf-8'))
        reactor.callLater(60, self.sendHello)

    def onOpen(self):
        self.sendHello()

    def onMessage(self, payload, isBinary):
        print(payload)


if __name__ == '__main__':

    server_address = "ws://127.0.0.1:8081/ws"
    factory = WebSocketClientFactory(server_address)
    factory.protocol = BroadcastClientProtocol
    connectWS(factory)

    reactor.run()
import base64
import io
import os
import requests
import zipfile
from websocket import create_connection


class File_Broker:
    """
    Programmed by: Eric McCullough
    Description: The file_broker acts as an intermediary between CoMPES and the ACU Repository server.
                 It takes a list of ACU definitions and requests the zip file for each from the server.
                 It then takes the zip file, unpacks it, and sends individual files to the correct
                 recipients.
    Related Requirements: 3.4.2.1
    Related HLD sections: File Broker Component Diagram
    """

    def __init__(self, acu_list, network_schema, server_ip):
        """
        @ acu_list: 2d list containing acu names and versions to download
        @ network_schema: dictionary containing ip address of CoMPES entities
        @ server_ip: the IP address currently hosting the ACU Repository server
        """
        self.acu_list = acu_list
        self.network_schema = network_schema
        self.server_ip = server_ip

    def retrieve(self):
        """
        Iterates over acu_list and requests each file
        """
        for i in range(len(self.acu_list)):
            r_data = {'file_request': self.acu_list[i][0],
                      'version': self.acu_list[i][1]}
            r = requests.post(self.server_ip, data=r_data)
            acu_bytes = base64.b64decode(r.text)
            print("Acquired ACU: {}".format(self.acu_list[i][0]))
            acu_zip = zipfile.ZipFile(io.BytesIO(acu_bytes))
            directory = 'temp/' + self.acu_list[i][0]
            os.mkdir(directory)
            for file_name in acu_zip.namelist():
                acu_zip.extract(file_name, directory)
                if file_name.endswith('.vo'):
                    print("sending virtual object definition to Hub")
                    with open(directory + '/' + file_name, 'r') as vo:
                        data = {"payload type": "file",
                                "payload": vo.read().encode("utf-8")}
                    hub_r = requests.post(self.network_schema["Hubs"]["RSH-Hub"],
                                          data=data)
                    # print(hub_r.text)
                elif file_name.endswith('.cdef'):
                    print("Sending device schema to Compute Service")
                    with open(directory + '/' + file_name, 'r') as cdef:
                        payload = cdef.read()
                        ws = create_connection(
                            self.network_schema["Compute Service"])
                        ws.send(payload)
                        ws.close
                elif file_name.endswith('.py'):
                    print("sending gpio script to raspberry pi")
                    with open(directory + '/' + file_name, 'r') as vo:
                        data = {"payload type": "file",
                                "payload": vo.read().encode("utf-8")}
                    gpio_r = requests.post(self.network_schema["GPIO-Devices"][self.acu_list[i][0]],
                                           data=data)

    def start_hub(self):
        try:
            hub_r = requests.post(self.network_schema["Hubs"]["RSH-Hub"],
                                  data={"payload type": "end"})
            print("File closed")
        except:
            pass

    def start_network(self):
        for i in range(len(self.acu_list)):
            try:
                device_r = requests.post(self.network_schema["GPIO-Devices"][self.acu_list[i][0]],
                                         data={"payload type": "end"})
            except:
                pass


if __name__ == "__main__":

    # TODO: modify acu_list to contain the acu names you would like to use
    acu_list = [["Button", "0.1"], ["Buzzer", "0.3"], ["Lamp", "0.1"],
                ["Fan", "0.1"], ["Motion Sensor", "0.1"], ["Temperature Sensor", "0.1"]]

    # TODO: modify network_schema to reflect the CoMPES network you are using
    network_schema = {
        "Compute Service": "ws://192.168.86.125:8040",
        "Hubs": {
            "RSH-Hub": "http://192.168.86.123:8089/"
        },
        "GPIO-Devices": {
            "Button": "http://192.168.86.155:8089/",
            "Buzzer": "http://192.168.86.154:8089/",
            "Fan": "http://192.168.86.149:8087/",
            "Lamp": "http://192.168.86.149:8089/",
            "Motion Sensor": "http://192.168.86.150:8089/",
            "Temperature Sensor": "http://192.168.86.156:8089/"
        }
    }

    # TODO: modify this variable to reflect the server's IP address
    server_ip = "http://192.168.86.23:8081/compes"

    fb = File_Broker(acu_list, network_schema, server_ip)
    fb.retrieve()
    fb.start_hub()
    startNetwork = False
    while not startNetwork:
        input("press any key to continue")
        startNetwork = True
    fb.start_network()
import sys

from twisted.python import log
from twisted.web import server, resource
from twisted.internet import reactor, endpoints


class Listener(resource.Resource):
    """
    Programmed by: Eric McCullough
    Related Requirements: 3.4.2.1
    Related HLD sections: File Broker Component Diagram 
    """

    def render_POST(self, request):
        print("Handling Post")
        isLeaf = True
        try:
            print(request.args)
            if request.args[b'payload type'][0] == b'end':
                reactor.stop()
            elif request.args[b'payload type'][0] == b'file':
                with open("device.py", 'w+') as vo_file:
                    # print(request.args[b'payload'][0].decode())
                    if request.args[b'payload'][0].decode() not in vo_file.read():
                        vo_file.write(request.args[b'payload'][0].decode())
                return b'File received'
        except:
            print(request.args)
            return b'Nothing was done'


if __name__ == "__main__":

    log.startLogging(sys.stdout)

    root = resource.Resource()
    root.putChild(b'', Listener())
    site = server.Site(root)
    reactor.listenTCP(8089, site)
    reactor.run()
import sys

from twisted.python import log
from twisted.web import server, resource
from twisted.internet import reactor, endpoints


class Listener(resource.Resource):
    """
    Programmed by: Eric McCullough
    Related Requirements: 3.4.2.1
    Related HLD sections: File Broker Component Diagram 
    """

    def render_POST(self, request):
        print("Handling Post")
        isLeaf = True
        try:
            print(request.args)
            if request.args[b'payload type'][0] == b'end':
                reactor.stop()
            elif request.args[b'payload type'][0] == b'file':
                file_dir = "Data_Structures/VirtualObjectDefinitions.py"
                with open(file_dir, 'a') as vo_file:
                    # print(request.args[b'payload'][0].decode())
                    if request.args[b'payload'][0].decode() not in vo_file.read():
                        vo_file.write(request.args[b'payload'][0].decode())
                return b'File received'
        except:
            print(request.args)
            return b'Nothing was done'


if __name__ == "__main__":

    log.startLogging(sys.stdout)

    root = resource.Resource()
    root.putChild(b'', Listener())
    site = server.Site(root)
    reactor.listenTCP(8089, site)
    reactor.run()
"""
Programmed by: Eric McCullough
Related Requirements: 3.4.2.1
Related HLD sections: File Broker Component Diagram 
NOTE: This file will NOT run on it's own. This code is meant to augment a Compute Service application.py file
"""


class BrokerProtocol(WebSocketServerProtocol):

    def onConnect(self, request):
        print("Incoming connection from file broker")

    def onOpen(self):
        pass

    def onMessage(self, payload, isBinary):
        print("DEVICE SCHEMA RETRIEVED: ", payload)

    def onClose(self, wasClean, code, reason):
        pass


if(__name__ == '__main__'):
    Compute_Info = {
        "GUI Server Address": "ws://192.168.86.125:8081",
        "Hub Server Address": "ws://192.168.86.125:8070",
        "CoMPES Server Address": "ws://192.168.86.125:8083",
        "Broker Server Address": "ws://192.168.86.125:8040"
    }
    server1 = ComputeServer(Compute_Info["GUI Server Address"], Compute_Info["Hub Server Address"],
                            Compute_Info["CoMPES Server Address"], Compute_Info["Broker Server Address"])
    server1.start()
"""
This file contains the configurations for the server.
Resource definitions and documentation are in the site/resources.py document
Licensing info: https://opensource.org/licenses/MIT

Related Requirements:
Related HLD Components: Server, CoMPES Bridge
"""
import base64
import json
import io
import sys

from twisted.cred.portal import IRealm, Portal
from twisted.internet import reactor, endpoints
from twisted.python import log
from twisted.web.guard import HTTPAuthSessionWrapper, BasicCredentialFactory
from twisted.web.resource import Resource
from twisted.web.server import Site  # , NOT_DONE_YET
from twisted.web.static import File

from autobahn.twisted.resource import WebSocketResource
from autobahn.twisted.websocket import WebSocketServerFactory

from . site.resources import LoginResource, LogoutResource, ContributorResource,\
    ACURealm, ACUCredentialChecker, FetchACU, Search, ACUVersions, ACUForContributor,\
    ACUExists, CreateNewUser, Index, DocumentIndex, AuthorizedIndex, EditIndex,\
    RootResource, CompesComunication

from . site.elements import WebPage, UploadPage, HelpPage, AboutPage, LoginPage,\
    ContributionsPage


def main(port=8081):
    log.startLogging(sys.stdout)

    # Root for entire service
    root = RootResource()  # Resource()
    # Root for API endpoints (dl/ul, search)
    api = Resource()

    # Protected Resources
    checker = ACUCredentialChecker()
    realm = ACURealm()
    authorizer = HTTPAuthSessionWrapper(
        Portal(realm, [checker]), [BasicCredentialFactory("ACURepository")])

    # Setting up CoMPES Communicaiton resource
    root.putChild(b'compes', CompesComunication())

    api.putChild(b'search', Search())
    api.putChild(b'fetch', FetchACU())
    api.putChild(b'ownAcus', ACUForContributor())
    api.putChild(b'versions', ACUVersions())

    #api.putChild(b'edit', EditACU())

    api.putChild(b'exists', ACUExists())
    # this endpoint requires an authorized session
    api.putChild(b'contributor', ContributorResource())

    root.putChild(b'authorize', authorizer)
    root.putChild(b'upload', AuthorizedIndex(element=UploadPage()))
    root.putChild(b'logout', LogoutResource())

    root.putChild(b'', Index(element=WebPage()))
    root.putChild(b'help', Index(element=HelpPage()))
    root.putChild(b'about', Index(element=AboutPage()))
    root.putChild(b'login', Index(element=LoginPage()))

    root.putChild(b'contributions', AuthorizedIndex(
        element=ContributionsPage()))
    root.putChild(b'edit', EditIndex())
    root.putChild(b'documentation', DocumentIndex())
    root.putChild(b'api', api)
    root.putChild(b'assets', File('./assets'))

    site = Site(root)
    endpoint = endpoints.TCP4ServerEndpoint(reactor, port)
    endpoint.listen(site)
    reactor.run()


# Setup ####################################################
if __name__ == "__main__":
    main()
import zipfile
import json


class InvalidACUError(Exception):
    def __init__(self, message, offenders=[]):
        self.message = message
        self.offenders = offenders


class ACU_Validator:
    """
    Programmed by: Eric McCullough
    Related Requirement: 3.1.1.2
    see ACU validator under component descriptions for the ACU repository in the HLD
    Functions contain their own docstring
    """

    def validate(self, zip_file):
        """
        Programmed by: Eric McCullough
        @ Params: an ACU definition zip file
        @ Return: an error message detailing issues with the ACU zip file. If the file passes the validation
                  process, the error message will be an empty string
        """
        # these five variables will be used to determine the ACU's validity
        # Error message will have new info added to it whenever something is found to be wrong
        error_message = ''
        offenders = []          # offenders will be a list of files that violate some rules
        # These variables track the presence of key file types
        vo_present, cdef_present, md_present = False, False, False

        # self._unzip(zip_file)
        file_dir = 'temp/'

        for file_name in zip_file.namelist():
            zip_file.extract(file_name, 'temp')
            if file_name.endswith('.cdef'):
                cdef_present = True
                self._cdef_check(file_dir + file_name)
            elif file_name.endswith('.vo'):
                vo_present = True
                test_result = self._vo_check(file_dir + file_name)
                if test_result != '':
                    error_message += 'Virtual object definition file was missing the ' \
                                     'following components:\n{}\n'.format(
                                         test_result)
                    # error_message += test_result
            elif file_name.endswith('.md'):
                md_present = True
            elif not file_name.endswith('.py'):
                # invalid file type found
                error_message += 'Invalid file type found at {}\n'.format(
                    file_name)
                offenders.append(file_name)

        # Check that all components are present
        if not vo_present:
            error_message += 'Missing python ACU definition file\n'
        if not cdef_present:
            error_message += 'Missing .cdef file\n'
        if not md_present:
            error_message += 'Missing markdown documentation file\n'

        if error_message == '':
            return 'ACU valid'
        else:
            raise InvalidACUError(error_message, offenders=offenders)

    def _cdef_check(self, cdef_file):
        """
        Programmed by: Eric McCullough
        @ Params: a cdef file with the schema first, followed by the device definition. Please note that 
                  you cannot load a python `None` object into a dictionary, meaning that blank fields will
                  need to be delineated with the word 'None' in quotes.
        @ Return: a error message containing a statement for each incorrect field it encounters. If the cdef file
                  is correctly formatted, it will return an empty string.
        """
        with open(cdef_file) as f:
            content = f.read()  # read contents into string
        # cdef files do not seperate different json objects with commas, therefore json.loads() fails on these files.
        # The following while loop manually parse the string into python dictionaries
        dict_list = []
        r_brackets, l_brackets = 0, 0
        start, index = 0, 0
        while (r_brackets != l_brackets or r_brackets == 0) and index <= len(content) - 1:
            if content[index] == "{":
                r_brackets += 1
            elif content[index] == "}":
                l_brackets += 1
            if r_brackets == l_brackets and r_brackets != 0:
                new_json = json.loads(content[start:index+1])
                dict_list.append(new_json)
                start = index+1
                r_brackets, l_brackets = 0, 0
            index += 1

        error_message = ''
        device_id = list(dict_list[1].keys())[0]
        try:
            if type(dict_list[1][device_id]["ID"]) is not str:
                error_message += "\tdevice ID in invalid format\n"
        except:
            error_message += "\tdevice ID missing from device definition\n"

        try:
            # list of accepted vo_types
            vo_types = ["Generic-HTTP", "Generic-WebSocket",
                        "Generic-Direct-API", "Custom"]
            if type(dict_list[1][device_id]["VO-Type"]) is not str:
                error_message += "\tdevice VO-Type in invalid format\n"
            if dict_list[1][device_id]["VO-Type"] not in vo_types:
                error_message += "\tunkown VO-Type\n"
        except:
            error_message += "\tdevice VO-Type missing from device definition\n"

        try:
            if type(dict_list[1][device_id]["Class"]) is not str:
                error_message += "\tdevice Class in invalid format\n"
        except:
            error_message += "\tdevice Class missing from device definition\n"

        try:
            if dict_list[1][device_id]["Location"] != "":
                error_message += "\tdevice Location should be empty by default\n"
        except:
            error_message += "\tdevice Location missing from device definition\n"

        try:
            if type(dict_list[1][device_id]["GET"]) is not str:
                error_message += "\tdevice GET in invalid format\n"
        except:
            error_message += "\tdevice GET missing from device definition\n"

        try:
            I_Types = ["Rubric", "State", "None"]
            if dict_list[1][device_id]["I-Type"] not in I_Types:
                error_message += "\tunkownk I-Type\n"
        except:
            error_message += "\tdevice I-Type missing from device definition\n"

        try:
            if type(dict_list[1][device_id]["Rubric"]) is not str and dict_list[1][device_id]["Rubric"] != "None":
                error_message += "\tdevice Rubric in invalid format\n"
        except:
            error_message += "\tdevice Rubric missing from device definition\n"

        try:
            if type(dict_list[1][device_id]["States"]) is not list:
                error_message += "\tdevice States in invalid format\n"
        except:
            error_message += "\tdevice States missing from device definition\n"

        try:
            if type(dict_list[1][device_id]["Actions"]) is not list and dict_list[1][device_id]["Actions"] != "None":
                error_message += "\tdevice Actions in invalid format\n"
        except:
            error_message += "\tdevice Actions missing from device definition\n"

        try:
            if type(dict_list[1][device_id]["Rules"]) is not list and dict_list[1][device_id]["Rules"] != "None":
                error_message += "\tdevice Rules in invalid format\n"
        except:
            error_message += "\tdevice Rules missing from device definition\n"

        try:
            if dict_list[1][device_id]["Links"] != []:
                error_message += "\tdevice Links in invalid format\n"
        except:
            error_message += "\tdevice Links missing from device definition\n"

        vo_specific_fields = list(dict_list[1][device_id].keys())[11:]
        for key in vo_specific_fields:
            try:
                dict_list[0][device_id][key]
            except:
                error_message += "\tVO-specific field '{}' is missing".format(
                    key)
        return error_message

    def _vo_check(self, vo_file):
        """
        Programmed by: Eric McCullough
        @ Params: a python file with the schema first, followed by the device definition. Please note that 
                  you cannot load a python `None` object into a dictionary, meaning that blank fields will
                  need to be delineated with the word 'None' in quotes.
        @ Return: a error message containing a statement for each incorrect field it encounters. If the cdef file
                  is correctly formatted, it will return an empty string.
        """
        with open(vo_file) as f:
            f_contents = f.read()

        error_message = ''

        if 'import ABC' not in f_contents:
            error_message += '\tMissing ACU Base Class\n'

        if 'def push' not in f_contents:
            error_message += '\tMissing push method\n'

        if 'def pull' not in f_contents:
            error_message += '\tMissing pull method\n'

        if 'def execute' not in f_contents:
            error_message += '\tMissing execute method\n'

        return error_message


if __name__ == "__main__":
    validator = ACU_Validator()
    #test = zipfile.ZipFile('test.zip')
    error_message = ''
    print(validator._vo_check("src/VirtualObjectDefinitions.vo"))
    print(error_message)
"""Alex S, Nawaf A, Eric M

This module handles all functionality regarding uploading and retrieving ACU files.
Also updates the index when uploads and deletions occur.

Related Requirements: 3.5.1
Related HLD Components: File Manager, File System Bridge"""

from os import mkdir, path, remove
import re
from zipfile import ZipFile, BadZipFile
from . validator import ACU_Validator, InvalidACUError

from . database import acu_database

valid_name_rx = re.compile('^[^/\\"\'`~;:,|]*$')
doc_rx = re.compile('^.*\\.md$')


class UnauthorizedUserError(Exception):
    def __init__(self, acu_name):
        self.acu_name = acu_name

    def __str__(self):
        return 'User does not have authorization to modify {}'.format(self.acu_name)


class FileManager():
    def __init__(self, root_dir):
        self.validator = ACU_Validator()
        if path.isdir(root_dir):
            self.root_dir = root_dir
            self.acu_dir = path.join(self.root_dir, 'acu')
            self.doc_dir = path.join(self.root_dir, 'doc')
            if not path.exists(self.acu_dir):
                mkdir(self.acu_dir)
            if not path.exists(self.doc_dir):
                mkdir(self.doc_dir)
        else:
            raise Exception(
                'Root directory given to FileManager does not exist')

    def add_def(self, name, contributor_id, bytesio, description=None, version=None, classification=[]):
        """Alex S:
        Adds a definition to the ACU repository, saving a zipfile and .md file to disk,
        as well as updating the database.

        Args:
            name (str): ACU Name
            contributor_id (int): ID of the user attempting to upload. This is expected to have been checked before this function is ever called, ideally using the user's session.
            bytesio (io.BytesIO): Binary stream containing zipfile
            description (str): ACU Description
            version (str): Unique version string for this upload
            classification (str[]): list of tags/classifications
        Returns:
            str: the string 'success' if successful; else raises an exception

        Related Requirements: 3.1.2.2, 3.1.2.5
        """
        if valid_name_rx.match(name) is None or valid_name_rx.match(version) is None:
            raise InvalidACUError(
                'Name or version contains invalid characters')
        if self.wrong_user(name, contributor_id):
            raise UnauthorizedUserError(name)
        if acu_database.find_acu_by_name_and_version(name, version) is not None:
            raise InvalidACUError(
                'ACU with name {} and version {} already exists'.format(name, version))
        zip_file = ZipFile(bytesio)
        self.validator.validate(zip_file)

        # `doc` comes out as a byte array
        doc = zip_file.read(
            filter(lambda name: doc_rx.match(name) is not None, zip_file.namelist()).__next__())
        with open(path.join(self.doc_dir, '{}.md'.format(name)), 'wb', buffering=0) as doc_file:
            doc_file.write(doc)

        # now save the zip
        with open(path.join(self.acu_dir, '{}.{}.zip'.format(name, version)), 'wb', buffering=0) as file:
            bytesio.seek(0)  # creating ZipFile flushes buffer; rewind
            bytez = bytesio.read()
            file.write(bytez)

        # now make a database entry
        acu_database.create_definition(
            name=name,
            version=version,
            user_id=contributor_id,
            classification=classification,
            description=description)

        return 'success'

    def edit_def(self, name, contributor_id, description=None, version=None, classification=[], mdfilebites=""):
        """Christian H:
        This function only saves the description, classification tags, and the markdown file to an existing ACU definition

        Args:
            name (str): ACU Name
            contributor_id (int): ID of the user attempting to upload. This is expected to have been checked before this function is ever called, ideally using the user's session.
            bytesio (io.BytesIO): Binary stream containing mdfile
            description (str): ACU Description
            version (str): Unique version string for this upload
            classification (str[]): list of tags/classifications
        Returns:
            str: the string 'success' if successful; else raises an exception
        """

        if mdfilebites != "":
            self.replace_doc(name, contributor_id, mdfilebites)

        # now make a database entry
        acu_database.edit_definition(
            name=name,
            version=version,
            user_id=contributor_id,
            classification=classification,
            description=description)

        return 'success'

    def replace_doc(self, name, contributor_id, bytesio):
        """Alex S:
        Replaces the .md file for a given ACU name."""

        if len(acu_database.find_acu_by_name(name)) is not None:
            if self.wrong_user(name, contributor_id):
                raise UnauthorizedUserError(name)
            with open(path.join(self.doc_dir, '{}.md'.format(name)), 'w+b', buffering=0) as doc_file:
                print("writing file")
                doc_file.write(bytesio.read())
            return 'success'
        else:
            raise InvalidACUError('{} does not exist.'.format(name))

    def def_exists(self, name, version=None):
        """Checks if an ACU exists in the index.

        Related Requirements: 3.1.2.4"""
        if version is not None:
            return acu_database.find_acu_by_name_and_version(name, version) is not None
        else:
            return acu_database.find_acu_by_name(name) is not None

    def wrong_user(self, acu_name, uploader_id):
        """Check if a given user has the right to modify the given ACU"""
        acu = acu_database.find_acu_by_name(acu_name)
        return acu is not None and acu.user_id is not uploader_id

    def remove_def(self, name, version, contributor_id):
        """Remove an ACU from the index, as well as the associated files."""
        if self.wrong_user(name, contributor_id):
            raise UnauthorizedUserError(name)
        if self.def_exists(name):
            acu_database.delete_definition(name, version)
            remove(path.join(self.root_dir, 'acu',
                             '{}.{}.zip'.format(name, version)))
            if len(acu_database.find_acu_all_versions(name)) == 0:
                # only remove documentation if the last version is deleted
                remove(path.join(self.root_dir, 'doc', '{}.md'.format(name)))
            return 'success'
        else:
            # return {'error': 'ACU Definition under the name {} not found'.format(name)}
            raise InvalidACUError('ACU Does not exist')

    def retrieve_def(self, name, version):
        """Alex S.: 
        Retrieves an ACU Definition's zipfile from disk.
        Related Requirements: 3.1.2.3"""
        if self.def_exists(name):
            file = None
            with open((path.join(self.acu_dir, '{}.{}.zip'.format(name, version))), 'rb') as f:
                file = f.read()
            return file
        else:
            raise Exception(
                'ACU Definition under the name {} not found'.format(name))

    def retrieve_doc(self, name):
        """Retrieves the .md file for a given ACU name.
        Related Requirements: 3.2.2.7"""
        if self.def_exists(name):
            file = None
            with open((path.join(self.doc_dir, '{}.md'.format(name))), 'rb') as f:
                file = f.read()
            return file
        else:
            raise Exception(
                'ACU Definition under the name {} not found'.format(name))
"""Alex S:
Auxiliary class to act as a mutex lock.
Related Requirements: 3.5.2
Related HLD Components: Database Bridge
"""

from threading import Lock
from _thread import LockType
# Wrapper for default multithreading lock


class ACULock():
    def __init__(self, lock=None, session=None):
        if session is None:
            raise Exception('Must initialize ACU Lock with session')
        self.session = session
        if type(lock) is not LockType:
            self.lock = Lock()
        else:
            self.lock = lock

    def __enter__(self):
        self.lock.acquire()

    def __exit__(self, exc_type, exc_value, traceback):
        self.lock.release_lock()

    # Create/Update/Delete methods must lock and rollback,
    # This wraps such methods to automatically lock and
    # rollback if there are errors
    def critical_section(self, func):
        def f(*args, **kwargs):
            r = None
            try:
                with self.lock:  # auto-unlock on return or raise
                    r = func(*args, **kwargs)
                return r
            except Exception as e:  # flush any DB work before raising
                self.session.rollback()
                raise e
        return f

    # Wrap functions that only perform writes
    def read_lock(self, func):
        def f(*args, **kwargs):
            with self.lock:
                r = func(*args, **kwargs)
            return r
        return f
"""Maintains a single thread-safe session open to the database while the app is running.
Related Requirements: 3.5.1, 3.5.2
Related HLD Components: Database Bridge"""

from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

engine = create_engine('sqlite:///data/data.db', echo=False)
engine.connect()
Session = sessionmaker(bind=engine)

session = Session()
"""Alex S.

SQLAlchemy methods for accessing ACU Index and users.
Related Requirements: 3.1.2.1, 3.3.1, 3.5.2
Related HLD Components: Database Bridge, Search Module
"""
from datetime import datetime
from sqlalchemy import func
import re
from threading import Lock

from ..validator import InvalidACUError

from .entity import User, ACUClassification, ACUDefinition, Privilege
from .locker import ACULock
from .session import session

# This will wrap each function in a mutex lock
locker = ACULock(session=session)

version_re = re.compile(r'^[0-9\.a-zA-Z]*$')


def esc(string):
    """Escape the wildcard characters for LIKE expressions"""
    return string.replace('%', '[%]').replace('_', '[_]')


# TODO: get rid of this asap
def nuke():
    """ Delete everything from the database. """
    from src.storage.database.entity import Base
    from src.storage.database.session import engine, session
    # session = Session()
    print('Nuking DB; enter y to confirm, all else exits')
    answer = input()
    if answer is 'y':
        # session.query(User).drop()
        # session.query(ACUDefinition).drop()
        # session.query(ACUClassification).drop()
        Base.metadata.drop_all(engine)
        Base.metadata.create_all(engine)
        session.commit()
        print('DB Nuked!!!')
    else:
        print('Not nuking.')
        exit(1)


@locker.read_lock
def acu_info(acu):
    """Write an ACU's information into a dictionary, easily converted
    into JSON."""
    c = list(map(
        lambda x: x.tag,
        session.query(ACUClassification)
        .filter(ACUClassification.acu == acu)
        .all()))
    return {
        'name': acu.name,
        'classification': c,
        # Python's native datetime has precision in seconds, need in
        # milli's for JS
        'added': acu.added.timestamp() * 1000,
        'version': acu.version,
        'description': acu.description,
        'contributor': acu.author.name
    }


@locker.critical_section
def create_user(name, pw, privilege=Privilege.contributor):
    existing_user = session.query(User).filter_by(name=name).first()
    if (existing_user is not None):
        existing_user.password = pw
        session.commit()
        return existing_user
    else:
        user = User(name=name, password=pw, privilege=privilege.value)
        session.add(user)
        session.commit()
        return user


def edit_definition(name,
                    version,
                    user_id,
                    classification=[],
                    description='No Description.'):
    edit_acu = session.query(ACUDefinition).filter_by(
        name=name, version=version).first()

    edit_acu.description = description

    session.query(ACUClassification).filter_by(acu_name=name).delete()

    if classification is not None and type(classification) == list:
        for c in classification:
            session.add(ACUClassification(tag=c, acu_name=name))

    session.commit()

    return edit_acu


@locker.critical_section
def create_definition(name,
                      version,
                      user_id,
                      classification=[],
                      description='No Description.'):
    # existing_acu = session.query(ACUDefinition).filter_by(name=name, version=version).first()
    # if existing_acu is not None:
    #     # raise ACUOverwriteException('Overwrite attempted: {} version {}'.format(name, version))
    #     existing_acu.description = description
    #     session.query(ACUClassification).filter_by(acu_name).delete()
    # else:
    #     if (version_re.match(version) is None):
    #         raise InvalidACUError('Invalid version string: {}'.format(version))
    # NOTE: This assumes all validation has been done in a service class higher in
    # call hierarchy.
    new_acu = ACUDefinition(
        name=name,
        version=version,
        user_id=user_id,
        added=datetime.utcnow(),
        description=description)
    session.add(new_acu)
    # session.commit()
    # return new_acu
    if classification is not None and type(classification) == list:
        for c in classification:
            session.add(ACUClassification(tag=c, acu_name=name))
    session.commit()
    return new_acu


@locker.read_lock
def find_contributor_by_id(user_id):
    return session.query(User).filter(User.id == user_id).first()


@locker.read_lock
def find_contributor_by_name(name):
    return session.query(User).filter(User.name == name).first()


@locker.critical_section
def delete_definition_all(name):
    """Deletes all ACU entries with the given name"""
    acu = session.query(ACUDefinition)\
        .filter(ACUDefinition.name == name)\
        .delete(synchronize_session=False)
    session.query(ACUClassification)\
        .filter(ACUClassification.acu_name == name)\
        .delete(synchronize_session=False)
    session.commit()
    return acu


@locker.critical_section
def delete_definition(name, version):
    """Deletes given ACU with specific name and version."""
    acu = session.query(ACUDefinition)\
        .filter_by(name=name, version=version)\
        .delete(synchronize_session=False)
    if session.query(ACUDefinition).filter_by(name=name).first() is None:
        session.query(ACUClassification)\
            .filter(ACUClassification.acu_name == name)\
            .delete(synchronize_session=False)
    session.commit()
    return acu


@locker.read_lock
def find_acus_by_contributor_exact(name):
    """Finds all ACUs by contributor name"""
    return session.query(ACUDefinition)\
        .join(ACUDefinition.author)\
        .having(func.max(ACUDefinition.added))\
        .group_by(ACUDefinition.name)\
        .filter(User.name == name)\
        .all()


@locker.read_lock
def find_acus_by_contributor(name):
    """Finds all ACUs where contributor name is LIKE the input."""
    return session.query(ACUDefinition)\
        .join(ACUDefinition.author)\
        .having(func.max(ACUDefinition.added))\
        .group_by(ACUDefinition.name)\
        .filter(User.name.like('%{}%'.format(esc(name))))\
        .all()


@locker.read_lock
def find_acu_all_versions(name):
    """gets all ACU versions for a given name"""
    return session.query(ACUDefinition)\
        .order_by(ACUDefinition.added.desc())\
        .filter(ACUDefinition.name == name)\
        .all()


@locker.read_lock
def find_acu_by_name(name):
    return session.query(ACUDefinition)\
        .having(func.max(ACUDefinition.added))\
        .group_by(ACUDefinition.name)\
        .filter(ACUDefinition.name == name)\
        .first()


@locker.read_lock
def find_acu_by_name_and_version(name, version):
    return session.query(ACUDefinition)\
        .having(func.max(ACUDefinition.added))\
        .group_by(ACUDefinition.name)\
        .filter_by(name=name, version=version)\
        .first()


@locker.read_lock
def find_acus_by_name(name):
    name = esc(name)
    return session.query(ACUDefinition)\
        .having(func.max(ACUDefinition.added))\
        .group_by(ACUDefinition.name)\
        .filter(ACUDefinition.name.like('%{}%'.format(name)))\
        .all()


@locker.read_lock
def find_acus_by_tag(tag):
    return list(map(
        lambda x: x.acu,
        session.query(ACUClassification)
        .join(ACUClassification.acu)
        .filter(ACUClassification.tag.like('%{}%'.format(esc(tag))))
        .all()))


@locker.read_lock
def find_user_by_name_and_pw(name, password):
    return session.query(User)\
        .filter(User.name == name)\
        .filter(User.password == password)\
        .first()


@locker.read_lock
def find_user_by_name(name):
    return session.query(User)\
        .filter(User.name == name)\
        .first()


def example_db():
    """Setup some example users"""
    #session = Session()
    for name, pw in {'alex': 'foo', 'eric': 'bar', 'lucas': 'baz'}.items():
        create_user(name, pw)
"""Alex S.

Domain objects for ACU Definitions, classifications, and users.
Related Requirements: 3.5.*
Related HLD Components: Database Bridge
"""

from sqlalchemy import Column, Integer, String, Sequence, Enum, DateTime, ForeignKey
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import relationship
from sqlalchemy.types import Enum as dbEnum

from datetime import datetime

from enum import Enum

# Extending this class maps a Python class to a DB table
Base = declarative_base()


class Privilege(Enum):
    contributor = 1
    admin = 2


# TODO: Actually use raw enum value when using DB that supports native enum type (not sqlite)
class User(Base):
    __tablename__ = 'user'
    id = Column(Integer, Sequence('user_id_seq'), primary_key=True)
    name = Column(String(50))
    password = Column(String(50))
    # privilege = Column(dbEnum(Privilege, values_callable=lambda x: [e.value for e in x]))
    privilege = Column(Integer)

    def __str__(self):
        return "User: {} Id: {} Privilege: {}".format(self.name, self.id,
                                                      self.privilege)


class ACUDefinition(Base):
    __tablename__ = 'definition'
    # id = Column(Integer, Sequence('acu_id_seq'), primary_key=True, autoincrement=True)
    name = Column(String(256), primary_key=True, nullable=False)
    version = Column(String(256), primary_key=True)
    added = Column(DateTime())
    description = Column(String(1024))
    user_id = Column(Integer, nullable=False)
    author = relationship(  # Foreign key constraint
        'User',
        foreign_keys=[user_id],
        primaryjoin='User.id == ACUDefinition.user_id',
        order_by=User.id)


class ACUClassification(Base):
    __tablename__ = 'def_class'
    id = Column(Integer, Sequence('acu_id_seq'), primary_key=True)
    tag = Column(String(50))
    acu_name = Column(String(256), ForeignKey('definition.name'))
    acu = relationship(
        'ACUDefinition',
        foreign_keys=[acu_name],
        primaryjoin='ACUClassification.acu_name == ACUDefinition.name',
        order_by=ACUDefinition.name)
"""Alex S

Shared utilities for the web server."""

# Handy shortcuts for response headers
json_header = ('Content-Type', 'application/json; charset=utf-8')
http_header = ('Content-Type', 'text/html; charset=utf-8')

# Decode byte array into utf-8 string


def dec(byte_array):
    return byte_array.decode('utf-8')

# encode utf-8 string as bytes


def enc(a_string):
    return bytes(a_string, 'utf-8')
"""Twisted Element classes used to combine HTML templates into complete webpages.

Related Requirements: 3.2.2.(3-8)
Related HLD Components: Website, Server Interface
"""

import json

from twisted.python.filepath import FilePath
from twisted.web.microdom import escape as dom_escape
from twisted.web.template import Element, renderer, XMLFile, XMLString, flattenString, tags

from .. storage.database.acu_database import acu_info

from . util import json_header, http_header, dec, enc


class WebPage(Element):
    """Alex S., Christian H:
    This class serves as both the base class for all other web pages and as itself
    deals with rendering the home page of the application.
    """

    loader = XMLFile(FilePath('views/base.html'))

    # Christian H, Alex S., Lucas A.:
    # Created the home page of the application
    # Trello board entry - S2T5
    content = XMLFile(FilePath('views/content.html'))

    # Christian H:
    # Created the top nav bar to let users navigate the website
    # Trello board entry - S2T6
    navbar = XMLFile(FilePath('views/navbar.html'))

    foot = XMLFile(FilePath('views/footer.html'))
    compassSVG = XMLFile(FilePath('assets/compass.svg'))

    @renderer
    def header(self, request, tag):
        return self.navbar.load()

    @renderer
    def nav_controls(self, request, tag):
        request.getSession()
        name = request.session.sessionNamespaces.get('name')
        if name is not None:
            return XMLString("""
            <ul class="nav ml-auto">
                <li class="nav-item"><span class="nav-link text-white">Welcome, {}</span></li>
                <li class="nav-item"><a href="/upload" class="nav-link text-white">Upload</a></li>
                <li class="nav-item"><a href="/contributions" class="nav-link text-white">Contributions</a></li>
                <li class="nav-item"><a href="/logout" class="nav-link text-white">Logout</a></li>
            </ul>
            """.format(dom_escape(name))).load()  # escape name just in case
        else:
            return tags.ul(
                tags.li(tags.a('Login', href='/login', class_="nav-link text-white"),
                        class_="nav-item"),
                class_="nav ml-auto")

    @renderer
    def body(self, request, tag):
        return XMLFile(FilePath('views/content.html')).load()
        # return self.content.load()

    @renderer
    def footer(self, request, tag):
        return self.foot.load()

    @renderer
    def compass(self, request, tag):
        el = self.compassSVG.load()
        if tag.attributes.get('class') is not None:
            el[0].attributes.update({'class': tag.attributes.get('class')})
        return el


class NotFound(WebPage):
    @renderer
    def body(self, request, tag):
        request.setResponseCode(404)
        return XMLString("""
        <div class="text-center">
            <p>Resource Not Found.</p>
            <a href="/">Go Back</a>
        </div>
        """).load()


class DocumentationPage(WebPage):
    """Christian H., Alex S.:
    This class handles the rendering for the documentation page that
    Each ACU definition will have
    """
    content = XMLFile(FilePath('views/documentation.html'))

    def __init__(self, acu_info):
        super().__init__()
        self.acus = acu_info
        self.latest = acu_info[0]

    # TODO: remove this
    @renderer
    def body(self, request, tag):
        return XMLFile(FilePath('views/documentation.html')).load()

    @renderer
    def name(self, request, tag):
        return enc(self.latest.name)

    @renderer
    def version(self, request, tag):
        return enc(self.latest.version)

    @renderer
    def author(self, request, tag):
        return enc(self.latest.author.name)

    @renderer
    def description(self, request, tag):
        if self.latest.description is None:
            return enc('No Description.')
        else:
            return enc(self.latest.description)

    @renderer
    def info(self, request, tag):
        return enc(json.dumps([acu_info(acu) for acu in self.acus]))


class HelpPage(WebPage):
    help_page = XMLFile(FilePath('views/help.html'))

    @renderer
    def body(self, request, tag):
        return self.help_page.load()


class LoginPage(WebPage):
    """Christian H.:
    This class handles the rendering for the login page so that
    contributors can authenticate before contributing or editing
    Trello board entry - S2T2
    """
    login_page = XMLFile(FilePath('views/login.html'))
    # FIXME:
    @renderer
    def body(self, request, tag):
        # return self.login_page.load()
        return XMLFile(FilePath('views/login.html')).load()


class AboutPage(WebPage):
    about_page = XMLFile(FilePath('views/about.html'))
    @renderer
    def body(self, request, tag):
        return self.about_page.load()


class UploadPage(WebPage):
    upload_page = XMLFile(FilePath('views/upload2.html'))
    # FIXME:
    @renderer
    def body(self, request, tag):
        return self.upload_page.load()
        # return XMLFile(FilePath('views/upload2.html')).load()


class EditPage(WebPage):
    """Christian H.:
    This class handles the rendering for the ACU definiton edit page so that contributors
    can either change the project details or update their current ACU definition version
    """

    def __init__(self, acu_info):
        super().__init__()
        self.acus = acu_info
        self.latest = acu_info[0]

    # TODO: remove this
    @renderer
    def body(self, request, tag):
        return XMLFile(FilePath('views/edit.html')).load()

    @renderer
    def name(self, request, tag):
        return enc(self.latest.name)

    @renderer
    def version(self, request, tag):
        return enc(self.latest.version)

    @renderer
    def info(self, request, tag):
        return enc(json.dumps([acu_info(acu) for acu in self.acus]))


class ResultsPage(WebPage):
    results_page = XMLFile(FilePath('views/results.html'))

    @renderer
    def body(self, request, tag):
        return self.results_page.load()


class ContributionsPage(WebPage):
    contributions_page = XMLFile(FilePath('views/contributions.html'))
    @renderer
    def body(self, request, tag):
        return self.contributions_page.load()

    @renderer
    def successAlert(self, request, tag):
        if (request.args.get(b'success')) is not None:
            text = dom_escape(dec(request.args.get(b'success')[0]))
            return XMLString("""
            <div>
                <div id="successFlash" class="alert alert-success">Successfully Uploaded "{}"</div>
                <script>
                    setTimeout(() => q('#successFlash').classList.add('hidden'), 4000);
                </script>
            </div>
            """.format(dom_escape(text))).load()
        else:
            return tag
"""Alex S. Eric M. Christian H.

Resource classes that will serve webpages, open REST endpoints, and authenticate
users.

Related Requirements: 3.1 all, 3.3.1, 3.3.3, 3.3.4
Related HLD Components: Search Module, Website Interface, CoMPES Bridge, File System Bridge
"""

import base64
import json
import io
import sys
from zipfile import BadZipFile

from autobahn.twisted.websocket import WebSocketServerProtocol

from twisted.cred.checkers import ICredentialsChecker
from twisted.cred.credentials import IUsernamePassword
from twisted.cred.error import UnauthorizedLogin
from twisted.cred.portal import IRealm
from twisted.internet import reactor
from twisted.internet.defer import Deferred
from twisted.internet.task import deferLater
from twisted.web.resource import Resource, IResource
from twisted.web.server import NOT_DONE_YET
from twisted.web.static import File
from twisted.web.template import flattenString, tags

from zope.interface import implementer

from .. storage.database import acu_database
from .. storage.database.acu_database import acu_info
from .. storage.file_manager import FileManager, UnauthorizedUserError
from .. storage.validator import InvalidACUError

from . util import json_header, http_header, dec, enc
from . elements import NotFound, DocumentationPage, HelpPage, LoginPage,\
    AboutPage, UploadPage, EditPage, ContributionsPage

file_manager = FileManager('data')

# Utilities ###################################################################


def bad_request(request, message):
    request.setResponseCode(400)
    request.setHeader(*json_header)
    return enc(json.dumps({'error': message}))


def redirect_unauthorized(func):
    """Alex S.:
    Decorator function for protecting authorized frontend elements.
    Redirects user to login page if they do not have an authorized session.

    Related Requirements: 3.1.2.5"""
    def authorizer(zelf, request):
        request.getSession()
        if request.session.sessionNamespaces.get('name') is None:
            request.setResponseCode(403)
            request.redirect('/login')
            request.finish()
            return NOT_DONE_YET
        else:
            return func(zelf, request)
    return authorizer


def api_credential_checker(func):
    """Alex S.:
    Decorator function that wraps a render method, enabling a user to
    perform an authorized action via the API without requiring an existing session.
    Requires authorization header to be set manually.

    Related Requirements: 3.1.2.5"""
    def authorizer(zelf, request):
        result = None
        request.getSession()
        if request.session.sessionNamespaces.get('name') is not None:
            result = func(zelf, request)
        else:
            # print('got request')
            auth = request.requestHeaders.getRawHeaders(b'authorization')
            if auth is not None:
                auth_string = dec(base64.b64decode(auth[0].split(b' ')[1]))
                (name, pazz) = auth_string.split(':')
                user = acu_database.find_user_by_name_and_pw(name, pazz)
                if user is not None:
                    request.session.sessionNamespaces['name'] = name
                    request.session.sessionNamespaces['id'] = user.id
                    result = func(zelf, request)
                    request.session.expire()
        if result is not None:
            return result
        else:
            request.setResponseCode(403)
            return enc(json.dumps('Not Authorized'))

    return authorizer


# Login-only Resources ######################################################

class LoginResource(Resource):
    """ Alex S:
    Consumes a user's name and ID and adds it to the user's session.

    Related Requirements: 3.1.2.5"""

    def __init__(self, avatar):
        super().__init__()
        self.avatar = avatar

    def render_GET(self, request):
        request.getSession()
        request.session.sessionTimeout = 1200  # 10 minutes
        ns = request.session.sessionNamespaces
        ns['name'] = self.avatar['name']
        ns['id'] = self.avatar['id']
        request.redirect('/')
        request.finish()
        return NOT_DONE_YET


class LogoutResource(Resource):
    """ Alex S:
    Expires an authorized user's session."""

    @redirect_unauthorized
    def render_GET(self, request):
        request.getSession()
        request.session.expire()
        request.redirect('/')
        request.finish()
        return NOT_DONE_YET


class ContributorResource(Resource):
    """Alex S. and Christian H.:
    Authorized endpoint to which ACUs may be uploaded or deleted."""

    @staticmethod
    def post_acu(acu_name, version, classification, contributor_id, file_bytes,
                 description, request):
        request.setHeader(*http_header)
        request.write(
            enc(
                file_manager.add_def(acu_name, contributor_id, file_bytes,
                                     description, version,
                                     classification)))
        request.finish()

    @staticmethod
    def edit_acu(acu_name, version, classification, contributor_id,
                 description, mdfile, request):
        request.setHeader(*http_header)
        request.write(
            enc(
                file_manager.edit_def(acu_name, contributor_id,
                                      description, version,
                                      classification, mdfile)))
        request.finish()

    @staticmethod
    def post_error(failure, request):
        """Returns an error message to the user if upload/delete unsuccessful"""
        request.setHeader(*http_header)
        if type(failure.value) is InvalidACUError:
            request.setResponseCode(400)
            request.write(enc(failure.value.message))
        elif type(failure.value) is BadZipFile:
            request.setResponseCode(400)
            request.write(enc(failure.value.args[0]))
        elif type(failure.value) is UnauthorizedUserError:
            request.setResponseCode(403)
            request.write(enc(str(failure.value)))
        request.write(b'')
        request.finish()

    @api_credential_checker
    def render_POST(self, request):
        request.getSession()
        contributor_id = request.session.sessionNamespaces.get('id')
        try:
            # mandatory args
            acu_name = dec(request.args[b'name'][0])
            version = dec(request.args[b'version'][0])
            # classification = request.args.get(b'classification[]') or request.args.get(b'classification')
            classification = request.args.get(b'classification')[0]
            if classification is not None:
                classification = dec(classification).split(',')
            editing = request.args.get(b'edit') or [b'0']
            editing = int(editing[0].decode("utf-8"))

            md_file = ""
            if editing == 1 and request.args[b'md'][0] != b'':
                md_file = io.BytesIO(request.args[b'md'][0])

            file_bytes = ""
            if editing != 1:
                file_bytes = io.BytesIO(request.args[b'file'][0])

            description = dec(request.args[b'description'][0])

            if editing == 0:
                d = deferLater(reactor, 0, ContributorResource.post_acu, acu_name,
                               version, classification, contributor_id, file_bytes,
                               description, request)
                d.addErrback(ContributorResource.post_error, request)
            else:
                d = deferLater(reactor, 0, ContributorResource.edit_acu, acu_name,
                               version, classification, contributor_id,
                               description, md_file, request)
                d.addErrback(ContributorResource.post_error, request)
            return NOT_DONE_YET
        except KeyError as e:
            return bad_request(
                request, 'Required form parameter missing: {}'.format(e.args))

    @staticmethod
    def delete_acu(acu_name, version, contributor_id, request):
        result = file_manager.remove_def(acu_name, version, contributor_id)
        request.write(enc(json.dumps(result)))
        request.finish()

    @api_credential_checker
    def render_DELETE(self, request):
        request.getSession()
        contributor_id = request.session.sessionNamespaces.get('id')
        try:
            acu_name = dec(request.args[b'name'][0])
            version = dec(request.args[b'version'][0])
            d = deferLater(reactor, 0, ContributorResource.delete_acu, acu_name,
                           version, contributor_id, request)
            d.addErrback(ContributorResource.post_error, request)
            return NOT_DONE_YET
        except KeyError as e:
            return bad_request(
                request, 'Required query parameter missing: {}'.format(e.args))

    @api_credential_checker
    def render_PUT(self, request):
        """Allow the user to replace items for an ACU definition."""
        request.getSession()
        contributor_id = request.session.sessionNamespaces.get('id')
        try:
            name = request.args[b'name']
            if name is None:
                return bad_request(
                    request, 'Required query parameter missing: {}'.format(e.args))
            name = dec(name[0])
            if version is None:  # can only replace markdown if none
                acu = acu_database.find_acu_by_name(name)
                doc = request.args[b'doc'][0]
                return file_manager.replace_doc(name, contributor_id, request.args[b'doc'][0])
        except KeyError as e:
            return bad_request(
                request, 'Required data missing from upload: {}'.format(e.args))


class ACUForContributor(Resource):
    """Alex S:
    Gets a list of all ACU Definitions made by the authorized user."""
    @api_credential_checker
    def render_GET(self, request):
        request.getSession()
        contributor = request.session.sessionNamespaces.get('name')
        if contributor is None:
            return bad_request(request,
                               'Must be authorized to use this endpoint')
        else:
            acus = acu_database.find_acus_by_contributor_exact(contributor)
            request.setHeader(*json_header)
            return enc(json.dumps([acu_info(info) for info in acus]))


@implementer(IRealm)
class ACURealm(object):
    """Alex S:
    Stores session credentials associated with this site's domain."""

    def requestAvatar(self, avatarId, mind, *interfaces):
        if IResource in interfaces:
            login_resource = LoginResource(avatarId)
            return IResource, login_resource, lambda: None
        raise NotImplementedError()


@implementer(ICredentialsChecker)
class ACUCredentialChecker(object):
    """Alex S:
    Adds credentials to session."""

    def __init__(self):
        self.credentialInterfaces = [IUsernamePassword]

    def requestAvatarId(self, credentials):
        creds = (credentials.username.decode('utf-8'),
                 credentials.password.decode('utf-8'))
        user = acu_database.find_user_by_name_and_pw(creds[0], creds[1])
        if user is not None:
            return {'name': user.name, 'id': user.id}
        else:
            raise UnauthorizedLogin

# Anonymous User Resources ####################################################


class FetchACU(Resource):
    """Alex S:
    Resource for grabbing either ACU zips or .md files

    Related Requirements: 3.1.2.3
    """

    class Fetch(Resource):
        """Nested resource that will respond to /doc or /acu"""

        def __init__(self, name, which, version):
            super().__init__()
            self.name = name
            self.type = which
            self.version = version

        def fetcher(self, request):
            if self.name is not None and file_manager.def_exists(
                    self.name, self.version):
                if self.type == 'doc':
                    request.setHeader('Content-Type', 'text/plain')
                    request.setHeader('Content-Disposition', 'inline')
                    # return file_manager.retrieve_doc(self.name)
                    request.write(file_manager.retrieve_doc(self.name))
                elif self.type == 'acu':
                    request.setHeader('Content-Type', 'text/json')
                    request.setHeader('Content-Disposition', 'attachment; filename="{}.{}.zip"'
                                      .format(self.name, self.version))
                    # return file_manager.retrieve_def(self.name, self.version)
                    request.write(
                        file_manager.retrieve_def(self.name, self.version))
                request.finish()
            else:
                return bad_request(request, 'ACU Definition does not exist')

        def render_GET(self, request):
            deferLater(reactor, 0, self.fetcher, request)
            return NOT_DONE_YET

    def getChild(self, path, request):
        if len(request.postpath) == 1:
            name = dec(request.postpath.pop())
            path = dec(path)
            if path == 'acu':
                return FetchACU.Fetch(
                    name, 'acu', version=dec(request.args.get(b'v')[0]))
            elif path == 'doc':
                return FetchACU.Fetch(name, 'doc', version=None)
        return self

    def render_GET(self, request):
        return bad_request(request, 'The specified resource does not exist.')


class Search(Resource):
    """Alex S. Nawaf A. Eric M.:
    Consumes an HTTP request and performs database queries to search ACU index
    Related Requirements: 3.1.2.4
    """

    def render_GET(self, request):
        request.getSession()
        results = []
        query_contributor = request.args.get(enc('author'))
        request.setHeader(*json_header)
        if query_contributor is not None:
            results = [acu_info(acu_def) for contributor in query_contributor
                       for acu_def in acu_database.find_acus_by_contributor(dec(contributor))]
            # Convert ACU Definition objects to dictionaries
            request.setHeader(*json_header)
            return enc(json.dumps(results))

        query_tag = request.args.get(enc('tag'))
        if query_tag is not None:
            results = [acu_info(acu_def) for tag in query_tag
                       for acu_def in acu_database.find_acus_by_tag(dec(tag))]
            # Convert ACU Definition objects to dictionaries
            request.setHeader(*json_header)
            return enc(json.dumps(results))

        query_name = request.args.get(enc('name'))
        if query_name is not None:
            name = dec(query_name[0])
            results = [
                acu_info(acu_def)
                for acu_def in acu_database.find_acus_by_name(name)
            ]
            # acu = acu_database.find_acus_by_name(query_name)
            # # if acu is not None:
            #     results = [acu_info(acu)]
            return enc(json.dumps(results))
        return bad_request(request,
                           'Necessary query parameter missing for search')


class ACUVersions(Resource):
    """Alex S.
    Returns all versions for a given ACU name."""

    def render_GET(self, request):
        if request.args.get(b'name') is None:
            bad_request(request, 'Required query parameter "name" missing')
        versions = acu_database.find_acu_all_versions(
            dec(request.args.get(b'name')[0]))
        request.setHeader(*json_header)
        return enc(json.dumps([acu_info(info) for info in versions]))


class ACUExists(Resource):
    """Tells whether or not a given ACU name is in the index."""

    def render_GET(self, request):
        try:
            name, version = (dec(request.args[b'name'][0]),
                             dec(request.args[b'version'][0]))
            request.setHeader(*json_header)
            return enc('true' if file_manager.
                       def_exists(name, version) else 'false')
        except KeyError:
            return bad_request(
                request, 'Required query parameters name or version missing')


class CreateNewUser(Resource):
    """Create a new user account. Insufficient time to add a frontend
    component mapping to this."""

    def render_GET(self, request):
        try:
            (name, pw) = request.args[b'name'][0], request.args[b'pass']
            acu_database.find_user_by_name(dec(name))
        except KeyError as e:
            return bad_request(request, '{} missing'.format(e.args))


class Index(Resource):
    """Alex S.:
    Resource that wraps around a given Element class and performs the actual
    flattening operation on that element's renderer methods."""

    def __init__(self, *args, **kwargs):
        super().__init__()
        self.element = kwargs['element']

    def sendPage(self, result):
        request = result[0]
        request.setHeader('Content-Type', 'text/html; charset=utf-8')
        html = result[1]
        request.write(html)
        request.finish()

    def render_GET(self, request):
        d = flattenString(request, self.element)
        d.addCallback(lambda x: (request, x))
        d.addCallback(self.sendPage)
        d.addErrback(lambda e: print(e))
        return NOT_DONE_YET


class DocumentIndex(Index):
    """Alex S., Christian H:
    Renders a documentation page for a given ACU. Details are rendered statically to the page,
    requiring a database lookup each time the page is requested."""

    def __init__(self, *args, **kwargs):
        super().__init__(element=None)

    def render_GET(self, request):
        if request.args.get(b'name') is not None:
            acu_info = acu_database.find_acu_all_versions(
                dec(request.args.get(b'name')[0]))
            if acu_info is not None:
                d = flattenString(request, DocumentationPage(acu_info))
                d.addCallback(lambda x: (request, x))
                d.addCallback(super().sendPage)
                d.addErrback(lambda e: print(e))
                return NOT_DONE_YET
        request.setResponseCode(404)
        return tags.p('Content not found', class_='text-center')
        # return bad_request(request, 'requires single query parameter "name"')


class AuthorizedIndex(Index):
    """Alex S.:
    Renders the provided Element class only if the user is authorized."""

    def __init__(self, *args, **kwargs):
        super().__init__(element=kwargs['element'])

    @redirect_unauthorized
    def render_GET(self, request):
        return super().render_GET(request)


class EditIndex(Index):
    def __init__(self, *args, **kwargs):
        super().__init__(element=None)

    @redirect_unauthorized
    def render_GET(self, request):
        if request.args.get(b'name') is not None:
            acu_info = acu_database.find_acu_all_versions(
                dec(request.args.get(b'name')[0]))
            if acu_info is not None:
                d = flattenString(request, EditPage(acu_info))
                d.addCallback(lambda x: (request, x))
                d.addCallback(super().sendPage)
                d.addErrback(lambda e: print(e))
                return NOT_DONE_YET
        request.setResponseCode(404)
        return tags.p('Content not found', {'class': 'text-center'})
        # return error_response(request, 'requires single query parameter "name"')


class RootResource(Resource):
    def getChild(self, path, request):
        print(path)
        return Index(element=NotFound())


# WebSocket resources #########################################################


class CompesComunication(Resource):
    """
    Programmed by: Eric McCullough
    @ params: generic http resource
    Related Requirements: 3.4.2.1
    in HLD see File Broker
    """

    def render_POST(self, request):

        print("Message received: {}".format(request.args))
        message_content = request.args
        if b'search_request' in message_content.keys():
            print("About to search for {}".format(
                message_content[b'search_request']))
            results = [
                acu_info(acu_def) for acu_def in acu_database.
                find_acus_by_name(
                    message_content[b'search_request'][0].decode())
            ]
            return json.dumps(results).encode("utf-8")

        elif b'file_request' in message_content.keys():
            print("Fetching file for {}".format(
                message_content[b'file_request']))
            acu_file = file_manager.retrieve_def(
                message_content[b'file_request'][0].decode(), message_content[b'version'][0].decode())
            return base64.b64encode(acu_file)

        else:
            return b'invalid request'
#!/usr/local/bin/python3
"""
CONTRIBUTORS:
    Justin Culbertson-Faegre
DETAILED DESCRIPTION:
    This file is responsible for calculating the frames per second of the system.
REQUIREMENTS ADDRESSED:
    N/A
LICENSE INFORMATION:
    Copyright (c) 2019, CSC 450 Group 4
    All rights reserved.
    Redistribution and use in source and binary forms, with or without modification, are permitted provided that the
    following conditions are met:
        * Redistributions of source code must retain the above copyright notice, this list of conditions and the
          following disclaimer.
        * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and
          the following disclaimer in the documentation and/or other materials provided with the distribution.
        * Neither the name of the CSC 450 Group 4 nor the names of its contributors may be used to endorse or
          promote products derived from this software without specific prior written permission.
    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
    INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
    DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,
    OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
    DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
    STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
    EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
"""

from datetime import datetime


class FramesPerSecondMeter:
    def __init__(self):
        self.timestamp = datetime.utcnow()

    def cycle(self):
        self.last_timestamp = self.timestamp
        self.timestamp = datetime.utcnow()

        return str(1 / ((self.timestamp - self.last_timestamp).microseconds / 1000000))[:4]
#!/usr/local/bin/python3
"""
CONTRIBUTORS:
    Justin Culbertson-Faegre, Codie Orberson, Landan Ginther
DETAILED DESCRIPTION:
    This file creates all the needed default configurations and external files needed for data persistence within the
    system. This module has all needed getters and setters for all three external files. If a file is already found on
    the computer being used, the system will load the data from that file into the system instead of the default
    values. More detailed information is available in section 3.2.4 in the SDD
REQUIREMENTS ADDRESSED:
    FR.14, NFR.5, LDR.1
LICENSE INFORMATION:
    Copyright (c) 2019, CSC 450 Group 4
    All rights reserved.
    Redistribution and use in source and binary forms, with or without modification, are permitted provided that the
    following conditions are met:
        * Redistributions of source code must retain the above copyright notice, this list of conditions and the
          following disclaimer.
        * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and
          the following disclaimer in the documentation and/or other materials provided with the distribution.
        * Neither the name of the CSC 450 Group 4 nor the names of its contributors may be used to endorse or
          promote products derived from this software without specific prior written permission.
    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
    INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
    DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,
    OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
    DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
    STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
    EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
"""

from fileManager import FileManager

_default_log_values = ["   Date        Time     Command\n"]

_default_command_values = [
    "fist-palm-blink, None, None\n",
    "palm-fist-blink, None, None\n",
    "fist-blink-palm, None, None\n",
    "palm-blink-fist, None, None\n"
]

_default_configuration_values = ["0.05\n",
                                 "2\n",
                                 "5\n"
                                 ]

_configuration_index_map = {
    'open_eye_ratio': 0,
    'minimum_time_increment': 1,
    'maximum_time_increment': 2
}


def _get_configuration_index(configuration_column_name):
    return _configuration_index_map[configuration_column_name]


class DatabaseManager:
    def __init__(self):
        self.log_manager = FileManager("log.csv",
                                       _default_log_values)
        self.command_manager = FileManager("commands.csv",
                                           _default_command_values)
        self.configuration_manager = FileManager("configuration.csv",
                                                 _default_configuration_values)

    def set_gesture(self, gesture_name, now):
        self.log_manager.append_line(''.join((now.isoformat()[:10], "    ",
                                              now.isoformat()[12:19], "    ", gesture_name, " \n")))

    def set_gesture_sequence(self, gesture_sequence, now, was_recognised):
        if was_recognised:
            ending = "] recognised."
        else:
            ending = "] not recognised."

        self.log_manager.append_line(''.join((now.isoformat()[:10], "    ",
                                              now.isoformat()[
            12:19], "    ", "pattern: [",
            ", ".join(gesture_sequence), ending, " \n")))

    def set_gesture_sequence_link(self, device, device_linked, state, now):
        if device_linked:
            ending = " is now " + state + "."
        else:
            ending = " is not linked to the system. No state change will be observed."

        self.log_manager.append_line(''.join((now.isoformat()[:10], "    ",
                                              now.isoformat()[12:19], "    ", device, ending, " \n")))

    def set_gesture_sequence_error(self, output):
        self.log_manager.append_line(output)

    def get_gestures(self):
        return self.log_manager.get_lines()

    def set_command(self, gesture_sequence, command_text, device_name):
        commands = self.get_commands()
        is_registered = False
        line_index = 0

        for command in commands:
            if command["gesture_sequence"] == gesture_sequence:
                is_registered = True
                break
            else:
                line_index += 1

        gesture_sequence = '-'.join(gesture_sequence)
        line_contents = gesture_sequence + ', ' + \
            command_text + ', ' + device_name + '\n'

        if is_registered:
            self.command_manager.set_line(line_index, line_contents)
        else:
            self.command_manager.append_line(line_contents)

    def get_commands(self):
        lines = self.command_manager.get_lines()
        commands = []
        for line in lines:
            line = line.split(', ')
            commands.append({
                "gesture_sequence": line[0].split('-'),
                "command_text": line[1],
                "device_name": line[2][:-1]
            })
        return commands

    def __set_configuration__(self, column_name, value):
        self.configuration_manager.set_line(
            _get_configuration_index(column_name), str(value) + "\n")

    def __get_configuration__(self, column_name):
        return self.configuration_manager.get_line(
            _get_configuration_index(column_name))

    def set_open_eye_threshold(self, new_open_eye_ratio):
        self.__set_configuration__('open_eye_ratio', new_open_eye_ratio / 100)

    def get_open_eye_threshold(self):
        return float(self.__get_configuration__('open_eye_ratio')) * 100

    def set_minimum_time_increment(self, new_minimum_time_increment):
        self.__set_configuration__(
            'minimum_time_increment', new_minimum_time_increment)

    def get_minimum_time_increment(self):
        return float(self.__get_configuration__('minimum_time_increment'))

    def set_maximum_time_increment(self, new_maximum_time_increment):
        self.__set_configuration__(
            'maximum_time_increment', new_maximum_time_increment)

    def get_maximum_time_increment(self):
        return float(self.__get_configuration__('maximum_time_increment'))
#!/usr/local/bin/python3
"""
CONTRIBUTORS:
    Justin Culbertson-Faegre, Codie Orberson
DETAILED DESCRIPTION:
    This file is used for the detection of hand gestures within the system. This module simply loads the needed haar
    cascades and then adds the detection processes to the process manager to check for fists and palms within the
    current frame. More detailed information is available in section 3.2.10 in the SDD
REQUIREMENTS ADDRESSED:
    FR.2, FR.3, FR.10, FR.14, NFR.2, NFR.8, NFR.6, EIR.1
LICENSE INFORMATION:
    Copyright (c) 2019, CSC 450 Group 4
    All rights reserved.
    Redistribution and use in source and binary forms, with or without modification, are permitted provided that the
    following conditions are met:
        * Redistributions of source code must retain the above copyright notice, this list of conditions and the
          following disclaimer.
        * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and
          the following disclaimer in the documentation and/or other materials provided with the distribution.
        * Neither the name of the CSC 450 Group 4 nor the names of its contributors may be used to endorse or
          promote products derived from this software without specific prior written permission.
    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
    INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
    DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,
    OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
    DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
    STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
    EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
"""

from processManager import ProcessManager
from gesture import Gesture


class HandGestureDetector():
    def __init__(self):
        self.process_manager = ProcessManager()
        self.fist = Gesture("fist.xml")
        self.palm = Gesture("palm.xml")

    def detect(self, frame, flipped_frame, has_made_fist, has_made_palm):
        self.process_manager.add_process(
            self.fist.detect, (frame, flipped_frame, has_made_fist, 'fist'))
        self.process_manager.add_process(
            self.palm.detect, (frame, flipped_frame, has_made_palm, 'palm'))
        self.process_manager.on_done()
#!/usr/local/bin/python3
"""
CONTRIBUTORS:
    Justin Culbertson-Faegre, Evan Pollitt
DETAILED DESCRIPTION:
    This file creates the user inputted gesture sequence the system will compare to already configured commands. To
    begin, all gestures are added to the gestures list, which will then be lexed over to combine multiple gestures and
    ensure the gesture sequence sent to the parser is more readable and easier to compare to system commands.
    If a gesture falls within the minimum time increment (set by the administrator) from the time of the first
    recognized instance of that gesture, it will not be added into the gesture sequence. This module is also
    responsible for checking the maximum time increment for a gesture sequence to be complete and sends the current
    gesture sequence to the parser if it is above that time increment. More detailed information is
    available in section 3.2.7 in the SDD
REQUIREMENTS ADDRESSED:
    FR.3, FR.10, FR.14, NFR.7, NFR.2, NFR.6
LICENSE INFORMATION:
    Copyright (c) 2019, CSC 450 Group 4
    All rights reserved.
    Redistribution and use in source and binary forms, with or without modification, are permitted provided that the
    following conditions are met:
        * Redistributions of source code must retain the above copyright notice, this list of conditions and the
          following disclaimer.
        * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and
          the following disclaimer in the documentation and/or other materials provided with the distribution.
        * Neither the name of the CSC 450 Group 4 nor the names of its contributors may be used to endorse or
          promote products derived from this software without specific prior written permission.
    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
    INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
    DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,
    OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
    DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
    STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
    EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
"""


class GestureLexer:
    def __init__(self):
        self.gestures = []
        self.gesture_patterns = []

    def add(self, gesture_name, now):
        self.gestures.append((gesture_name, now.timestamp()))

    # Iterates over list of gestures in proper order. If a timestamp is less than current time - set max increment,
    # that gesture sequence is added to list of all sequences.
    def lex(self, now, min_increment, max_increment):
        last_dict = {'fist': None, 'palm': None, 'blink': None,
                     'left_wink': None, 'right_wink': None}

        now = now.timestamp()
        gesture_pattern = []
        for gesture in self.gestures:
            if not last_dict[gesture[0]]:
                last_dict[gesture[0]] = gesture[1]
                gesture_pattern.append(gesture[0])
            elif last_dict[gesture[0]] + min_increment < gesture[1]:
                last_dict[gesture[0]] = gesture[1]
                gesture_pattern.append(gesture[0])

        if len(self.gestures) > 0:
            if float(now) > max_increment + self.gestures[len(self.gestures) - 1][1]:
                if gesture_pattern != []:
                    self.gesture_patterns.append(gesture_pattern)
                    self.gestures = []

        current_patterns = self.gesture_patterns
        self.gesture_patterns = []

        return current_patterns
# Sound Effects by Eric Matyas,  www.soundimage.org
from playsound import playsound
from sys import argv
from os import path
import os

current_working_directory = path.dirname(os.path.realpath(__file__))
relative_path = "/"
sound_file = argv[1]
full_path = current_working_directory + relative_path + sound_file

playsound(full_path)
#!/usr/local/bin/python3
"""
CONTRIBUTORS:
    Codie Orberson, Landan Ginther, Justin Culbertson-Faegre, Danielle Bode, Evan Pollitt
DETAILED DESCRIPTION:
    This file is an instance of the GUI window. It is here that the GUI tab loads all the needed data into the
    respective tabs. This is where the video capture is set within the GUI. Here there are also callbacks for setting
    the configuration values for the system within the GUI. The system also uses this module to withdraw the GUI when
    the administrator is done configuring the system. More detailed information is available in section 3.2.2 in the SDD
REQUIREMENTS ADDRESSED:
    FR.5, FR.7, FR.12, NFR.5, EIR.1
LICENSE INFORMATION:
    Copyright (c) 2019, CSC 450 Group 4
    All rights reserved.
    Redistribution and use in source and binary forms, with or without modification, are permitted provided that the
    following conditions are met:
        * Redistributions of source code must retain the above copyright notice, this list of conditions and the
          following disclaimer.
        * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and
          the following disclaimer in the documentation and/or other materials provided with the distribution.
        * Neither the name of the CSC 450 Group 4 nor the names of its contributors may be used to endorse or
          promote products derived from this software without specific prior written permission.
    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
    INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
    DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,
    OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
    DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
    STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
    EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
"""

from tkinter import *
from tkinter import ttk
from gui_data import gui_data
from guiTab import GuiTab


# An instance of this class represents a window with multiple tabs.
class GuiWindow(Tk):
    def __init__(self, *args, **kwargs):
        Tk.__init__(self, *args, **kwargs)

    def set_initial_ear(self, initial_value):
        self.initial_ear = initial_value

    def set_initial_minimum_time_increment(self, initial_value):
        self.initial_minimum_time_increment = initial_value

    def set_initial_maximum_time_increment(self, initial_value):
        self.initial_maximum_time_increment = initial_value

    def on_ear_change(self, callback):
        self.on_ear_change = callback

    def on_minimum_time_increment_change(self, callback):
        self.on_minimum_time_increment_change = callback

    def on_maximum_time_increment_change(self, callback):
        self.on_maximum_time_increment_change = callback

    def on_new_command(self, callback):
        self.on_new_command_change = callback

    def set_cap(self, cap, settings_manager):
        self.cap = cap
        self.notebook = ttk.Notebook(width=1000, height=800)
        self.debug_tab = self.add_content(gui_data, settings_manager)

        self.notebook.grid(row=0)

    def add_content(self, body, settings_manager):
        for i in range(len(list(body.keys()))):
            page_configuration = body[list(body.keys())[i]]
            tab = GuiTab(self.notebook, self, settings_manager)

            tab.set_initial_ear(self.initial_ear)
            tab.set_initial_minimum_time_increment(
                self.initial_minimum_time_increment)
            tab.set_initial_maximum_time_increment(
                self.initial_maximum_time_increment)
            tab.set_cap(self.cap)

            tab.on_ear_change(self.on_ear_change)
            tab.on_minimum_time_increment_change(
                self.on_minimum_time_increment_change)
            tab.on_maximum_time_increment_change(
                self.on_maximum_time_increment_change)
            tab.on_new_command(self.on_new_command_change)

            tab.load_data(page_configuration['elements'])
            self.notebook.add(tab, text=page_configuration["title"])

            if tab.is_debug:
                debug_tab = tab
            if tab.is_fps:
                self.fps_tab = tab
            if tab.is_blink_label:
                self.blink_label = tab
            if tab.is_fist_label:
                self.fist_label = tab
            if tab.is_palm_label:
                self.palm_label = tab
            if tab.is_logfile:
                self.log_text = tab

        return debug_tab

    def get_debug_tab(self):
        return self.debug_tab

    def get_fps_tab(self):
        return self.fps_tab

    def get_blink_label(self):
        return self.blink_label

    def get_fist_label(self):
        return self.fist_label

    def get_palm_label(self):
        return self.palm_label

    def get_log_page(self):
        return self.log_text

    def withdraw_gui(self):
        self.withdraw()
#!/usr/local/bin/python3
"""
CONTRIBUTORS:
    Codie Orberson, Landan Ginther, Justin Culbertson-Faegre, Yutang Li
DETAILED DESCRIPTION:
    This file creates the needed content for each tab within the GUI. This file begins by loading all the needed data
    from gui_data and creating each individual item to be displayed on each tab (using the initial configuration values
    if needed) and sets all needed callbacks for buttons and option lists as well as sets the callbacks for various
    configuration changes. This file is where a majority of the error message calls live. Most of the error messages
    deal with the creation of new commands. This is also were the call for the GUI window to withdraw once the system is
    configured is housed. This file also creates functions for checking the new values of the configuration sliders
    and ensures there is not any errors made. The camera feedback is also displayed using this module. More detailed
    information is available in section 3.2.2 in the SDD
REQUIREMENTS ADDRESSED:
    FR.5, FR.7, FR.12, NFR.5, EIR.1
LICENSE INFORMATION:
    Copyright (c) 2019, CSC 450 Group 4
    All rights reserved.
    Redistribution and use in source and binary forms, with or without modification, are permitted provided that the
    following conditions are met:
        * Redistributions of source code must retain the above copyright notice, this list of conditions and the
          following disclaimer.
        * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and
          the following disclaimer in the documentation and/or other materials provided with the distribution.
        * Neither the name of the CSC 450 Group 4 nor the names of its contributors may be used to endorse or
          promote products derived from this software without specific prior written permission.
    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
    INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
    DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,
    OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
    DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
    STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
    EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
"""

from tkinter import *
from tkinter import ttk
import tkinter
from tkinter import messagebox
import PIL.Image
import PIL.ImageTk
import cv2


class GuiTab(Frame):
    def __init__(self, name, window, database_manager, *args, **kwargs):
        self.event_map = {}
        self.initial_value_map = {}

        self.window = window

        Frame.__init__(self, *args, **kwargs)
        self.is_debug = False
        self.is_fps = False
        self.is_blink_label = False
        self.is_fist_label = False
        self.is_palm_label = False
        self.is_logfile = False
        self.is_command_menu = False
        self.has_list_box = False
        self.name = name

        self.database_manager = database_manager
        self.option = 1
        self.command_index = 0
        self.is_full = 0

        self.command_links = {}
        self.new_command = {}

    def set_initial_ear(self, initial_value):
        self.initial_value_map['on_ear_change'] = initial_value

    def set_initial_minimum_time_increment(self, initial_value):
        self.initial_value_map['on_min_time_inc'] = initial_value

    def set_initial_maximum_time_increment(self, initial_value):
        self.initial_value_map['on_max_time_inc'] = initial_value

    def set_cap(self, cap):
        self.cap = cap

    def on_ear_change(self, callback):
        self.event_map['on_ear_change'] = callback

    def on_minimum_time_increment_change(self, callback):
        self.event_map['on_min_time_inc'] = callback

    def on_maximum_time_increment_change(self, callback):
        self.event_map['on_max_time_inc'] = callback

    def on_new_command(self, callback):
        self.on_new_command_change = callback

    def update_mininum_time_increment(self, val):
        val = int(val)
        if self.minimum_time_slider.get() >= val:
            self.minimum_time_slider.set(val - 1)
            self.update_slider_command(self.minimum_time_slider.get(), val)
        else:
            self.update_slider_command(None, val)

    def update_maximum_time_increment(self, val):
        val = int(val)
        if self.maximum_time_slider.get() <= val:
            self.maximum_time_slider.set(val + 1)
            self.update_slider_command(val, self.maximum_time_slider.get())
        else:
            self.update_slider_command(val, None)

    def update_slider_command(self, min_time_value, max_time_value):
        self.min_time_inc_slider_command = self.event_map["on_min_time_inc"]
        self.max_time_inc_slider_command = self.event_map["on_max_time_inc"]
        if min_time_value == None:
            self.max_time_inc_slider_command(max_time_value)
        elif max_time_value == None:
            self.min_time_inc_slider_command(min_time_value)
        else:
            self.min_time_inc_slider_command(min_time_value)
            self.max_time_inc_slider_command(max_time_value)

    def load_data(self, tab_elements):
        self.row_index = 1

        for element in tab_elements:
            if element["format"] == "text":
                column_index = 0
                body_index = list(element.keys()).index("body")
                for body in list(element.keys())[body_index:]:
                    if self.is_command_menu:
                        self.label = Label(
                            self.command_listbox, element.get(body), bg="White")
                        self.label.grid(row=self.row_index,
                                        column=column_index, padx=10, pady=10)
                        column_index += 1
                    elif self.has_list_box:
                        self.label = Label(
                            self.list_box, element.get(body), bg="White")
                        self.label.grid(row=self.row_index,
                                        column=column_index, padx=10, pady=0)
                        column_index += 1
                    else:
                        self.label = Label(self, element.get(body), bg="White")
                        self.label.grid(row=self.row_index,
                                        column=column_index, padx=10, pady=10)
                        column_index += 1

            elif element["format"] == "text-cam-status":
                text_var = StringVar()
                self.label = Label(
                    self, textvariable=text_var, font=16, bg="White")
                text_var.set("Camera On: " + str(self.cap.isOpened()))
                self.label.grid(row=self.row_index, column=0, padx=10, pady=10)

            elif element["format"] == "text-cam-fps":
                self.fps_container = StringVar()
                self.label = Label(
                    self, textvariable=self.fps_container, font=16, bg="White")
                try:
                    self.fps_container.set(
                        "FPS:       " + self.get_cam_fps(self.cap))
                except:
                    self.fps_container.set("FPS:       " + "0")
                    self.display_error_message(
                        "Camera maufunction", "There is no camera connected or it is malfunctioning, please check it.")
                    sys.exit()
                self.label.grid(row=self.row_index, column=0, padx=10, pady=10)
                self.is_fps = True

            elif element["format"] == "video":
                self.is_debug = True
                self.debug_width = 600
                self.debug_height = 400
                self.debug_canvas = Canvas(
                    self, width=self.debug_width, height=self.debug_height)

                self.debug_canvas.grid(
                    row=self.row_index, column=0, padx=10, pady=10, columnspan=5)

            elif element["format"] == "slider":
                column_index = 0
                for event in element["events"]:
                    event_name = event
                    self.slider_command = self.event_map[event_name]
                    if event_name == "on_ear_change":
                        self.ear_slider = Scale(
                            self, orient='horizontal', from_=0, to=100, command=self.slider_command)
                        # initial_ear * 100
                        self.ear_slider.set(self.initial_value_map[event_name])
                        self.ear_slider.grid(
                            row=self.row_index, column=column_index, padx=10, pady=10)
                    elif event_name == "on_min_time_inc":
                        self.minimum_time_slider = Scale(
                            self, orient='horizontal', from_=0, to=14, command=self.update_maximum_time_increment)
                        self.minimum_time_slider.set(
                            self.initial_value_map[event_name])
                        self.minimum_time_slider.grid(
                            row=self.row_index, column=column_index, padx=10, pady=10)
                    elif event_name == "on_max_time_inc":
                        self.maximum_time_slider = Scale(
                            self, orient='horizontal', from_=1, to=15, command=self.update_mininum_time_increment)
                        self.maximum_time_slider.set(
                            self.initial_value_map[event_name])
                        self.maximum_time_slider.grid(
                            row=self.row_index, column=column_index, padx=10, pady=10)

                    column_index += 1

            elif element["format"] == "gestures":
                self.gesturename = Label(
                    self, text=element["body"][0], font=16, bg="White")
                self.gesturename.grid(row=self.row_index,
                                      column=0, padx=10, pady=10)

                self.is_blink_label = True
                self.blink_label = Label(
                    self, text=element["body"][1], font=16, fg="Blue")
                self.blink_label.grid(row=self.row_index,
                                      column=1, padx=10, pady=10)

                self.is_fist_label = True
                self.fist_label = Label(
                    self, text=element["body"][2], font=16, fg="Blue")
                self.fist_label.grid(row=self.row_index,
                                     column=2, padx=10, pady=10)

                self.is_palm_label = True
                self.palm_label = Label(
                    self, text=element["body"][3], font=16, fg="Blue")
                self.palm_label.grid(row=self.row_index,
                                     column=3, padx=10, pady=10)

            elif element["format"] == "commands":
                self.is_command_menu = True

            elif element["format"] == "option":
                self.option_list = [
                    "None", "Lights", "Smart Plug", "Heater", "Air Conditioning", "Fan"]
                for option in self.database_manager.get_commands():
                    self.add_device_list_to_gui(option["gesture_sequence"][0], option["gesture_sequence"][1],
                                                option["gesture_sequence"][2], option["command_text"])

            elif element["format"] == "new":
                small_frame = LabelFrame(
                    self.command_listbox, width=1000, height=100, bd=0, bg="White")
                small_frame.grid(row=self.row_index,
                                 column=0, padx=10, pady=10)
                for x in range(1, 4):
                    self.gesture_list = ["None", "Fist", "Palm", "Blink"]
                    variable = StringVar()
                    variable.set("None")
                    self.new_command[self.command_index] = variable
                    gesture = OptionMenu(
                        small_frame, variable, *self.gesture_list, command=self.is_full_command)
                    gesture.grid(row=self.row_index,
                                 column=self.command_index, pady=10)
                    self.command_index += 1
                add_button = Button(
                    small_frame, text="Add New Command", command=self.add_new_command, bg="White")
                add_button.grid(row=self.row_index,
                                column=self.command_index + 1, pady=10)

            elif element["format"] == "logfile":
                self.is_logfile = True
                self.scroll = Scrollbar(self)
                self.scroll.grid(row=self.row_index, column=1,
                                 sticky=N + E + S + W)
                self.log_text = Text(
                    self, font=16, height=30, width=60, yscrollcommand=self.scroll.set)
                with open("./log.csv") as logfile:
                    content = logfile.readlines()
                    for line in content:
                        self.log_text.insert(INSERT, line)
                self.log_text.config(state=DISABLED)
                self.log_text.grid(row=self.row_index,
                                   column=0, padx=10, pady=10)
                self.log_text.see(END)
                self.scroll.config(command=self.log_text.yview)

            elif element["format"] == "listbox":
                if self.is_command_menu:
                    self.command_listbox = Listbox(
                        self, bd=0, height=60, width=150)
                    self.command_listbox.grid(
                        row=self.row_index, column=0, pady=10)
                else:
                    self.list_box = Listbox(self, bd=0, height=60, width=150)
                    self.list_box.grid(row=self.row_index, column=0, pady=10)
                    self.has_list_box = True

            elif element["format"] == "close_gui_button":
                self.close_button = Button(self.list_box, text="Close Administrator Window",
                                           command=self.close_gui_window)
                self.close_button.grid(row=self.row_index, column=0)

            self.row_index += 1

    def __bgr_to_rgb__(self, frame):
        return frame[..., [2, 1, 0]]

    def add_device_list_to_gui(self, gesture1, gesture2, gesture3, command):
        small_frame = LabelFrame(self.command_listbox,
                                 width=1000, height=100, bd=0, bg="White")
        small_frame.grid(row=self.row_index, column=0, padx=10, pady=10)
        text = {"text": "Command " + str(self.option) + " (" + gesture1.capitalize() + ", " +
                        gesture2.capitalize() + ", " + gesture3.capitalize() + ")"}
        self.label = Label(small_frame, text, bg="White")
        self.label.grid(row=self.row_index, column=0, padx=10, pady=10)
        variable = StringVar()
        variable.set(command)
        self.command_links[self.option] = variable
        self.optionMenu = OptionMenu(
            small_frame, variable, *self.option_list, command=self.set_value)
        self.optionMenu.grid(row=self.row_index, column=1,
                             padx=10, pady=10, columnspan=100)
        self.optionMenu.config(width=30)
        self.option += 1
        self.row_index += 1

    def set_value(self, value):
        for option in self.database_manager.get_commands():
            if value == option["command_text"] and value != "None":
                self.display_error_message("Smart Home Device Linked",
                                           "This smart home device has already been linked to "
                                           "another command. Please chose a different device "
                                           "for this command.")
                return

        count = 1
        for option in self.database_manager.get_commands():
            device = None

            if self.command_links[count].get() == "Heater" or self.command_links[count].get() == "Air Conditioning":
                device = "Nest"
            else:
                device = "Alexa"

            self.database_manager.set_command([option["gesture_sequence"][0], option["gesture_sequence"][1],
                                               option["gesture_sequence"][2]], self.command_links[count].get(), device)
            count += 1

    def is_full_command(self, value):
        if value != "None":
            self.is_full += 1

    def add_new_command(self):
        does_not_exist = self.check_new_command()
        if self.option > 8:
            self.display_error_message("Command Maximum Reached", "The system can only house 8 commands. "
                                                                  "You have reached the maximum allowed commands.")
            return

        if self.is_full >= 3:
            if does_not_exist:
                if self.new_command[0].get() != self.new_command[1].get() and self.new_command[1].get() != \
                        self.new_command[2].get():
                    self.add_device_list_to_gui(self.new_command[0].get(), self.new_command[1].get(),
                                                self.new_command[2].get(), "None")
                    self.database_manager.set_command(
                        [self.new_command[0].get().lower(), self.new_command[1].get().lower(),
                         self.new_command[2].get().lower()], "None", "None")
                else:
                    self.display_error_message("Incorrect Command",
                                               "Commands may not have identical gestures in a successive order.")
        else:
            self.display_error_message(
                "No Command Created", "Please chose three gestures to create a full command.")

        self.is_full = 0

    def check_new_command(self):
        is_not_equal = True
        for option in self.database_manager.get_commands():
            if "".join(option["gesture_sequence"]) == "".join((self.new_command[0].get().lower(),
                                                               self.new_command[1].get(
            ).lower(),
                    self.new_command[2].get().lower())):
                is_not_equal = False

        if not is_not_equal:
            self.display_error_message("Command Exists", "This command is already created "
                                                         "within the system. Please create a new, unique command.")

        return is_not_equal

    def set_fps(self, fps):
        self.fps_container.set("FPS:       " + str(fps))

    def __frame_to_image__(self, frame):
        return PIL.ImageTk.PhotoImage(image=PIL.Image.fromarray(frame))

    def __display_image__(self, image):
        self.image = image
        self.debug_canvas.create_image(
            0, 0, image=self.image, anchor=tkinter.NW)

    def set_debug_frame(self, frame):
        self.__display_image__(
            self.__frame_to_image__(self.__bgr_to_rgb__(frame)))

    def get_cam_fps(self, cap):
        while cap.isOpened():
            return str(cap.get(cv2.CAP_PROP_FPS))

    def display_error_message(self, title, text):
        messagebox.showerror(title, text)

    # This code, as written, cannot display two simultaneous gestures.
    def set_gesture_background(self, gesture_detected):
        if gesture_detected == "fist":
            self.fist_label.configure(bg="Black")
            self.palm_label.configure(bg="White")
            self.blink_label.configure(bg="White")
        elif gesture_detected == "palm":
            self.palm_label.configure(bg="Black")
            self.fist_label.configure(bg="White")
            self.blink_label.configure(bg="White")
        elif gesture_detected == "blink":
            self.blink_label.configure(bg="Black")
            self.fist_label.configure(bg="White")
            self.palm_label.configure(bg="White")
        else:
            self.fist_label.configure(bg="White")
            self.palm_label.configure(bg="White")
            self.blink_label.configure(bg="White")

    def close_gui_window(self):
        self.window.withdraw_gui()
#!/usr/local/bin/python3
"""
CONTRIBUTORS:
    Justin Culbertson-Faegre, Codie Orberson
DETAILED DESCRIPTION:
    This file is responsible for adding the perimeters to the gestures being detected. This is also where the system
    checks a flipped frame from the camera in order to recognize gestures from the users left hand. This is also where
    the system loads in the haar cascades used to detect the hand gestures.
REQUIREMENTS ADDRESSED:
    FR.2, FR.3, FR.14, NFR.2, NFR.6
LICENSE INFORMATION:
    Copyright (c) 2019, CSC 450 Group 4
    All rights reserved.
    Redistribution and use in source and binary forms, with or without modification, are permitted provided that the
    following conditions are met:
        * Redistributions of source code must retain the above copyright notice, this list of conditions and the
          following disclaimer.
        * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and
          the following disclaimer in the documentation and/or other materials provided with the distribution.
        * Neither the name of the CSC 450 Group 4 nor the names of its contributors may be used to endorse or
          promote products derived from this software without specific prior written permission.
    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
    INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
    DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,
    OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
    DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
    STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
    EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
"""

import cv2


class Gesture:
    def __init__(self, haar_cascade_xml,
                 detection_check=lambda detected_gestures: len(
                     detected_gestures) > 0,
                 debug_color=(0, 0, 255)):
        self.haar_cascade = cv2.CascadeClassifier(haar_cascade_xml)
        self.detection_check = detection_check
        self.debug_color = debug_color

    def set_debug_color(self, rgb_tuple):
        self.debug_color = rgb_tuple

    def set_detection_criteria(self, detection_check):
        self.detection_check = detection_check

    def detect(self, frame, flipped_frame, multithreaded_perimeter, hand_gesture):
        gesture = self.haar_cascade.detectMultiScale(frame, 1.3, 5)
        flipped_gesture = self.haar_cascade.detectMultiScale(
            flipped_frame, 1.3, 5)
        if self.detection_check(gesture):
            multithreaded_perimeter.set(gesture[0])
        elif self.detection_check(flipped_gesture):
            if hand_gesture == 'fist':
                flipped_gesture = self.detect_flipped_gesture(
                    flipped_gesture, 550)
                multithreaded_perimeter.set(flipped_gesture[0])
            elif hand_gesture == 'palm':
                flipped_gesture = self.detect_flipped_gesture(
                    flipped_gesture, 500)
                multithreaded_perimeter.set(flipped_gesture[0])

    def detect_flipped_gesture(self, flipped_gesture, size):
        flipped_gesture[0][0] = size - flipped_gesture[0][0]
        return flipped_gesture
from multiprocessing import Value


class MultithreadedPerimeter():
    def __init__(self):
        self.x1 = Value('I', 0)
        self.y1 = Value('I', 0)
        self.x2 = Value('I', 0)
        self.y2 = Value('I', 0)

    def get_top_corner(self):
        return (self.x1.value, self.y1.value)

    def get_bottom_corner(self):
        return (self.x2.value, self.y2.value)

    def get_ratio(self):
        if(self.x1.value != self.x2.value):
            return (self.y2.value - self.y1.value) / (self.x2.value - self.x1.value)
        else:
            return 1

    def set(self, x_y_w_h_tuple):
        self.x1.value = x_y_w_h_tuple[0]
        self.y1.value = x_y_w_h_tuple[1]
        self.x2.value = x_y_w_h_tuple[0] + x_y_w_h_tuple[2]
        self.y2.value = x_y_w_h_tuple[1] + x_y_w_h_tuple[3]

    def is_set(self):
        return bool(self.x2.value > 0)
#!/usr/local/bin/python3
"""
CONTRIBUTORS:
    Codie Orberson, Landan Ginther, Justin Culbertson-Faegre, Danielle Bode, Yutang Li
DETAILED DESCRIPTION:
    This file is responsible for detecting eye blinks. This file loads the eye.dat file used for facial recognition into
    the system. This file also calculates the eye aspect ratio used to set the sensitivity for detecting eye blinks.
    This file is also responsible for setting the perimeters for the rectangles on the eyes within the Debug tab. More
    detailed information is available in section 3.2.9 in the SDD
REQUIREMENTS ADDRESSED:
    FR.1, FR.3, FR.8, FR.14, NFR.2, NFR.8, NFR.6, OR.1
LICENSE INFORMATION:
    Copyright (c) 2019, CSC 450 Group 4
    All rights reserved.
    Redistribution and use in source and binary forms, with or without modification, are permitted provided that the
    following conditions are met:
        * Redistributions of source code must retain the above copyright notice, this list of conditions and the
          following disclaimer.
        * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and
          the following disclaimer in the documentation and/or other materials provided with the distribution.
        * Neither the name of the CSC 450 Group 4 nor the names of its contributors may be used to endorse or
          promote products derived from this software without specific prior written permission.
    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
    INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
    DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,
    OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
    DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
    STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
    EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
"""

import cv2
import dlib
from imutils import face_utils


class BlinkDetector:

    def __init__(self, ear_thresh=0.2, ear_consec_frame=2, ear=None):
        self.detector = dlib.get_frontal_face_detector()
        self.predictor = dlib.shape_predictor('eye.dat')
        self.ear_thresh = ear_thresh
        self.ear_consec_frame = ear_consec_frame
        self.ear = ear

    def detect(self, frame, left_eye_perimeter, right_eye_perimeter):
        # grab the indexes of the facial landmarks for the left and
        # right eye, respectively
        (lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS["left_eye"]
        (rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS["right_eye"]

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        # detect faces in the grayscale frame
        faces = self.detector(gray, 0)
        try:
            # loop over the face detections
            for face in faces:
                # determine the facial landmarks for the face region, then
                # convert the facial landmark (x, y)-coordinates to a NumPy
                # array
                shape = self.predictor(gray, face)
                shape = face_utils.shape_to_np(shape)

                # extract the left and right eye coordinates, then use the
                # coordinates to compute the eye aspect ratio for both eyes
                leftEye = shape[lStart:lEnd]
                rightEye = shape[rStart:rEnd]

                leftEyeHull = cv2.convexHull(leftEye)
                rightEyeHull = cv2.convexHull(rightEye)

                x = int(leftEyeHull[3][0][0])
                width = int(leftEyeHull[0][0][0]) - x
                y = int((leftEyeHull[1][0][1] + leftEyeHull[2][0][1]) / 2)

                if len(leftEyeHull) > 5:
                    height = y - \
                        int((leftEyeHull[4][0][1] + leftEyeHull[5][0][1]) / 2)
                else:
                    height = 0

                y = y - height
                left_eye_perimeter.set((x, y, width, height))

                x = int(rightEyeHull[3][0][0])
                width = int(rightEyeHull[0][0][0]) - x
                y = int((rightEyeHull[1][0][1] + rightEyeHull[2][0][1]) / 2)

                if len(rightEyeHull) > 5:
                    height = y - \
                        int((rightEyeHull[4][0][1] +
                             rightEyeHull[5][0][1]) / 2)
                else:
                    height = 0

                y = y - height
                right_eye_perimeter.set((x, y, width, height))

        except:
            # handle event when eyes are close to the edge of the screen
            left_eye_perimeter.set((0, 0, 0, 0))
            right_eye_perimeter.set((0, 0, 0, 0))
#!/usr/local/bin/python3
"""
CONTRIBUTORS:
    Justin Culbertson-Faegre, Codie Orberson, Landan Ginther
DETAILED DESCRIPTION:
    This file is responsible for logging the detected gestures and gesture sequences onto the console. The logger also
    logs information to the console on whether or not a smart home device was actually contacted by the system. More
    detailed information is available in section 3.2.5 in the SDD
REQUIREMENTS ADDRESSED:
    FR.10, LDR.1
LICENSE INFORMATION:
    Copyright (c) 2019, CSC 450 Group 4
    All rights reserved.
    Redistribution and use in source and binary forms, with or without modification, are permitted provided that the
    following conditions are met:
        * Redistributions of source code must retain the above copyright notice, this list of conditions and the
          following disclaimer.
        * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and
          the following disclaimer in the documentation and/or other materials provided with the distribution.
        * Neither the name of the CSC 450 Group 4 nor the names of its contributors may be used to endorse or
          promote products derived from this software without specific prior written permission.
    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
    INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
    DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,
    OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
    DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
    STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
    EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
"""

import os


class Logger:
    def __init__(self):
        self.output = ""
        exists = os.path.exists("logfile.txt")
        if not exists:
            self.file = open("logfile.txt", 'w+')
            self.file.write("   Date        Time     Command\n")
            print("   Date        Time     Command\n")
        else:
            self.file = open("logfile.txt", "a+")

    def log(self, output):
        self.__init__()
        self.output = output
        self.file.write(output)
        print(output)

    def get_output(self):
        return self.output

    def log_gesture(self, gesture_name, now):
        self.log(''.join((now.isoformat()[:10], "    ", now.isoformat()[12:19],
                          "    ", gesture_name, " \n")))

    def log_gesture_sequence(self, gesture_sequence, now, was_recognised):
        if was_recognised:
            ending = "] recognised"
        else:
            ending = "] not recognised"

        self.log_gesture(
            "pattern: [" + ', '.join(gesture_sequence) + ending, now)

    def log_device_state_change(self, device, device_linked, state, now):
        if device_linked:
            ending = " is now " + state + "."
        else:
            ending = " is not linked to the system. No state change will be observed."

        self.log_gesture(device + ending, now)

    def get_output(self):
        return self.output

    def close(self):
        self.file.seek(0)
        self.file.close()
        os.remove("logfile.txt")
#!/usr/local/bin/python3
"""
CONTRIBUTORS:
    Justin Culbertson-Faegre, Codie Orberson
DETAILED DESCRIPTION:
    This file creates and regulates the processes of the system. If the system is on Linux, the multiprocessing is used.
    If the system is on any other operating system, it will use synchronous processes to complete actions. More detailed
    information is available in section 3.2.11 in the SDD
REQUIREMENTS ADDRESSED:
    NFR.7, NFR.9
LICENSE INFORMATION:
    Copyright (c) 2019, CSC 450 Group 4
    All rights reserved.
    Redistribution and use in source and binary forms, with or without modification, are permitted provided that the
    following conditions are met:
        * Redistributions of source code must retain the above copyright notice, this list of conditions and the
          following disclaimer.
        * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and
          the following disclaimer in the documentation and/or other materials provided with the distribution.
        * Neither the name of the CSC 450 Group 4 nor the names of its contributors may be used to endorse or
          promote products derived from this software without specific prior written permission.
    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
    INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
    DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,
    OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
    DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
    STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
    EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
"""

import multiprocessing
from multiprocessing import Process
import platform


class SynchronousProcess:
    def __init__(self, target=None, args=None):
        if args:
            target(*args)
        else:
            target()

    def start(self):
        pass

    def join(self):
        pass


if platform.system() == 'Linux':
    # On Linux, we use multiprocessing.
    ProcessConstructor = Process
else:
    # On Windows, we use the previously defined kludge.
    ProcessConstructor = SynchronousProcess


class ProcessManager:
    def __init__(self):
        self.processes = []

    def add_process(self, callback, arguments=None):
        if arguments:
            if not isinstance(arguments, tuple):
                arguments = (arguments, )
            self.process = ProcessConstructor(target=callback, args=arguments)
        else:
            self.process = ProcessConstructor(target=callback)

        self.processes.append(self.process)
        self.process.start()

    def on_done(self, callback=None):
        for self.process in self.processes:
            self.process.join()
        self.processes = []
        if callback:
            callback()
#!/usr/local/bin/python3
"""
CONTRIBUTORS:
    Justin Culbertson-Faegre, Codie Orberson, Landan Ginther
DETAILED DESCRIPTION:
    This file creates an interface for combining the detection of eye blinks and hand gestures. It starts by creating
    instances of the needed subcomponents and then sets up the system to begin drawing the red rectangles within the
    debug tab. Once everything is set up correctly, the system can then begin calling the detect method to reset the
    perimeters for the rectangles, detect the various gestures (including the left hand) and eye blinks, and triggering
    the linked events for those gestures. Once it recognizes a gesture, it begins to draw the rectangles that are shown
    in the debug tab. More detailed information is available in section 3.2.2 in the SDD
REQUIREMENTS ADDRESSED:
    FR.1, FR.2, FR.3, FR.8, FR.14, NFR.2, NFR.5, NFR.6, EIR.1, OR.1
LICENSE INFORMATION:
    Copyright (c) 2019, CSC 450 Group 4
    All rights reserved.
    Redistribution and use in source and binary forms, with or without modification, are permitted provided that the
    following conditions are met:
        * Redistributions of source code must retain the above copyright notice, this list of conditions and the
          following disclaimer.
        * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and
          the following disclaimer in the documentation and/or other materials provided with the distribution.
        * Neither the name of the CSC 450 Group 4 nor the names of its contributors may be used to endorse or
          promote products derived from this software without specific prior written permission.
    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
    INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
    DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,
    OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
    DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
    STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
    EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
"""

import cv2
import imutils
from multithreadedPerimeter import MultithreadedPerimeter
from processManager import ProcessManager
from gesture import Gesture
from handGestureDetector import HandGestureDetector
from blinkDetector import BlinkDetector


class GestureDetector:
    def __init__(self):
        self.__set_up_helpers__()
        self.__set_up_perimeters__()
        self.gesture_events = []
        self.gesture_detected = None

    def on_gesture(self, callback):
        self.gesture_events.append(callback)

    def get_gesture_detected(self):
        return self.gesture_detected

    # Method is to be run in separate thread
    def detect(self, frame, timestamp, open_eye_threshold):
        self.__reset_perimeters__()
        self.__detect_shapes__(frame)
        self.__trigger_events__(timestamp, open_eye_threshold)
        return self.__draw_rectangles__(frame)

    def __detect_shapes__(self, frame):
        self.process_manager.add_process(
            self.hand_gesture_detector.detect, (frame, self.flip_frame(frame), self.fist_perimeter, self.palm_perimeter))

        self.blink_detector.detect(
            frame, self.left_eye_perimeter, self.right_eye_perimeter)

        self.process_manager.on_done()

    def __trigger_events__(self, timestamp, open_eye_threshold):
        self.gesture_detected = None

        self.__trigger_hand_events__(self.fist_perimeter, 'fist', timestamp)
        self.__trigger_hand_events__(self.palm_perimeter, 'palm', timestamp)
        self.__trigger_blink_events__(timestamp, open_eye_threshold)

    def __trigger_hand_events__(self, perimeter, gesture_name, timestamp):
        if perimeter.is_set():
            self.gesture_detected = gesture_name
            for event in self.gesture_events:
                event(gesture_name, timestamp)

    def __trigger_blink_events__(self, timestamp, open_eye_threshold):
        if self.left_eye_perimeter.is_set() and self.right_eye_perimeter.is_set():
            if open_eye_threshold / 100 > (
                    self.left_eye_perimeter.get_ratio() + self.right_eye_perimeter.get_ratio()) / 2:
                self.gesture_detected = "blink"

                for event in self.gesture_events:
                    event('blink', timestamp)

    def __draw_rectangles__(self, frame):
        for perimeter in self.perimeters:
            if perimeter.is_set():
                cv2.rectangle(frame, perimeter.get_top_corner(),
                              perimeter.get_bottom_corner(), (0, 0, 255), 2)

        return frame

    def __reset_perimeters__(self):
        for perimeter in self.perimeters:
            perimeter.set((0, 0, 0, 0))

    def __set_up_helpers__(self):
        self.process_manager = ProcessManager()
        self.hand_gesture_detector = HandGestureDetector()
        self.blink_detector = BlinkDetector()

    def __set_up_perimeters__(self):
        self.fist_perimeter = MultithreadedPerimeter()
        self.palm_perimeter = MultithreadedPerimeter()
        self.left_eye_perimeter = MultithreadedPerimeter()
        self.right_eye_perimeter = MultithreadedPerimeter()

        self.perimeters = [
            self.fist_perimeter,
            self.palm_perimeter,
            self.left_eye_perimeter,
            self.right_eye_perimeter
        ]

    def flip_frame(self, frame):
        frame = cv2.flip(frame, flipCode=1)
        return frame
#!/usr/local/bin/python3
"""
CONTRIBUTORS:
    Justin Culbertson-Faegre
DETAILED DESCRIPTION:
    This file creates an interface for the NVSHR system to execute subprocesses that have been created and also allows
    the system to clean those processes up.
REQUIREMENTS ADDRESSED:
    NFR.7, NFR.9
LICENSE INFORMATION:
    Copyright (c) 2019, CSC 450 Group 4
    All rights reserved.
    Redistribution and use in source and binary forms, with or without modification, are permitted provided that the
    following conditions are met:
        * Redistributions of source code must retain the above copyright notice, this list of conditions and the
          following disclaimer.
        * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and
          the following disclaimer in the documentation and/or other materials provided with the distribution.
        * Neither the name of the CSC 450 Group 4 nor the names of its contributors may be used to endorse or
          promote products derived from this software without specific prior written permission.
    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
    INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
    DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,
    OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
    DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
    STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
    EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
"""

from subprocess import Popen


class SubprocessExecutor:
    def __init__(self):
        self.subprocesses = []

    def execute(self, file_name, argument):
        self.__clean_up_subprocesses__()
        self.subprocesses.append(Popen(['python3', file_name, argument]))

    def __clean_up_subprocesses__(self):
        running_subprocesses = []
        for subprocess in self.subprocesses:
            if subprocess.poll() is None:
                running_subprocesses.append(subprocess)
            else:
                subprocess.terminate()
        self.subprocesses = running_subprocesses
#!/usr/local/bin/python3
"""
CONTRIBUTORS:
    Codie Orberson, Landan Ginther, Justin Culbertson-Faegre, Danielle Bode, Evan Pollitt
DETAILED DESCRIPTION:
    This file is responsible for recognizing user inputted sequences as commands. All valid sequences are loaded into
    the gesture parser map on start up and related events are added into the events list. When the parser is sent a
    sequence (or sequences) from the lexer, the parser joins the list of gestures into one string and then checks to see
    if the full sequence or a portion of the sequence is housed within the system. Because the system is designed with
    disabled users in mind, the parser recognizes the first subset within the sequence to create an ease of use. More
    detailed information is available in section 3.2.6 in the SDD
REQUIREMENTS ADDRESSED:
    FR.3, FR.10, FR.14, NFR.7, NFR.2, NFR.6
LICENSE INFORMATION:
    Copyright (c) 2019, CSC 450 Group 4
    All rights reserved.
    Redistribution and use in source and binary forms, with or without modification, are permitted provided that the
    following conditions are met:
        * Redistributions of source code must retain the above copyright notice, this list of conditions and the
          following disclaimer.
        * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and
          the following disclaimer in the documentation and/or other materials provided with the distribution.
        * Neither the name of the CSC 450 Group 4 nor the names of its contributors may be used to endorse or
          promote products derived from this software without specific prior written permission.
    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
    INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
    DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,
    OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
    DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
    STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
    EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
"""


class GestureParser:
    def __init__(self):
        self.gesture_pattern_map = {}
        self.gesture_sequence_events = []

    def add_pattern(self, gestures):
        self.gesture_pattern_map["-".join(gestures)] = True

    def on_gesture_sequence(self, event):
        self.gesture_sequence_events.append(event)

    def parse_pattern(self, gesture_sequence, now):
        joined_gesture_sequence = "-".join(gesture_sequence)
        was_recognised = joined_gesture_sequence in self.gesture_pattern_map

        if not was_recognised:
            for valid_gesture_sequence in self.gesture_pattern_map.keys():
                if valid_gesture_sequence in joined_gesture_sequence:
                    gesture_sequence = valid_gesture_sequence.split("-")
                    was_recognised = True
                    break

        for event in self.gesture_sequence_events:
            event(gesture_sequence, now, was_recognised)

    def parse_patterns(self, gesture_patterns, now):
        for gesture_pattern in gesture_patterns:
            self.parse_pattern(gesture_pattern, now)
#!/usr/local/bin/python3
"""
CONTRIBUTORS:
    Justin Culbertson-Faegre
DETAILED DESCRIPTION:
    This file creates an interface for the playing of the NVSHR confirm and failure sounds.
REQUIREMENTS ADDRESSED:
    FR.10, EIR.3
LICENSE INFORMATION:
    Copyright (c) 2019, CSC 450 Group 4
    All rights reserved.
    Redistribution and use in source and binary forms, with or without modification, are permitted provided that the
    following conditions are met:
        * Redistributions of source code must retain the above copyright notice, this list of conditions and the
          following disclaimer.
        * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and
          the following disclaimer in the documentation and/or other materials provided with the distribution.
        * Neither the name of the CSC 450 Group 4 nor the names of its contributors may be used to endorse or
          promote products derived from this software without specific prior written permission.
    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
    INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
    DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,
    OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
    DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
    STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
    EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
"""

from subprocessExecutor import SubprocessExecutor
from playsound import playsound
from platform import system


class SoundPlayer:
    def __init__(self):
        self.subprocess_executor = SubprocessExecutor()
        self.is_linux = system() == 'Linux'

    def play_success_sound(self):
        self.__play_file__('Success.wav')

    def play_failure_sound(self):
        self.__play_file__('Failure.wav')

    def __play_file__(self, file_name):
        if self.is_linux:
            self.subprocess_executor.execute('./play_file.py', file_name)
        else:
            playsound(file_name, False)
# Define the elements to be laid out on each tab
gui_data = {
    "tab1": {"title": "Instructions",
             "elements": [
                 {
                     "format": "listbox"
                 },
                 {
                     "format": "text",
                     "body":
                         {
                             "text": "Welcome to the Non-Verbal Smart Home Recognition (NVSHR) System!",
                             "font": ("Helvetica", 14, "bold"),
                             "justify": "center"
                         }
                 },
                 {
                     "format": "text",
                     "body":
                         {
                             "text": "The NVSHR system is a system created with the purpose of using "
                                     "non-verbal communication to control smart "
                                     "home devices with the help of hand gestures and blink detection. As a system "
                                     "administrator there are a few things that need to be initialized before the "
                                     "NVSHR system can be used properly. Please follow the steps below to ensure the "
                                     "user has the best"
                                     " experience using this system.",
                             "width": 120,
                             "height": 4,
                             "wraplength": 800,
                             "justify": "center",

                             "font": ("Helevetica", 10, "italic")
                         }
                 },
                 {
                     "format": "text",
                     "body":
                         {
                             "text": "Before any commands are linked to a specific smart home action, the NVSHR system "
                                     "will not "
                                     "be able to make any state changes to the users smart home."
                                     "However, it will be able to recognize these commands. \nTo link commands with smart "
                                     "home actions:"
                                     "\n\n"
                                     "1. Navigate to the Command tab above."
                                     "\n\n"
                                     "2. Once in the Command tab, you will see a list of all available commands and their"
                                     " descriptions (Please take note of the gesture sequence for each command). You are "
                                     "also able to create new commands from this same tab. Instructions for creating these "
                                     "new commands is housed within this tab."
                                     "\n\n"
                                     "3. Choose a smart home device from the drop down menu below each command to link that "
                                     "device with the above command. If you do not wish to use a command, please choose the "
                                     "None option from the drop down menu. Each smart home device is only able to linked to "
                                     "one unique command, so be sure to chose command linking wisely."
                                     "\n\n"
                                     "Once each command you wish to use has been linked, navigate to the Debug tab above. "
                                     "Within this tab "
                                     "you will be able to view the live feedback from the connected camera as well as make "
                                     "some changes to that feedback for better processing within the system."
                                     "\n\n"
                                     "1. Each of the sliders lets you configure the system to the right specifications. "
                                     "The Eye Aspect Ratio (EAR) slider can be used to set the threshold for blink "
                                     "detection. The Low and High Contrast sliders allow you to change the contrast on "
                                     "the frame to improve the systems ability to recognize hand gestures if you aren't "
                                     "getting the results you expect. You also able to set how long the system should "
                                     "wait to register a command and what the shortest amount of time between unique "
                                     "gestures should be."
                                     "\n\n"
                                     "2. The Frames Per Second (FPS) provides information about the number of frames being processed "
                                     "within the system per second."
                                     "\n\n"
                                     "3. If the connected camera can be reached by the system, the Camera value will be set to true. "
                                     "If there is no feedback or this value is false, the connected camera is not being used properly "
                                     "by the system."
                                     "\n\n"
                                     "4. This page will also display the current gesture being processed. Please use this feature to "
                                     "ensure all gestures can be recognized by the system. This tab can also be used to test the "
                                     "previously linked commands."
                                     "\n\n"
                                     "Once all of the previous steps have been completed, the system will be ready for the user. "
                                     "If at anytime the system is not properly recognizing commands, the Log tab can be used to "
                                     "view previous gestures and commands. Feel free to use this tab to ensure that the linked "
                                     "commands are being recognized properly as well. Once you have completed the configuration "
                                     "process, simply press the button below to withdraw the window to prepare the system for "
                                     "actual users.",
                             "width": 120,
                             "height": 35,
                             "wraplength": 800,
                             "justify": "center",
                             "font": ("Helevetica", 10)
                         }
                 },
                 {
                     "format": "text",
                     "body":
                         {
                             "text": "Thank you for using the Non-Verbal Smart Home Recognition (NVSHR) System!",
                             "width": 120,
                             "height": 2,
                             "wraplength": 800,
                             "justify": "center",
                             "anchor": "center",
                             "font": ("Helevetica", 12, "italic")
                         }
                 },
                 {
                     "format": "close_gui_button"
                 }
             ]
             },
    "tab2": {"title": "Debug",
             "elements": [
                 {
                     "format": "video"
                 },
                 {
                     "format": "text",
                     "multicolumn": "true",
                     "body": {"text": "Set the EAR:"},
                     "body2": {"text": "Set the Minimum Time:"},
                     "body3": {"text": "Set the Maximum Time:"}
                 },
                 {
                     "format": "slider",

                     "events": ["on_ear_change", "on_min_time_inc",  "on_max_time_inc"]

                 },
                 {
                     "format": "text-cam-status"
                 },
                 {
                     "format": "text-cam-fps",
                 },
                 {
                     "format": "gestures",
                     "body": ["Current Gesture", "Blink", "Fist", "Palm"]
                 }
             ]
             },
    "tab3": {"title": "Commands",
             "elements": [
                 {
                     "format": "commands"
                 },
                 {
                     "format": "listbox"
                 },
                 {
                     "format": "text",
                     "body":
                         {
                             "text": "Command Menu",
                             "wraplength": 1000,
                             "justify": "center",
                             "font": ("Helvetica", 20, "bold")
                         }
                 },
                 {
                     "format": "text",
                     "body":
                         {
                             "text": "The following commands have been created for initial use and are ready to be "
                                     "used within the system. Before you use them, please link them to the desired "
                                     "smart home action. To create a new command, fill out all three fields below "
                                     "and press the ADD button "
                                     "to add it to the list below. Commands may not have the one gesture followed "
                                     "immediately by that same gesture (i.e. FIST, FIST, BLINK is not a valid command). "
                                     "Once it is added, make sure it is linked to the "
                                     "correct smart home device.",
                             "width": 120,
                             "height": 5,
                             "wraplength": 800,
                             "justify": "center"
                         }
                 },
                 {
                     "format": "new"
                 },
                 {
                     "format": "option"
                 }
             ]
             },
    "tab4": {"title": "Log",
             "elements": [
                 {"format": "logfile"}
             ]
             }
}
#!/usr/local/bin/python3
"""
CONTRIBUTORS:
    Codie Orberson, Landan Ginther
DETAILED DESCRIPTION:
    This file creates an interface between the NVSHR system and the TPLink smart plugs. (The IP Addresses are hard coded
    within the system currently.) This module has the ability to check the status of the smart plug (whether it is on
    or off) and changes that state based on the command inputted by the user. If the current device is not 'Lights' or
    'Smart Plug' it simply logs the output to the console. More detail information can be found in Section 3.2.3 within
    the SDD.
REQUIREMENTS ADDRESSED:
    FR.5, FR.7, FR.10, FR.12
LICENSE INFORMATION:
    Copyright (c) 2019, CSC 450 Group 4
    All rights reserved.
    Redistribution and use in source and binary forms, with or without modification, are permitted provided that the
    following conditions are met:
        * Redistributions of source code must retain the above copyright notice, this list of conditions and the
          following disclaimer.
        * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and
          the following disclaimer in the documentation and/or other materials provided with the distribution.
        * Neither the name of the CSC 450 Group 4 nor the names of its contributors may be used to endorse or
          promote products derived from this software without specific prior written permission.
    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
    INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
    DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,
    OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
    DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
    STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
    EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
"""

from pyHS100 import SmartPlug
from datetime import datetime
import time


class TPLinkDevice():
    def __init__(self):
        self.light_Plug = SmartPlug("192.168.43.236")
        time.sleep(1.2)
        self.fan_Plug = SmartPlug("192.168.43.37")
        self.logger = None
        self.log_manager = None

    def set_log_manager(self, log_manager, logger):
        self.log_manager = log_manager
        self.logger = logger

    def turn_on_off(self, device):
        if device == 'Lights':  # Change gesture sequence to default value
            if self.light_Plug.state == "OFF":
                self.light_Plug.turn_on()
            else:
                self.light_Plug.turn_off()
            self.log_manager.set_gesture_sequence_link(
                "Lights", True, self.light_Plug.state.lower(), datetime.utcnow())
            self.logger.log_device_state_change(
                "Lights", True, self.light_Plug.state.lower(), datetime.utcnow())

        elif device == 'Smart Plug':  # Change gesture sequence to default value
            if self.fan_Plug.state == "OFF":
                self.fan_Plug.turn_on()
            else:
                self.fan_Plug.turn_off()
            self.log_manager.set_gesture_sequence_link("Smart Plug", True, self.light_Plug.state.lower(),
                                                       datetime.utcnow())
            self.logger.log_device_state_change(
                "Smart Plug", True, self.light_Plug.state.lower(), datetime.utcnow())

        else:
            self.log_manager.set_gesture_sequence_link(device, False, "off",
                                                       datetime.utcnow())
            self.logger.log_device_state_change(
                device, False, "off", datetime.utcnow())

    @staticmethod
    def check_status(smart_plug):
        return smart_plug.state
#!/usr/local/bin/python3
"""
CONTRIBUTORS:
    Justin Culbertson-Faegre, Codie Orberson, Landan Ginther
DETAILED DESCRIPTION:
    This is the only file that needs to be run to start the system.
REQUIREMENTS ADDRESSED:
    N/A
LICENSE INFORMATION:
    Copyright (c) 2019, CSC 450 Group 4
    All rights reserved.
    Redistribution and use in source and binary forms, with or without modification, are permitted provided that the
    following conditions are met:
        * Redistributions of source code must retain the above copyright notice, this list of conditions and the
          following disclaimer.
        * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and
          the following disclaimer in the documentation and/or other materials provided with the distribution.
        * Neither the name of the CSC 450 Group 4 nor the names of its contributors may be used to endorse or
          promote products derived from this software without specific prior written permission.
    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
    INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
    DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,
    OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
    DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
    STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
    EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
"""

from nonVerbalSmartHomeRecognitionSystem import NonVerbalSmartHomeRecognitionSystem

if __name__ == '__main__':
    print("Activating the Non-Verbal Smart Home Recognition system.\n")
    NonVerbalSmartHomeRecognitionSystem()
#!/usr/local/bin/python3
"""
CONTRIBUTORS:
    Codie Orberson, Landan Ginther, Justin Culbertson-Faegre, Danielle Bode
DETAILED DESCRIPTION:
    This file is the main controller of the entire NVSHR system. It begins by setting up all needed modules/helpers to
    be used within the system. It then sets up the callbacks for the recognition of gestures and adds all commands
    stored within the database into the parser. Afterwards, it grabs access to the users webcam and checks to make sure
    the resolution is at least 720p. If a lesser resolution camera is found, it simply displays a warning of degraded
    performance. It then creates and sets up the GUI manager and begins the main loop of the system, which checks frames
    from the camera for gestures. This module also provides all needed clean up for the system upon closure. More
    detailed information is available in section 3.2.1 in the SDD
REQUIREMENTS ADDRESSED:
    Since this is the main controller of the system, all requirements should be present within this module and it's sub-
    components.
LICENSE INFORMATION:
    Copyright (c) 2019, CSC 450 Group 4
    All rights reserved.
    Redistribution and use in source and binary forms, with or without modification, are permitted provided that the
    following conditions are met:
        * Redistributions of source code must retain the above copyright notice, this list of conditions and the
          following disclaimer.
        * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and
          the following disclaimer in the documentation and/or other materials provided with the distribution.
        * Neither the name of the CSC 450 Group 4 nor the names of its contributors may be used to endorse or
          promote products derived from this software without specific prior written permission.
    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
    INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
    DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,
    OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
    DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
    STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
    EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
"""

import sys
import cv2
import platform
from datetime import datetime
from databaseManager import DatabaseManager
from gestureDetector import GestureDetector
from gestureLexer import GestureLexer
from gestureParser import GestureParser
from guiManager import GuiManager
from logger import Logger
from processManager import ProcessManager
from smartHomeActivator import SmartHomeActivator


class NonVerbalSmartHomeRecognitionSystem:
    def __init__(self):
        self.__set_up_helpers__()
        self.__set_up_gestures__()
        self.__set_up_commands__()
        self.__set_up_camera__()
        self.__set_up_configuration__()
        self.__set_up_gui__()

    def main_loop(self):
        ret, frame = self.cap.read()

        # Rescaling frame with these numbers to fit it in the GUI debug tab
        frame = self.rescale_frame(frame, 56, 47)
        timestamp = datetime.utcnow()

        # Aggregates gestures into gesture sequences.
        gesture_sequences = self.gesture_lexer.lex(
            timestamp, self.minimum_time_increment, self.maximum_time_increment)

        # Creates a child process to check for predefined patterns of gestures in the list of gesture sequences
        self.process_manager.add_process(
            self.gesture_parser.parse_patterns,
            (gesture_sequences, timestamp))

        frame = self.gesture_detector.detect(
            frame, timestamp, self.open_eye_threshold)

        self.process_manager.on_done()

        self.gui_manager.set_debug_frame(cv2.flip(frame, 1))
        self.gesture_detected = self.gesture_detector.get_gesture_detected()
        self.gui_manager.set_gesture_background(self.gesture_detected)

        new_log_line = self.logger.get_output()
        if self.gesture_detected != None:
            self.gui_manager.update_log_text(new_log_line)

        self.update_commands()

    def rescale_frame(self, frame, width_frame_percent, height_frame_percent):
        if self.valid_webcam:
            width = int(frame.shape[1] * width_frame_percent/100)
            height = int(frame.shape[0] * height_frame_percent/100)
            dim = (width, height)
            return cv2.resize(frame, dim, interpolation=cv2.INTER_AREA)
        else:
            return frame

    def set_open_eye_threshold(self, new_ear_value):
        self.open_eye_threshold = float(new_ear_value)
        self.database_manager.set_open_eye_threshold(self.open_eye_threshold)

    def set_minimum_time_increment(self, new_minimum_time_increment):
        self.minimum_time_increment = int(new_minimum_time_increment)
        self.database_manager.set_minimum_time_increment(
            new_minimum_time_increment)

    def set_maximum_time_increment(self, new_maximum_time_increment):
        self.maximum_time_increment = int(new_maximum_time_increment)
        self.database_manager.set_maximum_time_increment(
            new_maximum_time_increment)

    def add_command(self, gesture_sequence, command_text, device_name):
        self.gesture_parser.add_pattern(gesture_sequence)
        self.database_manager.set_command(
            gesture_sequence, command_text, device_name)
        commands = self.database_manager.get_commands()
        self.smart_home_activator.set_commands(commands)

    def update_commands(self):
        for command_map in self.database_manager.get_commands():
            self.add_command(command_map['gesture_sequence'],
                             command_map['command_text'],
                             command_map['device_name'])

    def on_close(self):
        # Close down OpenCV
        self.cap.release()
        cv2.destroyAllWindows()

        # Close the GUI
        self.gui_manager.destroy_gui()

        # Close log file.
        self.logger.close()

    def __set_up_helpers__(self):
        self.is_admin = True
        self.database_manager = DatabaseManager()
        self.logger = Logger()
        self.smart_home_activator = SmartHomeActivator()
        self.gesture_detector = GestureDetector()
        self.gesture_lexer = GestureLexer()
        self.gesture_parser = GestureParser()
        self.gesture_detected = None
        self.process_manager = ProcessManager()
        self.valid_webcam = None

        self.smart_home_activator.set_commands(
            self.database_manager.get_commands())
        self.smart_home_activator.set_log_manager(
            self.database_manager, self.logger)

    def __set_up_gestures__(self):
        self.gesture_detector.on_gesture(self.gesture_lexer.add)
        self.gesture_detector.on_gesture(self.database_manager.set_gesture)
        self.gesture_detector.on_gesture(self.logger.log_gesture)

    def __set_up_commands__(self):
        self.gesture_parser.on_gesture_sequence(
            self.logger.log_gesture_sequence)
        self.gesture_parser.on_gesture_sequence(lambda gesture_sequence, timestamp, was_recognised:
                                                self.database_manager.set_gesture_sequence(gesture_sequence,
                                                                                           timestamp, was_recognised))
        self.gesture_parser.on_gesture_sequence(
            lambda gesture_sequence, timestamp, was_recognised: self.smart_home_activator.activate(gesture_sequence,
                                                                                                   was_recognised))
        self.update_commands()

    def __check_camera_resolution__(self):
        ret, frame = self.cap.read()
        try:
            if((frame.shape[1]) >= 1280) and ((frame.shape[0]) >= 720):
                self.valid_webcam = True
                return True
            else:
                self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 600)
                self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 400)
                self.valid_webcam = False
                return False
        except:
            return False

    def __set_up_camera__(self):
        self.cap = cv2.VideoCapture(0)
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)

    def __set_up_configuration__(self):
        self.open_eye_threshold = self.database_manager.get_open_eye_threshold()
        self.minimum_time_increment = self.database_manager.get_minimum_time_increment()
        self.maximum_time_increment = self.database_manager.get_maximum_time_increment()

    def __set_up_gui__(self):
        self.gui_manager = GuiManager(
            self.cap, self.database_manager, self.is_admin, self.__check_camera_resolution__())
        self.__set_up_gui_values__()
        self.__set_up_gui_watchers__()
        self.gui_manager.start(self.main_loop, self.on_close)

    def __set_up_gui_values__(self):
        self.gui_manager.set_initial_ear(self.open_eye_threshold)
        self.gui_manager.set_initial_minimum_time_increment(
            self.minimum_time_increment)
        self.gui_manager.set_initial_maximum_time_increment(
            self.maximum_time_increment)

    def __set_up_gui_watchers__(self):
        self.gui_manager.on_ear_change(self.set_open_eye_threshold)
        self.gui_manager.on_minimum_time_increment_change(
            self.set_minimum_time_increment)
        self.gui_manager.on_maximum_time_increment_change(
            self.set_maximum_time_increment)
        self.gui_manager.on_new_command(self.add_command)
#!/usr/local/bin/python3
"""
CONTRIBUTORS:
    Justin Culbertson-Faegre, Codie Orberson, Landan Ginther
DETAILED DESCRIPTION:
    This file is responsible for managing the the external files. This is used to open the external files, read from the
    external files, and write to the external files.
REQUIREMENTS ADDRESSED:
    FR.14, NFR.5, LDR.1
LICENSE INFORMATION:
    Copyright (c) 2019, CSC 450 Group 4
    All rights reserved.
    Redistribution and use in source and binary forms, with or without modification, are permitted provided that the
    following conditions are met:
        * Redistributions of source code must retain the above copyright notice, this list of conditions and the
          following disclaimer.
        * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and
          the following disclaimer in the documentation and/or other materials provided with the distribution.
        * Neither the name of the CSC 450 Group 4 nor the names of its contributors may be used to endorse or
          promote products derived from this software without specific prior written permission.
    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
    INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
    DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,
    OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
    DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
    STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
    EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
"""

import os


class FileManager:
    def __init__(self, file_name, default_lines):
        self._file_name = file_name
        self._cached_lines = []
        if not os.path.exists(file_name):
            with open(self._file_name, "w+") as file:
                file.writelines(default_lines)
            self._cached_lines = default_lines
        else:
            with open(self._file_name) as file:
                self._cached_lines = file.readlines()

    def set_line(self, line_number, line_contents):
        with open(self._file_name, 'r') as file:
            lines = file.readlines()
            lines[line_number] = line_contents
        with open(self._file_name, 'w') as file:
            file.writelines(lines)
        self._cached_lines[line_number] = line_contents

    def append_line(self, line_contents):
        with open(self._file_name, "a") as file:
            file.write(line_contents)
        self._cached_lines.append(line_contents)

    def get_lines(self):
        return self._cached_lines

    def get_line(self, line_number):
        return self._cached_lines[line_number]

    def get_length(self):
        return len(self._cached_lines)
#!/usr/local/bin/python3
"""
CONTRIBUTORS:
    Codie Orberson, Landan Ginther, Justin Culbertson-Faegre
DETAILED DESCRIPTION:
    This file creates an interface between the NVSHR system and the TPLink devices. This is where the system actually
    determines if the device is physically connected to the device and outputs a warning/message to the console in
    to inform the user no state change will be observed. This is also where the confirmation and failure noises will be
    called. More detail information can be found in Section 3.2.3 within the SDD.
REQUIREMENTS ADDRESSED:
    FR.5, FR.7, FR.10, FR.12, EIR.3
LICENSE INFORMATION:
    Copyright (c) 2019, CSC 450 Group 4
    All rights reserved.
    Redistribution and use in source and binary forms, with or without modification, are permitted provided that the
    following conditions are met:
        * Redistributions of source code must retain the above copyright notice, this list of conditions and the
          following disclaimer.
        * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and
          the following disclaimer in the documentation and/or other materials provided with the distribution.
        * Neither the name of the CSC 450 Group 4 nor the names of its contributors may be used to endorse or
          promote products derived from this software without specific prior written permission.
    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
    INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
    DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,
    OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
    DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
    STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
    EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
"""

from TPLink import TPLinkDevice
from soundPlayer import SoundPlayer


class SmartHomeActivator:
    def __init__(self):
        self.sound_player = SoundPlayer()
        self.tp_Link_Devices = TPLinkDevice()

    def set_commands(self, commands):
        self.commands = commands

    def set_log_manager(self, log_manager, logger):
        self.log_manager = log_manager
        self.logger = logger
        self.tp_Link_Devices.set_log_manager(log_manager, logger)

    def activate(self, gesture_sequence, was_recognized):
        if was_recognized:
            try:
                self.sound_player.play_success_sound()
                self.turn_on_off_TpLink_Device(gesture_sequence)
            except:
                self.log_manager.set_gesture_sequence_error(
                    "Unable to connect command to requested smart home device.")
                self.logger.log(
                    "Unable to connect command to requested smart home device.")
        else:
            self.sound_player.play_failure_sound()

    # Iterating through the command dictionary and performing smart home action linked
    # with the given gesture sequence
    def turn_on_off_TpLink_Device(self, gesture_sequence):
        index = 0
        while index < len(self.commands):
            for key in self.commands[index]:
                if gesture_sequence == self.commands[index]['gesture_sequence']:
                    self.tp_Link_Devices.turn_on_off(
                        self.commands[index]['command_text'])
                index += 1
#!/usr/local/bin/python3
"""
CONTRIBUTORS:
    Codie Orberson, Landan Ginther, Justin Culbertson-Faegre, Danielle Bode
DETAILED DESCRIPTION:
    This file manages the administrator GUI. It is here that the GUI window is created and titled. It also creates an
    interface for setting the initial configuration values of the system as well as adding in callbacks for the changing
    of the various configurations. The GUI loop is also set and started here after all initial configurations have been
    set. The GUI Manager also calls the needed functions to create and maintain changes to the various tabs within the
    administrator GUI. It is also here that the GUI can be destroyed when the system terminates. More detailed
    information is available in section 3.2.2 in the SDD
REQUIREMENTS ADDRESSED:
    FR.5, FR.7, NFR.5, EIR.1
LICENSE INFORMATION:
    Copyright (c) 2019, CSC 450 Group 4
    All rights reserved.
    Redistribution and use in source and binary forms, with or without modification, are permitted provided that the
    following conditions are met:
        * Redistributions of source code must retain the above copyright notice, this list of conditions and the
          following disclaimer.
        * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and
          the following disclaimer in the documentation and/or other materials provided with the distribution.
        * Neither the name of the CSC 450 Group 4 nor the names of its contributors may be used to endorse or
          promote products derived from this software without specific prior written permission.
    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
    INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
    DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,
    OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
    DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
    STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
    EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
"""

from guiWindow import GuiWindow
from framesPerSecondMeter import FramesPerSecondMeter
from tkinter import *


class GuiManager:
    def __init__(self, cap, settings_manager, is_admin, valid_webcam):
        self.cap = cap
        self.settings_manager = settings_manager
        self.gui = GuiWindow()
        self.gui.title("Non-Verbal Smart Home Recognition System")
        self.valid_webcam = valid_webcam
        if not is_admin:
            self.gui.withdraw()

    def set_initial_ear(self, initial_value):
        self.gui.set_initial_ear(initial_value)

    def set_initial_minimum_time_increment(self, initial_value):
        self.gui.set_initial_minimum_time_increment(initial_value)

    def set_initial_maximum_time_increment(self, initial_value):
        self.gui.set_initial_maximum_time_increment(initial_value)

    def on_ear_change(self, callback):
        self.gui.on_ear_change(callback)

    def on_minimum_time_increment_change(self, callback):
        self.gui.on_minimum_time_increment_change(callback)

    def on_maximum_time_increment_change(self, callback):
        self.gui.on_maximum_time_increment_change(callback)

    def on_new_command(self, callback):
        self.gui.on_new_command(callback)

    def __loop__(self):
        self.loop_callback()
        self.fps_tab.set_fps(self.frames_per_second_meter.cycle())
        self.gui.after(1, self.__loop__)

    def start(self, loop_callback, close_callback):
        self.frames_per_second_meter = FramesPerSecondMeter()
        self.gui.set_cap(self.cap, self.settings_manager)
        self.debug_tab = self.gui.get_debug_tab()
        self.fps_tab = self.gui.get_fps_tab()
        self.blink_label = self.gui.get_blink_label()
        self.fist_label = self.gui.get_fist_label()
        self.palm_label = self.gui.get_palm_label()

        self.log_page = self.gui.get_log_page()

        self.loop_callback = loop_callback
        self.close_callback = close_callback
        self.gui.protocol("WM_DELETE_WINDOW", close_callback)
        self.resolution_message_popup()
        self.gui.after(1, self.__loop__)
        self.gui.mainloop()

    def set_debug_frame(self, frame):
        self.debug_tab.set_debug_frame(frame)

    def display_error_message(self, title, text):
        self.gui.messagebox.showerror(title, text)

    def set_gesture_background(self, gesture_detected):
        self.blink_label.set_gesture_background(gesture_detected)
        self.fist_label.set_gesture_background(gesture_detected)
        self.palm_label.set_gesture_background(gesture_detected)

    def update_log_text(self, content):
        self.log_page.log_text.config(state=NORMAL)
        self.log_page.log_text.insert(INSERT, content)
        self.log_page.log_text.config(state=DISABLED)
        self.log_page.log_text.see(END)

    def resolution_message_popup(self):
        if self.valid_webcam == False:
            messagebox.showwarning("Warning", "Your camera is not 720p. A camera of 720p or higher is "
                                              "recommended for optimal performance")
            self.valid_webcam = True

    def destroy_gui(self):
        self.gui.destroy()
'''
MIT License

Copyright (c) 2018 LiamZ96

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
'''
'''Authors: Jacob Wakefield'''


from gevent import monkey
from Server import app
import webbrowser
from gevent.pywsgi import WSGIServer
from gevent.pool import Pool as gPool
PORT = 5000


def main():
    pool = gPool(1000)  # create thread pool with a limit of 1000
    http_server = WSGIServer(('0.0.0.0', PORT), app,
                             spawn=pool)  # create wsgi server

    url = "http://localhost:"+str(PORT)+"/"
    webbrowser.open(url, new=2)  # Opens in new tab if possible
    http_server.serve_forever()


if __name__ == "__main__":
    main()
import coverage
from PIL import Image

from lib.counting import *
from lib.colorLabeler import *
from lib.file_util import *
from lib.stitching import *
from lib.util import *

from Server.routes import *


def main():
    cov = coverage.Coverage(
        omit=["./exp-env/*", "coverage_tests.py", './Server/*'])
    cov.start()

    test_single_upload()
    test_multiple_upload()
    test_directory_setup()
    test_invalid_stitch()

    cov.stop()
    cov.save()
    cov.html_report()


def test_single_upload():
    test_stitch = Stitching(
        'test/coverage_test/single/images/', 'test/coverage_test/single/maps/')
    (test_status_id, test_status_string) = test_stitch.stitchImages_Default()
    test_count = Counting(
        'test/test_bead_size_directory/maps/result_default.jpg')
    test_params = Parameters()
    test_params.maxRadius = 125
    test_params.minRadius = 0
    test_params.minDist = 20
    test_params.wantsCrushedBeads = True
    test_params.wantsWaterBubbles = True
    test_params.detectionAlgorithm = "mid"
    beads = test_count.getColorBeads(HoughConfig.DEFAULT, test_params)


def test_multiple_upload():
    test_stitch = Stitching(
        'test/coverage_test/multiple/images/', 'test/coverage_test/multiple/maps/')
    (test_status_id, test_status_string) = test_stitch.stitchImages_Default()

    test_count = Counting(
        'test/coverage_test/multiple/maps/result_default.jpg')
    test_params = Parameters()
    test_params.maxRadius = 125
    test_params.minRadius = 0
    test_params.minDist = 20
    test_params.detectionAlgorithm = "avg"
    test_params.wantsCrushedBeads = True
    test_params.wantsWaterBubbles = True
    beads1 = test_count.getColorBeads(HoughConfig.OBJX10, test_params)
    test_params.detectionAlgorithm = "rad"
    beads2 = test_count.getColorBeads(HoughConfig.OBJX4, test_params)
    test_params.detectionAlgorithm = "corner"
    beads3 = test_count.getColorBeads(HoughConfig.OBJX4, test_params)
    file_timestamp1 = test_count.makeBeadsCSV("hsv")
    file_timestamp2 = test_count.makeBeadsCSV("grayscale")
    file_timestamp3 = test_count.makeBeadsCSV("cmyk")
    file_timestamp4 = test_count.makeBeadsCSV("rgb")


def test_directory_setup():
    createUploadDir()
    filename1 = 'test/coverage_test/file_upload/test/test_image.jpg'
    image_file1 = Image.open(filename1)
    checkImagesAndSaveToDirectory(
        [image_file1], 'test/coverage_test/file_upload')
    filename2 = 'test/coverage_test/file_upload/test/invalid_test_image.png'
    image_file2 = Image.open(filename2)
    checkImagesAndSaveToDirectory(
        [image_file2], 'test/coverage_test/file_upload')


def test_invalid_stitch():
    test_stitch = Stitching('test/coverage_test/invalid_stitch/images/',
                            'test/coverage_test/invalid_stitch/maps/')
    (test_status_id, test_status_string) = test_stitch.stitchImages_Default()


main()
'''
MIT License

Copyright (c) 2018 LiamZ96

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
'''
# Authors: Gattlin Walker, Patrick Ayres, Alex Peters
import unittest
import os
import csv
import colorsys
import cv2
import coverage

from lib.counting import *
from lib.util import rgbToCmyk

from Server.routes import *


class TestBeadSize(unittest.TestCase):

    def setUp(self):
        self.test_count = Counting(
            'test/test_bead_size_directory/maps/result_default.jpg')
        self.test_params = Parameters()

    # FR. 1-1
    def test_beads_within_bounds(self):
        self.test_params.maxRadius = 125
        self.test_params.minRadius = 0
        self.test_params.minDist = 20
        self.test_params.detectionAlgorithm = "mid"
        beads = self.test_count.getColorBeads(
            HoughConfig.DEFAULT, self.test_params)
        self.assertEqual(len(beads), 4)

    # FR. 1-2
    def test_no_small_beads(self):
        self.test_params.maxRadius = 125
        self.test_params.minRadius = 110
        self.test_params.detectionAlgorithm = "mid"
        beads = self.test_count.getColorBeads(
            HoughConfig.DEFAULT, self.test_params)
        self.assertEqual(len(beads), 0)

    # FR. 1-3
    def test_no_big_beads(self):
        self.test_params.maxRadius = 80
        self.test_params.minRadius = 20
        self.test_params.detectionAlgorithm = "mid"
        beads = self.test_count.getColorBeads(
            HoughConfig.DEFAULT, self.test_params)
        self.assertEqual(len(beads), 0)

    # FR. 1-4
    def test_upper_bound_smaller_than_lower_bound(self):
        self.test_params.maxRadius = 50
        self.test_params.minRadius = 80
        self.test_params.detectionAlgorithm = "mid"
        beads = self.test_count.getColorBeads(
            HoughConfig.DEFAULT, self.test_params)
        # this should return an error

    # FR. 1-5
    def test_upper_bound_smaller_than_lower_default(self):
        self.test_params.maxRadius = 10
        self.test_params.minRadius = 30
        self.test_params.detectionAlgorithm = "mid"
        beads = self.test_count.getColorBeads(
            HoughConfig.DEFAULT, self.test_params)
        # this should return an error

    # FR. 1-6
    def test_lower_bound_larger_than_upper_default(self):
        self.test_params.maxRadius = 80
        self.test_params.minRadius = 100
        self.test_params.detectionAlgorithm = "mid"
        beads = self.test_count.getColorBeads(
            HoughConfig.DEFAULT, self.test_params)
        # this should return an error

    # FR. 1-7
    def test_default_size_bounds(self):
        self.test_params.maxRadius = 80
        self.test_params.minRadius = 30
        self.test_params.detectionAlgorithm = "mid"
        beads = self.test_count.getColorBeads(
            HoughConfig.DEFAULT, self.test_params)
        self.assertEqual(len(beads), 0)

    # FR. 1-8
    def test_upper_bound_equal_to_lower_bound(self):
        self.test_params.maxRadius = 40
        self.test_params.minRadius = 40
        self.test_params.detectionAlgorithm = "mid"
        beads = self.test_count.getColorBeads(
            HoughConfig.DEFAULT, self.test_params)
        # this should return an error

    # FR. 1-9
    #Error - Video

    # FR. 1-10
    #Error - Video

    # FR. 1-11
    #Error - Video


class TestCrushedBeads(unittest.TestCase):

    def setUp(self):
        self.test_params = Parameters()

    # FR. 2-1
    def test_single_crushed_bead(self):
        test_count = Counting(
            'test/test_crushed_bead_directory/images/one_crushed.jpg')
        cimg = cv2.cvtColor(test_count.grayScaleMap, cv2.COLOR_GRAY2BGR)

        self.test_params.wantsCrushedBeads = True
        self.test_params.minRadius = 55
        self.test_params.maxRadius = 100
        self.test_params.minRadius = 35
        self.test_params.detectionAlgorithm = "mid"

        test_count.getCrushedBeads(
            cimg, self.test_params, HoughConfig.OBJX10.value)

        crushedCount = len(test_count.crushedBeads)
        self.assertEqual(crushedCount, 2)

    # FR. 2-2
    def test_no_crushed_beads(self):
        test_count = Counting(
            'test/test_crushed_bead_directory/images/no_crushed.jpg')
        cimg = cv2.cvtColor(test_count.grayScaleMap, cv2.COLOR_GRAY2BGR)

        self.test_params.wantsCrushedBeads = True
        self.test_params.minRadius = 30
        self.test_params.maxRadius = 60
        self.test_params.detectionAlgorithm = "mid"

        test_count.getCrushedBeads(
            cimg, self.test_params, HoughConfig.OBJX4.value)

        crushedCount = len(test_count.crushedBeads)
        self.assertEqual(crushedCount, 0)

    # FR. 2-3
    def test_multiple_crushed_bead(self):
        test_count = Counting(
            'test/test_crushed_bead_directory/images/multiple_crushed.jpg')
        cimg = cv2.cvtColor(test_count.grayScaleMap, cv2.COLOR_GRAY2BGR)

        self.test_params.wantsCrushedBeads = True
        self.test_params.minRadius = 30
        self.test_params.maxRadius = 60
        self.test_params.detectionAlgorithm = "mid"

        test_count.getCrushedBeads(
            cimg, self.test_params, HoughConfig.OBJX4.value)

        crushedCount = len(test_count.crushedBeads)
        self.assertEqual(crushedCount, 4)

    # FR. 2-4
    def test_crushed_bead_off_with_crushed(self):
        test_count = Counting(
            'test/test_crushed_bead_directory/images/multiple_crushed.jpg')

        self.test_params.beadUpperBound = 40
        self.test_params.beadLowerBound = 60
        self.test_params.detectionAlgorithm = "mid"
        self.test_params.wantsCrushedBeads = False

        test_count.getColorBeads(HoughConfig.OBJX4, self.test_params)

        crushedCount = len(test_count.crushedBeads)
        self.assertEqual(crushedCount, 0)

    # FR. 2-5
    def test_crushed_bead_off_without_crushed(self):
        test_count = Counting(
            'test/test_crushed_bead_directory/images/no_crushed.jpg')

        self.test_params.beadUpperBound = 40
        self.test_params.beadLowerBound = 60
        self.test_params.detectionAlgorithm = "mid"
        self.test_params.wantsCrushedBeads = False

        test_count.getColorBeads(HoughConfig.OBJX4, self.test_params)

        crushedCount = len(test_count.crushedBeads)
        self.assertEqual(crushedCount, 0)

    # FR. 2-6
    # Tests to make sure the black edges from a stitched image do not affect
    # the detection results
    def test_crushed_bead_with_stitched_image(self):
        test_count = Counting(
            'test/test_crushed_bead_directory/maps/stitched_map.jpg')

        self.test_params.beadUpperBound = 20
        self.test_params.beadLowerBound = 60
        self.test_params.detectionAlgorithm = "mid"
        self.test_params.wantsCrushedBeads = True
        self.test_params.wantsWaterBubbles = True
        self.test_params.sensitivity = 50
        self.test_params.minRadius = 20

        test_count.getColorBeads(HoughConfig.OBJX4, self.test_params)

        crushedCount = len(test_count.crushedBeads)
        self.assertEqual(crushedCount, 5)

    # FR. 2-7
    def test_crushed_bead_with_black_borders(self):
        test_count = Counting(
            'test/test_crushed_bead_directory/images/black_borders.jpg')
        cimg = cv2.cvtColor(test_count.grayScaleMap, cv2.COLOR_GRAY2BGR)

        self.test_params.beadUpperBound = 20
        self.test_params.beadLowerBound = 60
        self.test_params.detectionAlgorithm = "mid"
        self.test_params.wantsCrushedBeads = True
        self.test_params.sensitivity = 50
        self.test_params.minRadius = 20

        test_count.getCrushedBeads(
            cimg, self.test_params, HoughConfig.OBJX4.value)

        crushedCount = len(test_count.crushedBeads)
        self.assertEqual(crushedCount, 4)

    # FR. 2-8
    def test_crushed_bead_with_black_borders_no_crushed_beads(self):
        test_count = Counting(
            'test/test_crushed_bead_directory/images/borders_with_no_crushed.jpg')
        cimg = cv2.cvtColor(test_count.grayScaleMap, cv2.COLOR_GRAY2BGR)

        self.test_params.beadUpperBound = 20
        self.test_params.beadLowerBound = 60
        self.test_params.detectionAlgorithm = "mid"
        self.test_params.wantsCrushedBeads = True
        self.test_params.sensitivity = 50
        self.test_params.minRadius = 20

        test_count.getCrushedBeads(
            cimg, self.test_params, HoughConfig.OBJX4.value)

        crushedCount = len(test_count.crushedBeads)
        self.assertEqual(crushedCount, 0)

    # FR. 2-9
    def test_crushed_bead_with_stitched_image_no_crushed_beads(self):
        test_count = Counting(
            'test/test_crushed_bead_directory/maps/stitched_no_crushed.jpg')
        cimg = cv2.cvtColor(test_count.grayScaleMap, cv2.COLOR_GRAY2BGR)

        self.test_params.beadUpperBound = 20
        self.test_params.beadLowerBound = 50
        self.test_params.detectionAlgorithm = "mid"
        self.test_params.wantsCrushedBeads = True
        self.test_params.sensitivity = 50
        self.test_params.minRadius = 20

        test_count.getCrushedBeads(
            cimg, self.test_params, HoughConfig.OBJX4.value)

        crushedCount = len(test_count.crushedBeads)
        self.assertEqual(crushedCount, 0)

    # FR. 2-10
    def test_crushed_beads_with_black_borders_and_edges_no_crushed_beads(self):
        test_count = Counting(
            'test/test_crushed_bead_directory/maps/stitched_no_crushed.jpg')
        cimg = cv2.cvtColor(test_count.grayScaleMap, cv2.COLOR_GRAY2BGR)

        self.test_params.beadUpperBound = 20
        self.test_params.beadLowerBound = 50
        self.test_params.detectionAlgorithm = "mid"
        self.test_params.wantsCrushedBeads = True
        self.test_params.sensitivity = 50
        self.test_params.minRadius = 20

        test_count.getCrushedBeads(
            cimg, self.test_params, HoughConfig.OBJX4.value)

        crushedCount = len(test_count.crushedBeads)
        self.assertEqual(crushedCount, 0)

    # FR. 2-11 test/test_crushed_bead_directory/images/multiple_colors.jpg
    def test_crushed_bead_with_colored_crushed_areas(self):
        test_count = Counting(
            'test/test_crushed_bead_directory/images/multiple_colors.jpg')
        cimg = cv2.cvtColor(test_count.grayScaleMap, cv2.COLOR_GRAY2BGR)

        self.test_params.beadUpperBound = 20
        self.test_params.beadLowerBound = 40
        self.test_params.detectionAlgorithm = "mid"
        self.test_params.wantsCrushedBeads = True
        self.test_params.sensitivity = 40
        self.test_params.minRadius = 20

        test_count.getCrushedBeads(
            cimg, self.test_params, HoughConfig.OBJX4.value)

        crushedCount = len(test_count.crushedBeads)
        self.assertEqual(crushedCount, 1)

    # FR. 2-12
    def test_cracked_beads_with_crushed(self):
        test_count = Counting(
            'test/test_crushed_bead_directory/images/cracked_beads.jpg')
        cimg = cv2.cvtColor(test_count.grayScaleMap, cv2.COLOR_GRAY2BGR)

        self.test_params.beadUpperBound = 20
        self.test_params.beadLowerBound = 60
        self.test_params.detectionAlgorithm = "mid"
        self.test_params.wantsCrushedBeads = True
        self.test_params.sensitivity = 40
        self.test_params.minRadius = 20

        test_count.getCrushedBeads(
            cimg, self.test_params, HoughConfig.OBJX4.value)

        crushedCount = len(test_count.crushedBeads)
        self.assertEqual(crushedCount, 2)

    # FR. 2-13
    def test_cracked_beads_without_crushed(self):
        test_count = Counting(
            'test/test_crushed_bead_directory/images/cracked_beads.jpg')
        cimg = cv2.cvtColor(test_count.grayScaleMap, cv2.COLOR_GRAY2BGR)

        self.test_params.beadUpperBound = 20
        self.test_params.beadLowerBound = 60
        self.test_params.detectionAlgorithm = "mid"
        self.test_params.wantsCrushedBeads = False
        self.test_params.sensitivity = 50
        self.test_params.minRadius = 20

        test_count.getColorBeads(HoughConfig.OBJX4, self.test_params)

        crushedCount = len(test_count.crushedBeads)
        self.assertEqual(crushedCount, 0)

    # FR. 2-14
    def test_crushed_beads_with_black_borders_and_edges(self):
        test_count = Counting(
            'test/test_crushed_bead_directory/maps/black_borders_and_edges.jpg')
        cimg = cv2.cvtColor(test_count.grayScaleMap, cv2.COLOR_GRAY2BGR)

        self.test_params.beadUpperBound = 20
        self.test_params.beadLowerBound = 60
        self.test_params.detectionAlgorithm = "mid"
        self.test_params.wantsCrushedBeads = True
        self.test_params.sensitivity = 50
        self.test_params.minRadius = 20

        test_count.getCrushedBeads(
            cimg, self.test_params, HoughConfig.OBJX4.value)

        crushedCount = len(test_count.crushedBeads)
        self.assertEqual(crushedCount, 4)


class TestWaterBubble(unittest.TestCase):

    def setUp(self):
        self.one_bubble_filename = 'test/test_water_bubble_directory/single/single.jpg'
        self.multiple_bubble_filename = 'test/test_water_bubble_directory/multiple/multiple.jpg'
        self.no_bubble_filename = 'test/test_water_bubble_directory/none/none.jpg'

        self.test_params = Parameters()
        self.setUpParameters()

    def setUpParameters(self):
        self.test_params.detectionAlgorithm = 'mid'
        self.test_params.wantsWaterBubbles = True
        self.test_params.minDist = 40
        self.test_params.sensitivity = 55
        self.test_params.minRadius = 0
        self.test_params.maxRadius = 75

    # FR. 3-1
    def test_water_bubble(self):
        counter = Counting(self.one_bubble_filename)
        beads = counter.getColorBeads(HoughConfig.OBJX10, self.test_params)
        self.assertEqual(len(counter.waterBeads), 1)

    # FR. 3-2
    def test_no_water_bubble(self):
        counter = Counting(self.no_bubble_filename)
        beads = counter.getColorBeads(HoughConfig.OBJX10, self.test_params)
        self.assertEqual(len(counter.waterBeads), 0)

    # FR. 3-3
    def test_multiple_water_bubbles(self):
        counter = Counting(self.multiple_bubble_filename)
        beads = counter.getColorBeads(HoughConfig.OBJX10, self.test_params)
        self.assertEqual(len(counter.waterBeads), 3)

    # FR. 3-4
    def test_water_bubble_off_with_bubble(self):
        self.test_params.wantsWaterBubbles = False
        counter = Counting(self.one_bubble_filename)
        beads = counter.getColorBeads(HoughConfig.OBJX10, self.test_params)
        self.assertEqual(len(counter.waterBeads), 0)

    # FR. 3-5
    def test_water_bubble_off_without_bubble(self):
        self.test_params.wantsWaterBubbles = False
        counter = Counting(self.no_bubble_filename)
        beads = counter.getColorBeads(HoughConfig.OBJX10, self.test_params)
        self.assertEqual(len(counter.waterBeads), 0)


class TestPartialBead(unittest.TestCase):

    def setUp(self):
        self.MARGIN_OF_ERROR = .95
        self.test_params = Parameters()

    # FR. 4-1

    def test_single_partial_bead(self):
        self.test_count = Counting(
            'test/test_partial_bead_directory/single/maps/result_default.jpg')
        self.test_params.minDist = 40
        self.test_params.sensitivity = 40
        self.test_params.minRadius = 50
        self.test_params.maxRadius = 125
        self.test_params.detectionAlgorithm = "mid"
        beads = self.test_count.getColorBeads(
            HoughConfig.DEFAULT, self.test_params)
        self.assertEqual(len(beads), 2)

    # FR. 4-2

    def test_no_partial_beads(self):
        self.test_count = Counting(
            'test/test_bead_size_directory/maps/result_default.jpg')
        self.test_params.maxRadius = 125
        self.test_params.minRadius = 0
        self.test_params.minDist = 20
        self.test_params.detectionAlgorithm = "mid"
        beads = self.test_count.getColorBeads(
            HoughConfig.DEFAULT, self.test_params)
        self.assertEqual(len(beads), 4)

    # FR. 4-3
    def test_multiple_partial_bead(self):
        self.test_count = Counting(
            'test/test_partial_bead_directory/multiple/maps/result_default.jpg')
        self.test_params.minDist = 40
        self.test_params.sensitivity = 35
        self.test_params.minRadius = 10
        self.test_params.maxRadius = 120
        self.test_params.detectionAlgorithm = "mid"
        beads = self.test_count.getColorBeads(
            HoughConfig.DEFAULT, self.test_params)
        actual_count = 67
        self.assertTrue(len(beads) >= round(actual_count * self.MARGIN_OF_ERROR)
                        and len(beads) <= round(actual_count / self.MARGIN_OF_ERROR))

    # FR. 4-4
    def test_partial_bead_true_edge_major_majority(self):
        self.test_count = Counting(
            'test/test_partial_bead_directory/true_major_majority/maps/result_default.jpg')
        self.test_params.minDist = 40
        self.test_params.sensitivity = 40
        self.test_params.minRadius = 50
        self.test_params.maxRadius = 125
        self.test_params.detectionAlgorithm = "mid"
        beads = self.test_count.getColorBeads(
            HoughConfig.DEFAULT, self.test_params)
        self.assertEqual(len(beads), 3)

    # FR. 4-5
    def test_partial_bead_true_edge_minor_majority(self):
        self.test_count = Counting(
            'test/test_partial_bead_directory/true_minor_majority/maps/result_default.jpg')
        self.test_params.minDist = 40
        self.test_params.sensitivity = 40
        self.test_params.minRadius = 50
        self.test_params.maxRadius = 125
        self.test_params.detectionAlgorithm = "mid"
        beads = self.test_count.getColorBeads(
            HoughConfig.DEFAULT, self.test_params)
        self.assertEqual(len(beads), 3)

    # FR. 4-6
    def test_partial_bead_true_edge_minority(self):
        self.test_count = Counting(
            'test/test_partial_bead_directory/true_minority/maps/result_default.jpg')
        self.test_params.minDist = 50
        self.test_params.sensitivity = 40
        self.test_params.minRadius = 50
        self.test_params.maxRadius = 125
        self.test_params.detectionAlgorithm = "mid"
        beads = self.test_count.getColorBeads(
            HoughConfig.DEFAULT, self.test_params)
        self.assertEqual(len(beads), 2)

    # FR. 4-7
    def test_partial_bead_false_top_right_edge(self):
        pass

    # FR. 4-8
    def test_partial_bead_false_top_left_edge(self):
        pass

    # FR. 4-9
    def test_partial_bead_false_bottom_left_edge(self):
        pass

    # FR. 4-10
    def test_partial_bead_false_bottom_right_edge(self):
        pass


class TestCSV(unittest.TestCase):

    def setUp(self):
        self.test_params = Parameters()

    # FR. 5-1
    def test_csv_rows(self):
        self.test_count = Counting(
            'test/test_csv_directory/maps/result_default.jpg')
        self.test_params.maxRadius = 125
        self.test_params.minRadius = 0
        self.test_params.minDist = 20
        self.test_params.detectionAlgorithm = "mid"
        beads = self.test_count.getColorBeads(
            HoughConfig.DEFAULT, self.test_params)
        file_timestamp = self.test_count.makeBeadsCSV("rgb")
        csv_file = open('test/test_csv_directory/results/rgb_' +
                        file_timestamp + '.csv', 'r')
        row_count = sum(1 for row in csv_file)
        csv_file.close()
        self.assertEqual(row_count, 5)

    # FR. 5-2
    def test_csv_type_col(self):
        self.test_count = Counting(
            'test/test_csv_directory/maps/result_default.jpg')
        self.test_params.maxRadius = 125
        self.test_params.minRadius = 0
        self.test_params.minDist = 20
        self.test_params.detectionAlgorithm = "mid"
        beads = self.test_count.getColorBeads(
            HoughConfig.DEFAULT, self.test_params)
        file_timestamp = self.test_count.makeBeadsCSV("rgb")
        csv_file = open('test/test_csv_directory/results/rgb_' +
                        file_timestamp + '.csv', 'r')
        row_count = sum(1 for row in csv_file)
        csv_file.close()
        os.remove('test/test_csv_directory/results/rgb_' +
                  file_timestamp + '.csv')
        self.assertEqual(row_count, len(beads) + 1)

    # FR. 5-3
    def test_rgb_csv(self):
        self.test_count = Counting(
            'test/test_csv_directory/maps/result_default.jpg')
        self.test_params.maxRadius = 125
        self.test_params.minRadius = 0
        self.test_params.minDist = 20
        self.test_params.detectionAlgorithm = "mid"
        beads = self.test_count.getColorBeads(
            HoughConfig.DEFAULT, self.test_params)
        file_timestamp = self.test_count.makeBeadsCSV("rgb")
        csv_file = open('test/test_csv_directory/results/rgb_' +
                        file_timestamp + '.csv', 'r')
        data = list(csv.reader(csv_file))

        correct_file = True
        for i in range(len(beads)):
            bead_color = beads[i][0]
            file_color = [float(data[i+1][2]),
                          float(data[i+1][3]), float(data[i+1][4])]

            if(bead_color != file_color):
                correct_file = False

        csv_file.close()
        os.remove('test/test_csv_directory/results/rgb_' +
                  file_timestamp + '.csv')
        self.assertTrue(correct_file)

    # FR. 5-4
    def test_hsv_csv(self):
        self.test_count = Counting(
            'test/test_csv_directory/maps/result_default.jpg')
        self.test_params.maxRadius = 125
        self.test_params.minRadius = 0
        self.test_params.minDist = 20
        self.test_params.detectionAlgorithm = "mid"
        beads = self.test_count.getColorBeads(
            HoughConfig.DEFAULT, self.test_params)
        file_timestamp = self.test_count.makeBeadsCSV("hsv")
        csv_file = open('test/test_csv_directory/results/hsv_' +
                        file_timestamp + '.csv', 'r')
        data = list(csv.reader(csv_file))

        correct_file = True
        for i in range(len(beads)):
            bead_color = beads[i][0]
            hsv = colorsys.rgb_to_hsv(
                bead_color[0]/255, bead_color[1]/255, bead_color[2]/255)
            file_color = (float(data[i+1][2]),
                          float(data[i+1][3]), float(data[i+1][4]))

            if(hsv != file_color):
                correct_file = False

        csv_file.close()
        os.remove('test/test_csv_directory/results/hsv_' +
                  file_timestamp + '.csv')
        self.assertTrue(correct_file)

    # FR. 5-5
    def test_cmyk_csv(self):
        self.test_count = Counting(
            'test/test_csv_directory/maps/result_default.jpg')
        self.test_params.maxRadius = 125
        self.test_params.minRadius = 0
        self.test_params.minDist = 20
        self.test_params.detectionAlgorithm = "mid"
        beads = self.test_count.getColorBeads(
            HoughConfig.DEFAULT, self.test_params)
        file_timestamp = self.test_count.makeBeadsCSV("cmyk")
        csv_file = open('test/test_csv_directory/results/cmyk_' +
                        file_timestamp + '.csv', 'r')
        data = list(csv.reader(csv_file))

        correct_file = True
        for i in range(len(beads)):
            bead_color = beads[i][0]
            c, m, y, k = rgbToCmyk(bead_color[0], bead_color[1], bead_color[2])
            cmyk = [c, m, y, k]
            file_color = [float(data[i+1][2]), float(data[i+1][3]),
                          float(data[i+1][4]), float(data[i+1][5])]

            if(cmyk != file_color):
                correct_file = False

        csv_file.close()
        os.remove('test/test_csv_directory/results/cmyk_' +
                  file_timestamp + '.csv')
        self.assertTrue(correct_file)

    # FR. 5-6
    def test_grayscale_csv(self):
        self.test_count = Counting(
            'test/test_csv_directory/maps/result_default.jpg')
        self.test_params.maxRadius = 125
        self.test_params.minRadius = 0
        self.test_params.minDist = 20
        self.test_params.detectionAlgorithm = "mid"
        beads = self.test_count.getColorBeads(
            HoughConfig.DEFAULT, self.test_params)
        file_timestamp = self.test_count.makeBeadsCSV("grayscale")
        csv_file = open(
            'test/test_csv_directory/results/grayscale_' + file_timestamp + '.csv', 'r')
        data = list(csv.reader(csv_file))

        correct_file = True
        for i in range(len(beads)):
            bead_color = beads[i][0]
            grayscale = [sum(bead_color) / len(bead_color)]
            file_color = [float(data[i+1][2])]

            if(grayscale != file_color):
                correct_file = False

        csv_file.close()
        os.remove('test/test_csv_directory/results/grayscale_' +
                  file_timestamp + '.csv')
        self.assertTrue(correct_file)

    # FR. 5-7
    def test_invalid_stich(self):
        pass


class TestColorAlgorithms(unittest.TestCase):

    def setUp(self):
        self.test_count = Counting(
            'test/test_color_algorithm_directory/maps/result_default.jpg')
        self.test_params = Parameters()

    # FR. 6-1
    def test_default_color_algorithm(self):
        self.test_params.maxRadius = 125
        self.test_params.minRadius = 0
        self.test_params.minDist = 20
        self.test_params.detectionAlgorithm = "mid"
        beads = self.test_count.getColorBeads(
            HoughConfig.DEFAULT, self.test_params)

        img = self.test_count.grayScaleMap
        cimg = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
        blur = cv2.GaussianBlur(img, (7, 7), 0)

        circles = cv2.HoughCircles(blur, cv2.HOUGH_GRADIENT,
                                   dp=1,
                                   minDist=self.test_params.minDist,
                                   param1=50,
                                   param2=self.test_params.sensitivity,
                                   minRadius=self.test_params.minRadius,
                                   maxRadius=self.test_params.maxRadius)
        circles = np.uint16(np.around(circles))

        circle_list = []
        for i in circles[0, :]:
            actual_color = self.test_count.getMiddleColor(i)
            circle_list.append(actual_color)

        correct_color = True
        for i in range(len(beads)):
            calculated_color = beads[i][0]
            actual_color = circle_list[i][0]

            if(calculated_color != actual_color):
                correct_color = False

        self.assertTrue(correct_color)

    # FR. 6-2

    def test_average_color_algorithm(self):
        self.test_params.maxRadius = 125
        self.test_params.minRadius = 0
        self.test_params.minDist = 20
        self.test_params.detectionAlgorithm = "avg"
        beads = self.test_count.getColorBeads(
            HoughConfig.DEFAULT, self.test_params)

        img = self.test_count.grayScaleMap
        cimg = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
        blur = cv2.GaussianBlur(img, (7, 7), 0)

        circles = cv2.HoughCircles(blur, cv2.HOUGH_GRADIENT,
                                   dp=1,
                                   minDist=self.test_params.minDist,
                                   param1=50,
                                   param2=self.test_params.sensitivity,
                                   minRadius=self.test_params.minRadius,
                                   maxRadius=self.test_params.maxRadius)
        circles = np.uint16(np.around(circles))

        circle_list = []
        for i in circles[0, :]:
            actual_color = self.test_count.getAverageColor(i)
            circle_list.append(actual_color)

        correct_color = True
        for i in range(len(beads)):
            calculated_color = beads[i][0]
            actual_color = circle_list[i][0]

            if(calculated_color != actual_color):
                correct_color = False

        self.assertTrue(correct_color)

    # FR. 6-3
    def test_middle_color_algorithm(self):
        self.test_params.maxRadius = 125
        self.test_params.minRadius = 0
        self.test_params.minDist = 20
        self.test_params.detectionAlgorithm = "mid"
        beads = self.test_count.getColorBeads(
            HoughConfig.DEFAULT, self.test_params)

        img = self.test_count.grayScaleMap
        cimg = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
        blur = cv2.GaussianBlur(img, (7, 7), 0)

        circles = cv2.HoughCircles(blur, cv2.HOUGH_GRADIENT,
                                   dp=1,
                                   minDist=self.test_params.minDist,
                                   param1=50,
                                   param2=self.test_params.sensitivity,
                                   minRadius=self.test_params.minRadius,
                                   maxRadius=self.test_params.maxRadius)
        circles = np.uint16(np.around(circles))

        circle_list = []
        for i in circles[0, :]:
            actual_color = self.test_count.getMiddleColor(i)
            circle_list.append(actual_color)

        correct_color = True
        for i in range(len(beads)):
            calculated_color = beads[i][0]
            actual_color = circle_list[i][0]

            if(calculated_color != actual_color):
                correct_color = False

        self.assertTrue(correct_color)

    # FR. 6-4
    def test_radius_color_algorithm(self):
        self.test_params.maxRadius = 125
        self.test_params.minRadius = 0
        self.test_params.minDist = 20
        self.test_params.detectionAlgorithm = "rad"
        beads = self.test_count.getColorBeads(
            HoughConfig.DEFAULT, self.test_params)

        img = self.test_count.grayScaleMap
        cimg = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
        blur = cv2.GaussianBlur(img, (7, 7), 0)

        circles = cv2.HoughCircles(blur, cv2.HOUGH_GRADIENT,
                                   dp=1,
                                   minDist=self.test_params.minDist,
                                   param1=50,
                                   param2=self.test_params.sensitivity,
                                   minRadius=self.test_params.minRadius,
                                   maxRadius=self.test_params.maxRadius)
        circles = np.uint16(np.around(circles))

        circle_list = []
        for i in circles[0, :]:
            actual_color = self.test_count.getRadiusAverageColor(i)
            circle_list.append(actual_color)

        correct_color = True
        for i in range(len(beads)):
            calculated_color = beads[i][0]
            actual_color = circle_list[i][0]

            if(calculated_color != actual_color):
                correct_color = False

        self.assertTrue(correct_color)

    # FR. 6-5
    def test_four_corner_color_algorithm(self):
        self.test_params.maxRadius = 125
        self.test_params.minRadius = 0
        self.test_params.minDist = 20
        self.test_params.detectionAlgorithm = "corner"
        beads = self.test_count.getColorBeads(
            HoughConfig.DEFAULT, self.test_params)

        img = self.test_count.grayScaleMap
        cimg = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
        blur = cv2.GaussianBlur(img, (7, 7), 0)

        circles = cv2.HoughCircles(blur, cv2.HOUGH_GRADIENT,
                                   dp=1,
                                   minDist=self.test_params.minDist,
                                   param1=50,
                                   param2=self.test_params.sensitivity,
                                   minRadius=self.test_params.minRadius,
                                   maxRadius=self.test_params.maxRadius)
        circles = np.uint16(np.around(circles))

        circle_list = []
        for i in circles[0, :]:
            actual_color = self.test_count.getFourQuadrantColor(i)
            circle_list.append(actual_color)

        correct_color = True
        for i in range(len(beads)):
            calculated_color = beads[i][0]
            actual_color = circle_list[i][0]

            if(calculated_color != actual_color):
                correct_color = False

        self.assertTrue(correct_color)


class TestNonFunctionalRequirements(unittest.TestCase):

    # NFR. 1-1
    def test_stitching_accuracy(self):
        pass

    # NFR. 1-2
    def test_counting_accuracy(self):
        pass


if __name__ == '__main__':
    unittest.main()
'''
MIT License

Copyright (c) 2018 LiamZ96

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
'''
# Requirements in this file: 3.1.1, 3.2.3
# Authors: Jacob Wakefield

from . import routes
import os
from flask import Flask, render_template, send_from_directory

app = Flask(__name__, instance_relative_config=True)
app.config.from_mapping(
    SECRET_KEY='dev',
    DATABASE=os.path.join(app.instance_path, 'flaskr.sqlite'),
    TEMPLATES_AUTO_RELOAD=True
)

app.config.from_pyfile('config.py', silent=True)

# ensure the instance folder exists
try:
    os.makedirs(app.instance_path)
except OSError:
    pass

# import routes after the app is created
'''
MIT License

Copyright (c) 2018 LiamZ96

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
'''
# Requirements in this file: 3.1.2, 3.1.4, 3.1.5, 3.1.11, 3.2.7, 3.3.2
# Authors: Jacob Wakefield, Noah Zeilmann, McKenna Gates, Liam Zay

# Authors: Alex Peters, Gattlin Walker, Patrick Ayres

from . import app
import json
from flask import render_template, send_from_directory, request, url_for, redirect, jsonify, send_file

from lib.counting import *
from lib.stitching import *
from lib.file_util import *

"""
    Description: a template class used for defining the detection parameters
    given from the front end.
"""


class Parameters():
    def __init__(self):
        self.wantsCrushedBeads = False
        self.wantsWaterBubbles = False
        self.detectionAlgorithm = 'avg'
        self.magnificationLevel = '4x'

        self.minDist = 10
        self.sensitivity = 50
        self.minRadius = 50
        self.maxRadius = 120


paramDict = {}

countingDict = {}  # global counting dictionary variable for regeneration of csv data. keys are timestamp directory names

"""
    Description: flask endpoint function for serving static resources
"""
@app.route('/resources/<path:path>')
def sendStaticResource(path):
    return send_from_directory('resources', path)


"""
    Description: flask endpoint function for serving the page index
"""
@app.route('/')
@app.route('/index')
def index():
    return render_template('index.html')


"""
    Description: flask endpoint function for serving the error page
"""
@app.route('/error')
def error():
    errorMessage = request.args['errorMessage']
    return render_template('error.html', error=errorMessage)


"""
    Description: flask endpoint function for POSTing images and configuration data to the server
"""
@app.route('/uploadImages', methods=["POST"])
def uploadImagesAndConfigure():

    newDir = file_util.createUploadDir()

    timestamp = newDir.split("/")[3]

    paramDict[timestamp] = Parameters()
    # convert js 'bool' to python Bool
    paramDict[timestamp].wantsCrushedBeads = True if request.args['wantsCrushed'] == 'true' else False
    paramDict[timestamp].wantsWaterBubbles = True if request.args['wantsBubbles'] == 'true' else False
    paramDict[timestamp].detectionAlgorithm = request.args['colorAlgorithm']
    paramDict[timestamp].minRadius = int(request.args['minBead'])
    paramDict[timestamp].maxRadius = int(request.args['maxBead'])

    if 'maglevel' in request.args:
        paramDict[timestamp].magnificationLevel = request.args['maglevel']

    images = request.files.getlist("images")

    if not file_util.checkImagesAndSaveToDirectory(images, newDir):
        return jsonify({"status": 1, "msg": "One or more of the images that were uploaded are in the incorrect format. Accepted formats: "
                        + (", ".join(file_util.ALLOWED_IMAGE_EXTENSIONS))})

    # redirect to homepage
    return jsonify({"status": 0, "msg": "Success", "location": newDir.replace("Server/resources/uploads", "")})


"""
    Description: flask endpoint function for stitching the images uploaded
"""
@app.route('/getStitchedImage/<path:stitchDirectory>')
def getStitchedImage(stitchDirectory):

    dirPrefix = 'Server/resources/uploads/' + stitchDirectory
    stitcher = Stitching(dirPrefix + '/images/', dirPrefix + '/maps/')
    (status, statusString) = stitcher.stitchImages_Default()

    if(statusString == "single"):
        return redirect(url_for('getResults', directory=stitchDirectory + '/maps/result_default.jpg'))
    else:
        return render_template('stitched_single.html', status=status, statusString=statusString, directory=stitchDirectory)


"""
    Description: flask endpoint for calling bead count functions
"""
@app.route('/getResults/<path:directory>')
def getResults(directory):

    resultsDirectory = directory.split("/")[0]

    countingParameters = Parameters()
    if resultsDirectory in paramDict:
        countingParameters = paramDict[resultsDirectory]
    else:
        paramDict[resultsDirectory] = countingParameters

    magLevel = ''
    if request.args.get('maglevel') == '4x' or countingParameters.magnificationLevel == '4x':
        magLevel = HoughConfig.OBJX4
    else:
        magLevel = HoughConfig.OBJX10

    serverDirectory = 'Server/resources/uploads/' + directory
    # save the counting object in a dictionary for regeneration of report data
    countingDict[resultsDirectory] = Counting(serverDirectory)

    colorBeads = countingDict[resultsDirectory].getColorBeads(
        magLevel, countingParameters)

    return render_template('results.html', colorBeads=colorBeads, waterBeads=countingDict[resultsDirectory].waterBeads,
                           crushedBeads=countingDict[resultsDirectory].crushedBeads, mapLocation=directory, resultsDirectory=resultsDirectory,
                           minDist=countingParameters.minDist,
                           sensitivity=countingParameters.sensitivity,
                           minRadius=countingParameters.minRadius,
                           maxRadius=countingParameters.maxRadius
                           )


"""
    Description: flask endpoint for setting parameters, used in recount functionality ajax updates
"""
@app.route('/setParameters', methods=['POST'])
def setParameters():
    try:
        jsonData = request.get_json()

        timestamp = jsonData['timestamp']

        countingParameters = Parameters()
        if timestamp in paramDict:
            countingParameters = paramDict[timestamp]
        else:
            paramDict[timestamp] = countingParameters

        countingParameters.minDist = int(jsonData['minDist'])
        countingParameters.sensitivity = int(jsonData['sensitivity'])
        countingParameters.minRadius = int(jsonData['minRadius'])
        countingParameters.maxRadius = int(jsonData['maxRadius'])

        return jsonify({'status': 0, 'statusString': 'Parameters successfully set'})

    except Exception as e:
        return jsonify({'status': 1, 'statusString': 'An Error occurred setting parameters'})


"""
    Description: flask endpoint for generating and downloading a .CSV file report for the user
"""
@app.route('/getResultReport/<path:directory>')
def getResultReport(directory):
    # this is the type of output we want
    colorOutputType = request.args.get('colorOutputType')
    # this is the directory we are accessing
    resDir = request.args.get('resDir')
    uploadDir = 'resources/uploads/' + resDir

    # access the stored counting variable and regen csv data
    csvTimestamp = countingDict[directory].makeBeadsCSV(colorOutputType)

    return send_file(uploadDir + '/results/' + colorOutputType + '_' + csvTimestamp + '.csv', as_attachment=True)
'''
MIT License

Copyright (c) 2018 LiamZ96

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
'''

# Authors: Alex Peters, Patrick Ayres

import csv
import colorsys

CSV_RGB_COLNAMES = ['Bead Number', 'Type', 'Red Val',
                    'Green Val', 'Blue Val', 'X-Coord', 'Y-Coord', 'Radius']
CSV_HSV_COLNAMES = ['Bead Number', 'Type', 'Hue Val',
                    'Saturation Val', 'Value Val', 'X-Coord', 'Y-Coord', 'Radius']
CSV_CMYK_COLNAMES = ['Bead Number', 'Type', 'Cyan Val', 'Magenta Val',
                     'Yellow Val', 'Black Val', 'X-Coord', 'Y-Coord', 'Radius']
CSV_GRAYSCALE_COLNAMES = ['Bead Number', 'Type',
                          'Grayscale Val', 'X-Coord', 'Y-Coord', 'Radius']

"""
    Description: function that takes beadinfo and creates a csv with varying types of color output data
    @param colorFormat: a string that is either 'rgb', 'hsv', 'cmyk', or 'grayscale'
    @return void, writes file directly from class attributes
"""


def makeBeadsCSV(filepath, colorFormat, colorBeads, crushedBeads, waterBeads):

    # RGB will be selected by default. these values will change if the colorFormat value matches below
    colNames = CSV_RGB_COLNAMES
    writeFunc = writeOutputRgb

    if colorFormat == 'hsv':
        colNames = CSV_HSV_COLNAMES
        writeFunc = writeOutputHsv
    elif colorFormat == 'cmyk':
        colNames = CSV_CMYK_COLNAMES
        writeFunc = writeOutputCmyk
    elif colorFormat == 'grayscale':
        colNames = CSV_GRAYSCALE_COLNAMES
        writeFunc = writeOutputGrayscale

    with open(filepath, mode='w', newline='') as beadFile:
        writer = csv.writer(beadFile, delimiter=',',
                            quotechar='"', quoting=csv.QUOTE_MINIMAL)
        writer.writerow(colNames)
        writeFunc(writer, colorBeads)
        addCrushedBeads(writer, colorFormat, crushedBeads)
        addWaterBeads(writer, colorFormat, waterBeads)


"""
    Description: a function that writes the color data to CSV in RGB format
    @param writer - the writer, preconfigured for the output file
    @param colorBeads - an array containing bead data from scan
    @return void
"""


def writeOutputRgb(writer, colorBeads):
    i = 1
    for bead in colorBeads:
        r = bead[0][0]
        g = bead[0][1]
        b = bead[0][2]

        x = bead[2][0]
        y = bead[2][1]
        radius = bead[2][2]

        # row is written with beadNum, r, g, b, x, y, radius
        writer.writerow([i, "Bead", r, g, b, x, y, radius])
        i += 1


"""
    Description: a function that writes the color data to CSV in HSV format
    @param writer - the writer, preconfigured for the output file
    @param colorBeads - an array containing bead data from scan
    @return void
"""


def writeOutputHsv(writer, colorBeads):
    i = 1
    for bead in colorBeads:
        # here, the colorsys conversion function expects values between 0-1 for rgb
        hsv = colorsys.rgb_to_hsv(
            bead[0][0]/255, bead[0][1]/255, bead[0][2]/255)
        h = hsv[0]
        s = hsv[1]
        # the returned values are placed in an array in the order h, s, v
        v = hsv[2]

        x = bead[2][0]
        y = bead[2][1]
        radius = bead[2][2]

        # row is written with beadNum, h, s, v, x, y, radius
        writer.writerow([i, "Bead", h, s, v, x, y, radius])
        i += 1


"""
    Description: a function that writes the color data to CSV in CMYK format
    @param writer - the writer, preconfigured for the output file
    @param colorBeads - an array containing bead data from scan
    @return void
"""


def writeOutputCmyk(writer, colorBeads):
    i = 1
    for bead in colorBeads:
        cmyk = rgbToCmyk(bead[0][0], bead[0][1], bead[0][2])
        C = cmyk[0]
        M = cmyk[1]
        Y = cmyk[2]
        # the returned values are placed in an array in the order c, m, y, k
        K = cmyk[3]

        x = bead[2][0]
        y = bead[2][1]
        radius = bead[2][2]

        # row is written with beadNum, c, m, y, k, x, y, radius
        writer.writerow([i, "Bead", C, M, Y, K, x, y, radius])
        i += 1


"""
    Description: a function that writes the color data to CSV in Grayscale format
    @param writer - the writer, preconfigured for the output file
    @param colorBeads - an array containing bead data from scan
    @return void
"""


def writeOutputGrayscale(writer, colorBeads):
    i = 1
    for bead in colorBeads:
        grayscaleValue = listAverage(bead[0])

        x = bead[2][0]
        y = bead[2][1]
        radius = bead[2][2]

        # row is written with beadNum, grayscaleValue, x, y, radius
        writer.writerow([i, "Bead",  grayscaleValue, x, y, radius])
        i += 1


"""
    Description: a function that sums the values in a list
    @param lst - the list to average
    @return the average of values in the list
"""


def listAverage(lst):
    return sum(lst) / len(lst)


"""
    Description: a function that takes an r, g, and b value and returns the corresponding CMYK values
    @param r - an int representing red 
    @param g - an int representing green
    @param b - an int representing blue
    @return a tuple of length four representing (C, M, Y, K) values
"""


def rgbToCmyk(r, g, b):
    cmyk_scale = 100

    if (r + g + b) == 0:  # bead is black
        return 0, 0, 0, cmyk_scale

    # rgb [0,255] -> cmy [0,1]
    c = 1 - (r / 255.)
    m = 1 - (g / 255.)
    y = 1 - (b / 255.)

    # extract out k [0,1]
    min_cmy = min(c, m, y)
    c = (c - min_cmy)  # / (1 - min_cmy)
    m = (m - min_cmy)  # / (1 - min_cmy)
    y = (y - min_cmy)  # / (1 - min_cmy)
    k = min_cmy

    # rescale to the range [0,cmyk_scale]
    return c*cmyk_scale, m*cmyk_scale, y*cmyk_scale, k*cmyk_scale


"""
    Description: a function that writes detected crushed beads to the output file
    @param writer - the writer, preconfigured for the output file
    @param colorFormat - a string representing the selected color format
    @param crushedBeads - a list of detected crushed beads during detection
    @return void
"""


def addCrushedBeads(writer, colorFormat, crushedBeads):

    for bead in crushedBeads:
        x = bead[2][0]
        y = bead[2][1]
        r = bead[2][2]

        if colorFormat == 'hsv':
            writer.writerow(
                ["N/A", "Crushed Bead", "N/A", "N/A", "N/A", x, y, r])
        elif colorFormat == 'cmyk':
            writer.writerow(["N/A", "Crushed Bead", "N/A",
                             "N/A", "N/A", "N/A", x, y, r])
        elif colorFormat == 'grayscale':
            writer.writerow(["N/A", "Crushed Bead", "N/A", x, y, r])
        elif colorFormat == 'rgb':
            writer.writerow(
                ["N/A", "Crushed Bead", "N/A", "N/A", "N/A", x, y, r])


"""
    Description: a function that writes detected water bubbles to the output file
    @param writer - the writer, preconfigured for the output file
    @param colorFormat - a string representing the selected color format
    @param crushedBeads - a list of detected water bubbles during detection
    @return void
"""


def addWaterBeads(writer, colorFormat, waterBeads):

    for bead in waterBeads:
        x = bead[2][0]
        y = bead[2][1]
        r = bead[2][2]

        if colorFormat == 'hsv':
            writer.writerow(
                ["N/A", "Water Bubble", "N/A", "N/A", "N/A", x, y, r])
        elif colorFormat == 'cmyk':
            writer.writerow(["N/A", "Water Bubble", "N/A",
                             "N/A", "N/A", "N/A", x, y, r])
        elif colorFormat == 'grayscale':
            writer.writerow(["N/A", "Water Bubble", "N/A", x, y, r])
        elif colorFormat == 'rgb':
            writer.writerow(
                ["N/A", "Water Bubble", "N/A", "N/A", "N/A", x, y, r])
'''
MIT License

Copyright (c) 2018 LiamZ96

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
'''
# Requirements in this file: 3.1.7, 3.1.8, 3.1.9, 3.1.10, 3.2.4, 3.2.5, 3.3.1
# Authors: Jacob Wakefield, McKenna Gates

# Authors: Patrick Ayres, Gattlin Walker, Alex Peters, Robbie Cichon

import cv2
import numpy as np
from matplotlib import pyplot as plt
import imutils
import random
import math
import itertools
import csv
import sys
import datetime
from enum import Enum
from os import listdir, path
from . import util
from lib.colorLabeler import getClosestColor, validColor

"""
    Description: an enum class to handle the HoughCircle configuration values that are used in cv2.HoughCircles().
"""


class HoughConfig(Enum):

    # 4x magnification
    OBJX4 = {"dp": 1, "minDist": 40, "param1": 50,
             "param2": 55, "minRadius": 0, "maxRadius": 75}

    # 10x magnification
    OBJX10 = {"dp": 1, "minDist": 60, "param1": 65,
              "param2": 68, "minRadius": 0, "maxRadius": 125}

    DEFAULT = {"dp": 1, "minDist": 0, "param1": 50,
               "param2": 30, "minRadius": 0, "maxRadius": 125}


"""
    Description: a class to deal with counting microbeads in a stitched image.
"""


class Counting:

    def __init__(self, imagePath):
        self.imagePath = imagePath
        self.grayScaleMap = cv2.imread(
            imagePath, 0)  # create grayscale cv2 img
        self.colorMap = cv2.imread(imagePath)  # create color cv2 img
        self.labMap = cv2.cvtColor(self.colorMap, cv2.COLOR_BGR2Lab)
        self.colorBeads = []
        self.waterBeads = []
        self.partialBeads = []
        self.crushedBeads = []

    """
        Description: a function that takes a map of images and counts the beads.
        @Param houghConfig - a HoughConfig object that contains the values for the HoughCircles() function
        @return an object containing information collected during the counting process.
    """

    def getColorBeads(self, houghConfig, detectionParams):
        houghConfig = houghConfig.value
        result = []
        cimg = cv2.cvtColor(self.grayScaleMap, cv2.COLOR_GRAY2BGR)
        circles = self.findCircles(detectionParams, houghConfig)

        if circles is not None:
            circles = np.uint16(np.around(circles))
            for i in circles[0, :]:
                # i[0] is x coordinate, i[1] is y coordinate, i[2] is radius
                # draw the outer circle
                cv2.circle(cimg, (i[0], i[1]), i[2], (0, 255, 0), 2)
                # draw the center of the circle
                cv2.circle(cimg, (i[0], i[1]), 2, (0, 0, 255), 3)

                partial = self.checkPartial(i)

                if detectionParams.detectionAlgorithm == "avg":
                    color = self.getAverageColor(i)
                elif detectionParams.detectionAlgorithm == "mid":
                    color = self.getMiddleColor(i)
                elif detectionParams.detectionAlgorithm == "corner":
                    color = self.getFourQuadrantColor(i)
                elif detectionParams.detectionAlgorithm == "rad":
                    color = self.getRadiusAverageColor(i)

                if partial:
                    self.partialBeads.append(color)
                # if the bead is a water bead, leave it out.
                elif(color[1] == 'bead'):
                    self.colorBeads.append(color)
                    result.append(color)

        if detectionParams.wantsWaterBubbles:
            self.GetWaterBubbles()

        # if the user wants to detect crushed beads.
        if detectionParams.wantsCrushedBeads:
            self.getCrushedBeads(cimg, detectionParams, houghConfig)

        imagePath = '/'.join(self.imagePath.split('/')[:-2]) + '/results/'
        imagePath += 'result_image.jpg'  # + str(fileNum) +'.jpg'
        cv2.imwrite(imagePath, cimg)

        return result

    """
        Description: a function that takes an image and finds the water bubbles in it
        @return an array with x,y coordinates for the center of each water bubble and the size of the water bubble
    """

    def GetWaterBubbles(self):
        # Read image
        im = self.colorMap
        # Create a white border around the image to detect partial water bubbles
        bordered = cv2.copyMakeBorder(im, 5, 5, 5, 5, cv2.BORDER_CONSTANT, 255)
        # Create a version of the image that makes values greater than a certain RGB value black, and those below white, then inverst it for blob detection
        lower = np.array([0, 0, 0])
        upper = np.array([120, 120, 120])
        colormask = cv2.inRange(bordered, lower, upper)
        (T, thresh) = cv2.threshold(colormask, 1, 255, cv2.THRESH_BINARY)

        # Setup SimpleBlobDetector parameters
        params = cv2.SimpleBlobDetector_Params()
        # Change thresholds
        params.minThreshold = 10
        params.maxThreshold = 200
        # Filter by Area.
        params.filterByArea = True
        params.minArea = 600
        params.maxArea = 10000
        # Filter by Circularity
        params.filterByCircularity = False
        params.minCircularity = .0
        # Filter by Convexity
        params.filterByConvexity = True
        params.minConvexity = 0.90
        # Filter by Inertia
        params.filterByInertia = True
        params.minInertiaRatio = 0.0

        # Create a detector with the parameters
        detector = cv2.SimpleBlobDetector_create(params)
        # Detect blobs.
        keypoints = detector.detect(thresh)

        # Remove keypoint if on a colored bead, and adds the size of the bubble to the array.
        NewKP = []
        for keypoint in keypoints:
            y = int(keypoint.pt[0])
            x = int(keypoint.pt[1])
            radius = np.sqrt(keypoint.size / 3.1415)
            if radius < 1:
                radius = 1
            BGRValue = im[x - 3, y - 3]
            if BGRValue[2] >= 50 and BGRValue[1] >= 50 and BGRValue[0] >= 50:
                self.waterBeads.append([[0, 0, 0], 'waterBead', [y, x, 30]])

    """
        Finds all circles in an image with the given parameters
        @param detectionParams - detection parameters used for detecting the circles
        @houghConfig - the hough config also used to detect the circles
        @return - the found circles in the image.
    """

    def findCircles(self, detectionParams, houghConfig):
        img = self.grayScaleMap
        blur = cv2.GaussianBlur(img, (7, 7), 0)
        circles = cv2.HoughCircles(blur, cv2.HOUGH_GRADIENT,
                                   dp=houghConfig["dp"],
                                   minDist=detectionParams.minDist,
                                   param1=houghConfig["param1"],
                                   param2=detectionParams.sensitivity,
                                   minRadius=detectionParams.minRadius,
                                   maxRadius=detectionParams.maxRadius)
        return circles

    """
        Description: a function that takes a cicle's RGB values and returns if it is water or not
        @param RGB - tuple containing the average red, green, and blue values of a circle
        @return a boolean that will be True if the circle is water
    """

    def isWater(self, RGB):
        red = RGB[0]
        green = RGB[1]
        blue = RGB[2]
        isWater = False

        maxRGBValue = 240
        minRGBValue = 3

        if red >= maxRGBValue and green >= maxRGBValue and blue >= maxRGBValue:
            isWater = True
        if red <= minRGBValue and green <= minRGBValue and blue <= minRGBValue:
            isWater = True
        return isWater

    """
        Description: does preprocessing on the image map to find the crushed beads.
        @param image - image that will have the final results of the counting
        @param detectionParams - detection parameters used for detecting the circles
        @houghConfig - the hough config also used to detect the circles
    """

    def getCrushedBeads(self, image, detectionParams, houghConfig):
        circleInfo = []
        knownObjects = self.colorBeads + self.waterBeads + self.partialBeads
        circles = self.findCircles(detectionParams, houghConfig)

        if circles is not None:
            circles = np.uint16(np.around(circles))
            for x, y, r in circles[0, :]:
                # to match the color layout
                circleInfo.append([[], [], [x, y, r]])

        color = self.__removeObjects(image, knownObjects + circleInfo)

        # makes background an even white color
        minBg = (235, 235, 235)
        maxBg = (255, 255, 255)
        self.__removeImgAspect(color, minBg, maxBg)

        # removes black edges caused by stitching
        minBlack = (0, 0, 0)
        maxBlack = (10, 10, 10)
        self.__removeImgAspect(color, minBlack, maxBlack)

        lab = cv2.cvtColor(color, cv2.COLOR_BGR2LAB)

        # removes black borders
        minBorder = (0, 0, 0)
        maxBorder = (180, 190, 130)
        self.__removeImgAspect(lab, minBorder, maxBorder, drawing=color)

        contours = self.__findContours(color)

        imageY = image.shape[0]
        imageX = image.shape[1]
        for c in contours:
            colorLabel = getClosestColor(self.labMap, c)
            if validColor(colorLabel):
                M = cv2.moments(c)
                if M['m00'] > 0:
                    cX = int((M["m10"] / M["m00"]))
                    cY = int((M["m01"] / M["m00"]))
                    if cX >= imageX - 50 or cY >= imageY - 50 or cX <= 50 or cY <= 50:
                        pass
                    else:
                        self.crushedBeads.append(
                            [[0, 0, 0], 'crushedBead', [cX, cY, 35]])
                        cv2.drawContours(image, [c], -1, (255, 0, 0), 4)
                        cv2.circle(image, (cX, cY), 2, (255, 0, 0), 3)

    """
        Remove the pixels in a given range. Used to remove certain objects
        from the image
        @param image - original image
        @param objects - detected objects that will be removed
        @return - the final image with the removed objects
    """

    def __removeObjects(self, image, objects):
        mask = np.ones(image.shape[:2], dtype="uint8")

        # takes the known objects (beads and water beads) and colors them black
        # so they can be ignored when detecting the crushed beads
        for bead in objects:
            bead[2][2] = int(round(bead[2][2]))
            cv2.circle(mask, (bead[2][0], bead[2][1]),
                       bead[2][2], (0, 0, 0), -1)
            cv2.circle(mask, (bead[2][0], bead[2][1]),
                       bead[2][2], (0, 0, 0), 16)

        color = cv2.bitwise_and(self.colorMap, self.colorMap, mask=mask)

        return color

    """
        Description: Gets the locations of pixels within a given bound and colors
        them white so they will not be picked up during image detection
        @param img - the image used to find the pixels withing a given range
        @param minBound - the lower bound of a pixel's color intensity
        @param maxBound - the upper bound of a pixel's color intensity
        @param drawing - an optional parameter in case the image the results need to be drawn on
                        is different than the image the range detection was performed on.
    """

    def __removeImgAspect(self, img, minBound, maxBound, drawing=None):
        # if no drawing image is given then it becomes the original img
        if drawing is None:
            drawing = img

        aspect = cv2.inRange(img, minBound, maxBound)
        imgOutput, contours, hierarchy = cv2.findContours(
            aspect, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        for c in contours:
            cv2.drawContours(drawing, [c], -1, (255, 255, 255), -1)

    """
        Finds the contours left in the image
        @param image: image used to find the contours
        @return: the contours found on the image
    """

    def __findContours(self, image):
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        blur = cv2.GaussianBlur(gray, (31, 31), 0)
        thresh = cv2.threshold(blur, 225, 255, cv2.THRESH_BINARY_INV)[1]
        erosion = cv2.erode(thresh, None, iterations=4)
        imgOutput, contours, hierarchy = cv2.findContours(
            erosion, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        gray = blur = thresh = erosion = None

        return contours

    def checkPartial(self, circle):
        img = self.colorMap
        imgY = img.shape[0]
        imgX = img.shape[1]
        x = circle[0]
        y = circle[1]
        radius = circle[2]

        if x + radius >= imgX or y + radius >= imgY:
            return True
        else:
            return False

    """
        Description: a function that takes an array representing a circle's[x-coord of center, y-coord of center, radius]
                    and returns a list containing tuple with the bead's average RGB values of the pixels within that bead
        @param circleInfo - array that contains a circle's x and y coordinates of the center and the radius of the circle
        @return a list containing tuple with average RGB values of top 10% from bead, boolean isWater, and x,y,radius value of the bead.
    """

    def getAverageColor(self, circleInfo):
        img = self.colorMap
        imgY = img.shape[0]
        imgX = img.shape[1]
        x = circleInfo[0]
        y = circleInfo[1]
        radius = circleInfo[2]
        reds, greens, blues = [], [], []

        points = self.getPointsInCircle(radius, x, y)
        coordinates = list(points)

        for xCoord, yCoord in coordinates:
            if (xCoord >= imgX) or (yCoord >= imgY):
                pass
            else:
                bgrValue = img[yCoord, xCoord]
                reds.append(bgrValue[2])
                greens.append(bgrValue[1])
                blues.append(bgrValue[0])

        average = (round(np.mean(reds), 2), round(
            np.mean(greens), 2), round(np.mean(blues), 2))
        isWater = self.isWater(average)
        type = 'waterBead' if isWater else 'bead'
        # [[R,G,B], isWater, [x,y,radius]]
        return [[average[0], average[1], average[2]], type, [circleInfo[0], circleInfo[1], circleInfo[2]]]

    """
        Description: a function that takes an array representing a circle's[x-coord of center, y-coord of center, radius]
                    and returns a list containing tuple with the bead's average RGB values of the middle 10% of pixels withing the bead
        @param circleInfo - array that contains a circle's x and y coordinates of the center and the radius of the circle
        @return a list containing tuple with average RGB values of top 10% from bead, boolean isWater, and x,y,radius value of the bead.
    """

    def getMiddleColor(self, circleInfo):
        img = self.colorMap
        imgY = img.shape[0]
        imgX = img.shape[1]
        x = circleInfo[0]
        y = circleInfo[1]
        radius = circleInfo[2]
        reds, greens, blues = [], [], []

        points = self.getPointsInCircle(radius/4, x, y)
        coordinates = list(points)

        for xCoord, yCoord in coordinates:
            if (xCoord >= imgX) or (yCoord >= imgY):
                pass
            else:
                bgrValue = img[yCoord, xCoord]
                reds.append(bgrValue[2])
                greens.append(bgrValue[1])
                blues.append(bgrValue[0])

        average = (round(np.mean(reds), 2), round(
            np.mean(greens), 2), round(np.mean(blues), 2))
        isWater = self.isWater(average)
        type = 'waterBead' if isWater else 'bead'
        # [[R,G,B], isWater, [x,y,radius]]
        return [[average[0], average[1], average[2]], type, [circleInfo[0], circleInfo[1], circleInfo[2]]]

    """
        Description: a function that takes an array representing a circle's[x-coord of center, y-coord of center, radius]
                    and returns a list containing tuple with the bead's average RGB values of the radius average pixels within that bead
        @param circleInfo - array that contains a circle's x and y coordinates of the center and the radius of the circle
        @return a list containing tuple with average RGB values of top 10% from bead, boolean isWater, and x,y,radius value of the bead.
    """

    def getRadiusAverageColor(self, circleInfo):
        img = self.colorMap
        imgY = img.shape[0]
        imgX = img.shape[1]
        x = circleInfo[0]
        y = circleInfo[1]
        radius = circleInfo[2]
        reds, greens, blues = [], [], []

        for xCoord in range(x - radius + 5, x + radius - 5):
            if(xCoord >= imgX):
                pass
            else:
                bgrValue = img[y, xCoord]
                reds.append(bgrValue[2])
                greens.append(bgrValue[1])
                blues.append(bgrValue[0])

        average = (round(np.mean(reds), 2), round(
            np.mean(greens), 2), round(np.mean(blues), 2))
        isWater = self.isWater(average)
        type = 'waterBead' if isWater else 'bead'
        # [[R,G,B], isWater, [x,y,radius]]
        return [[average[0], average[1], average[2]], type, [circleInfo[0], circleInfo[1], circleInfo[2]]]

    """
        Description: a function that takes an array representing a circle's[x-coord of center, y-coord of center, radius]
                    and returns a list containing tuple with the bead's average RGB values of each of the four quadrants within the bead
        @param circleInfo - array that contains a circle's x and y coordinates of the center and the radius of the circle
        @return a list containing tuple with average RGB values of top 10% from bead, boolean isWater, and x,y,radius value of the bead.
    """

    def getFourQuadrantColor(self, circleInfo):
        img = self.colorMap
        imgY = img.shape[0]
        imgX = img.shape[1]
        x = circleInfo[0]
        y = circleInfo[1]
        radius = circleInfo[2]
        reds, greens, blues = [], [], []

        for i in range(0, 4):
            currentPoints = self.getPointsInCircle(radius/10, x + math.ceil((radius/2) * math.cos(
                math.radians(90*i + 45))), y + math.ceil((radius/2) * math.sin(math.radians(90*i + 45))))
            currentCoordinates = list(currentPoints)

            for xCoord, yCoord in currentCoordinates:
                if (xCoord >= imgX) or (yCoord >= imgY):
                    pass
                else:
                    bgrValue = img[yCoord, xCoord]
                    reds.append(bgrValue[2])
                    greens.append(bgrValue[1])
                    blues.append(bgrValue[0])

        average = (round(np.mean(reds), 2), round(
            np.mean(greens), 2), round(np.mean(blues), 2))
        isWater = self.isWater(average)
        type = 'waterBead' if isWater else 'bead'
        # [[R,G,B], isWater, [x,y,radius]]
        return [[average[0], average[1], average[2]], type, [circleInfo[0], circleInfo[1], circleInfo[2]]]

    """
        Description: a function that takes a bead's radius and x and y coordinates of the center and returns coordinates of every point in
                    the bead
        @param radius - radius of bead
        @param centerX - X coordinate of the center of bead
        @param centerY - Y coordinate of the center of bead
        @return a zip of the coordinates within a circle
    """

    def getPointsInCircle(self, radius, centerX, centerY):
        a = np.arange(radius + 1)
        for x, y in zip(*np.where(a[:, np.newaxis]**2 + a**2 <= radius**2)):
            # x and y given here were assuming that the center was at 0,0 therefore you must add the actual center coordinates to give accurate ones back
            yield from set(((centerX + x, centerY + y), (centerX + x, centerY - y), (centerX - x, centerY + y), (centerX - x, centerY - y),))

    """
        Description:
        @param colorFormat: a string that is either 'rgb', 'hsv', 'cmyk', or 'grayscale'
        @return void, writes file directly from class attributes
    """

    def makeBeadsCSV(self, colorFormat):
        newPath = self.imagePath
        endIndex = newPath.rfind("/")
        newPath = newPath[:endIndex]
        newPath = newPath.replace("maps", "results")
        currentTime = datetime.datetime.now()
        currentTimeString = currentTime.strftime("%Y-%m-%dT%H-%M-%S")

        if colorFormat == "rgb":
            newPath = newPath + '/rgb_' + currentTimeString + '.csv'
        elif colorFormat == "hsv":
            newPath = newPath + '/hsv_' + currentTimeString + '.csv'
        elif colorFormat == "cmyk":
            newPath = newPath + '/cmyk_' + currentTimeString + '.csv'
        elif colorFormat == "grayscale":
            newPath = newPath + '/grayscale_' + currentTimeString + '.csv'

        util.makeBeadsCSV(newPath, colorFormat, self.colorBeads,
                          self.crushedBeads, self.waterBeads)
        return currentTimeString
'''
MIT License

Copyright (c) 2018 LiamZ96

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
'''

# Authors: Alex Peters

import cv2
import imutils
import datetime
import os
from imutils import paths
from werkzeug.utils import secure_filename

ALLOWED_IMAGE_EXTENSIONS = set(['jpg', 'jpeg'])

"""
    Description: a function that takes a directory string and returns a list of images
    @param path - a string indicating the directory on the server's filesystem to read images from 
    @return a list of opencv images
"""


def readImagesFromDirectory(path):
    imagePaths = sorted(list(imutils.paths.list_images(path)))
    images = []
    for imagePath in imagePaths:
        image = cv2.imread(imagePath)
        images.append(image)
    return images


"""
    Description: a function that writes an image to a directory
    @param path - string that indicates directory to write to
    @param image - opencv image data to write to directory
    @return void
"""


def writeImage(path, image):
    cv2.imwrite(path, image)


"""
    Description: a function used to see if the uploaded file is in a valid format.
    @Param filename - name of the file being uploaded.
    @Param extensionList - set of allowed file extensions.
    @return a boolean indicating whether the image is in an acceptable format or not.
"""


def isFileAllowed(filename, extensionList):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in extensionList


def createUploadDir():
    # create new folder to hold users data for run
    uploadDir = 'Server/resources/uploads'
    now = datetime.datetime.now()
    newFolder = now.strftime("%Y-%m-%dT%H-%M-%S")
    newDir = uploadDir + "/" + newFolder
    os.mkdir(newDir)
    subfolders = ['images', 'videos', 'maps', 'results', 'uploads']
    for folder in subfolders:
        subDir = newDir + "/" + folder
        os.mkdir(subDir)
    return newDir


"""
    Description: a function that takes an array representing a set of images and a string representing a directory to write to.
                    checks if images are of the correct format and renames them to a secure filename
    @param images - array that contains a set of opencv images
    @param directory - string that specifies the directory to save images to
    @return a boolean indicating whether or not operation was successful
"""


def checkImagesAndSaveToDirectory(images, directory):
    for i in images:
        if not isFileAllowed(i.filename, ALLOWED_IMAGE_EXTENSIONS):
            return False
        imgPath = directory + "/images/" + str(secure_filename(i.filename))
        i.save(imgPath)
    return True
'''
MIT License

Copyright (c) 2018 LiamZ96

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
'''

# Requirements in this file: 3.1.6, 3.2.4, 3.2.6
# Authors: Noah Zeilmann, Josiah Carpenter

# Authors: Alex Peters

import cv2
import numpy as np
import os
from matplotlib import pyplot as plt
import time
import sys
from PIL import Image, ExifTags
import shutil
import multiprocessing as mp
from collections import OrderedDict
import imutils
from imutils import paths
from . import file_util

"""
        Description: a class to deal with stitching images together and handling overlap of the images.
"""


class Stitching:
    def __init__(self, sourceDirectory, resultsDirectory):
        self.images = []
        self.sourceDirectory = self.setDirectory(sourceDirectory)
        self.resultsDirectory = resultsDirectory
        self.results = []

    """
		Description: a method that stitches the images configured to this object
		@return an opencv image of the stitched image
	"""

    def stitchImages_Default(self):

        if(len(self.images) < 2):
            file_util.writeImage(self.resultsDirectory +
                                 'result_default.jpg', self.images[0])
            return (0, 'single')

        else:
            stitcher = cv2.createStitcher(False)
            print(len(self.images))
            (status, stitched) = stitcher.stitch(self.images)

            if status != 0:
                print(status)
                blank_image = np.zeros((50, 50, 3), np.uint8)
                file_util.writeImage(
                    self.resultsDirectory + 'result_default.jpg', blank_image)
                return (status, 'An error occured while stitching.')

            file_util.writeImage(self.resultsDirectory +
                                 'result_default.jpg', stitched)
            return (status, 'Success.')

    """
		Description: a function setting the directory where images are contained for this object.
				uses the file_utils file to read file recursively with imutils
		@param path - The directory in unix format
	"""

    def setDirectory(self, path):
        # Get directory of test images
        self.sourceDirectory = os.path.abspath(
            os.path.join(os.path.dirname(__file__), "..", path))

        # and pass that directory into the file_util to recursively read all images from that dir
        self.images = file_util.readImagesFromDirectory(self.sourceDirectory)

    """
		Description: a setter for the object's directory path
		@param path - a string that indicates the path to set in the object
		@return void
	"""

    def setResultsDirectory(self, path):
        self.resultsDirectory = path
'''
MIT License

Copyright (c) 2018 LiamZ96

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
'''

# Authors: Gattlin Walker

import cv2
import numpy as np
import math

"""
	Finds the closest color associated with a contour
	@param img -  image the contours are found
	@param conotour - a given contour found on the image.
"""


def getClosestColor(img, contour):
    # colors given in LAB color space
    colors = [
        ("red", (136, 208, 195)),
        ("green", (224, 42, 211)),
        ("blue", (82, 207, 20)),
        ("black", (0, 128, 128)),
        ("yellow", (248, 106, 223)),
        ("darkblue", (10, 157, 86)),
        ("gray", (104, 128, 128)),
        ("darkgray", (76, 128, 128)),
        ("white", (255, 128, 128)),
        ("lightblue", (203, 117, 100)),
    ]

    mask = np.zeros(img.shape[:2], dtype="uint8")
    cv2.drawContours(mask, [contour], -1, 255, -1)
    mean = cv2.mean(img, mask=mask)

    closestPair = ('color', math.inf)

    for key, value in colors:
        distance = euclidean(value, mean[:3])
        if distance < closestPair[1]:
            closestPair = (key, distance)

    return closestPair[0]


"""
	Euclidean distance formula to find the similarity between two entries
	@param entry1 - first entry being compared
	@param entry2 - second entry being compared
	@return the distance between the two entries
"""


def euclidean(entry1, entry2):
    distance = 0

    for i in range(len(entry1)):
        distance += (entry1[i] - entry2[i]) ** 2

    return distance ** 0.5


"""
	Determines if the color is valid and not a blacklisted color
	@param color - string of the given color
	@return - boolean if the color is not in the colors to ignore
"""


def validColor(color):
    colorsToIgnore = ['darkgray', 'darkblue', 'black', 'white']
    return color not in colorsToIgnore
'''******************************************************************************************************************************************************************************************************
Copyright (c) 2019, Missouri State University
All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
*Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
*Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.
*Neither the name of the Missouri State University nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, 
THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. 
IN NO EVENT SHALL MISSOURI STATE UNIVERSITY BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, 
PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, 
STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

Created By Context-based-device-suggestion (Majordomo) - Group 3 CSC 450 Fall 2019 
Instructor: Dr. Razib Iqbal
Group Members: 
    Keven McDowell
    Hailey Martinelli
    Brandon Norman
    Julie Sweeney
    Brett Largent
    Lauren Tallerico

This file functions as the secondary server for speech processing.  It handles processing commands and context-based processing.  It recieves requests containing audio streams from the audio receiver file
and calls upon the speech_interpretter file to process the streams into a string.  Once it gets a string back, it checks to see if it is a command. If it is, the command is recognized and the proper
state associated with that command is sent to the raspberry pi server for execution.  If the text is not a command, it goes through context processing, where each word in the string is queried in the
database to see if it matches any part of speech that the processing is looking for.  It checks for context words, extremity words, state of being words, and tries to check against location.  It also checks
to see if a word is associated with a positvie or a negative change. Each found word type builds a result object.  After the text is iterated through, the processing checks for positive and negative words, as
well as for state of being words in order to determine the "state" and desire of the user. Once processing is done, a query is made for a state that matches the final values of the result object and 
is sent to the raspberry pi so devices can be manipulated.
******************************************************************************************************************************************************************************************************'''

# Importing needed modules
from flask import Flask, request, jsonify
import requests
import speech_interperter as SI
import context_resolution_db as CR
import json
from gtts import gTTS
from playsound import playsound
import os
from random import randint
import time

app = Flask(__name__)

# Route for receiving an audio stream from the audio receiver.
@app.route('/processSpeech', methods=["POST"])
def getSpeech():
    # change ip to match where the raspberry pi server is running.
    raspberryPiUrl = "http://169.254.29.8:5001/sendState"
    #raspberryPiUrl = "http://192.168.86.177:5001/sendState"
    #ifraspberryPiUrl = "http://localhost:5001/sendState"
    result = SI.getText(request)
    stateObj = CR.checkString(result)
    if stateObj != None:
        print("State: ", stateObj)

        payload = stateObj
        headers = {"content-type": "application/json"}
        try:
            req = requests.post(
                raspberryPiUrl, data=json.dumps(payload), headers=headers)
            print("Sent State to Raspberry Pi Successfully.")
        except Exception as e:
            print(e)
            print("Failed to Send State to Raspberry Pi.")
    return "OK"

# Route for receiving messages to be announced to the user.
@app.route('/alertUser', methods=["POST"])
def speak():
    text = request.json
    speech = gTTS(text=text, lang='en', slow=False)
    # Some stupid file permissions issue. These all go away when you kill the server.
    filename = "speech" + str(time.time()) + ".mp3"
    speech.save(filename)
    playsound(filename)
    removeStupidStubbornFile(filename)
    return "OK"

# Route for grabbing all commands associated with a device.
@app.route("/getCommands", methods=["POST"])
def getCommands():
    device = request.json.get("device")
    commandConfigs = CR.getCommandConfigs()
    commands = []

    for command in commandConfigs:
        if commandConfigs.get(command).get("device") == device:
            commandObj = {"text": command, "state": commandConfigs.get(
                command).get("state"), "device": device}
            commands.append(commandObj)

    return jsonify(commands)

# Route for editting commands associated with a device.
@app.route("/editCommands", methods=["POST"])
def editCommands():
    commands = request.json
    device = None
    commandConfigs = CR.getCommandConfigs()
    for command in commands:
        device = command.get("device")
        if not commandConfigs.get(command.get("text")):
            commandConfigs[command.get("text")] = {"device": command.get(
                "device"), "command": True, "state": command.get("state")}
            addClassifier(command.get("text"))

    removeCommands = []
    print("Removing Commands.")
    print("Commands: ", commands)

    for command in commandConfigs:
        foundCommand = False
        for com in commands:
            if com.get("text") == command:
                foundCommand = True
        if commandConfigs.get(command).get("device") == device and not foundCommand:
            removeCommands.append(command)

    print("Commands to remove: ", removeCommands)
    for command in removeCommands:
        del commandConfigs[command]
        deleteClassifier(command)

    CR.saveCommandConfigs(commandConfigs)
    return "OK"

# Route for deleting commands associated with a device.
@app.route("/deleteCommands", methods=["POST"])
def deleteCommands():
    device = request.json.get("device")
    delCommands = []
    commandConfigs = CR.getCommandConfigs()
    for command in commandConfigs:
        if commandConfigs.get(command).get("device") == device:
            delCommands.append(command)
            deleteClassifier(command)

    for command in delCommands:
        del commandConfigs[command]

    CR.saveCommandConfigs(commandConfigs)
    return "OK"


def removeStupidStubbornFile(name):
    '''
    Function for removing the sound files.
    '''
    os.remove(name)


def addClassifier(command):
    '''
    Function for adding a classifier associated with a command to the classifiers file.
    '''
    contents = None
    with open("classifiers_30.txt", "r") as classifiers:
        contents = classifiers.readlines()
        contents.append(command + "\n")
        classifiers.close()

    with open("classifiers_30.txt", "w") as classifiers:
        for command in contents:
            print(command)
            classifiers.write(command)

        classifiers.close()


def deleteClassifier(command):
    '''
    Function for deleting a classifier associated with a command.
    '''
    contents = None
    with open("classifiers_30.txt", "r") as classifiers:
        contents = classifiers.readlines()
        for classifier in contents:
            if classifier.strip() == command.lower():
                contents.remove(contents[contents.index(classifier)])
        classifiers.close()

    with open("classifiers_30.txt", "w") as classifiers:
        for command in contents:
            classifiers.write(command)

    with open("classifiers_30.txt", "r") as classifiers:
        contents = classifiers.read()
        contents.strip()
        classifiers.close()

    with open("classifiers_30.txt", "w") as classifiers:
        classifiers.write(contents)


if __name__ == "__main__":
    # Change to IP of local machine. Localhost will not expose the server on the network.
    # app.run(host="192.168.86.185", port=5000)  # Wifi
    app.run(host="169.254.20.68", port=5000)  # wired
    # app.run(host="localhost", port=5000)  # local
'''******************************************************************************************************************************************************************************************************
Copyright (c) 2019, Missouri State University
All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
*Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
*Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.
*Neither the name of the Missouri State University nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, 
THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. 
IN NO EVENT SHALL MISSOURI STATE UNIVERSITY BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, 
PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, 
STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

Created By Context-based-device-suggestion (Majordomo) - Group 3 CSC 450 Fall 2019 
Instructor: Dr. Razib Iqbal
Group Members: 
    Keven McDowell
    Hailey Martinelli
    Brandon Norman
    Julie Sweeney
    Brett Largent
    Lauren Tallerico

This file exposes an api for various database use cases, some of which are not used for our system, but could likely be leveraged in the next iteration of the project.  Functions include procedures for
looking up words in the database, adding words, adding states, adding word types, and checking the type associated with a word. The database used is implemented Sqlite3 and uses the Sqlite3 library from
Python to facilitate the database connection and query execution.

******************************************************************************************************************************************************************************************************'''

"""
This file can be imported for any interaction with the context database
Functions:

add_word_type(word_type)
    -adds the given word_type (context word) to the Word_Types table

add_word_types(word_types)
    -calls add_word_type() for each item in the array word_types

add_word(word, word_type)
    -add word to the Words table and associates it with the word_type
    -returns false if word_type is not in the Word_Types table
    -returns false if word is alreayd in the Words table

add_words(words, word_type)
    -calls add_word() for each word in words
    -applys the same given word_type to all words

add_state(state, word_type, extremity_level)
    -adds an state to the States table associated with word_type and extremity_level
    -returns false if word_type is not in the Word_Types table
    -returns false if state is alreayd in the States table
    -may need tinkering after we understad how the actuators work

check_word(word)
    -returns the context of the given word
    -if word = chilly
    -return = cold

check_words(words)
    -returns an array of unique context words associated with the words in the given list

get_words(word_type)
    -returns an array of all words in Words table associated with the given word_type
"""




import sqlite3
def add_words(words, word_type):
    '''
    for adding batches of words
    words can be an array
    word_type should be a single value
    '''
    for word in words:
        add_word(word, word_type)


def add_word_types(word_types):
    '''
    for adding batches of word_types
    word_types can be an array
    '''
    for word_type in word_types:
        add_word_type(word_type)


def add_word(word, word_type):
    '''
    auto generates and ID and adds word with FK word_type
    word_type must already be in the DB
    prints to console if word_type is not already in the DB
    '''
    word = word.lower()
    word_type = word_type.lower()

    conn = sqlite3.connect('wordDB.db')
    c = conn.cursor()

    c.execute("SELECT 1 FROM Words WHERE word=?", (word,))
    item_exists = c.fetchone()
    if (item_exists):
        return False

    c.execute("SELECT MAX(id) FROM Words")
    max_id = c.fetchone()

    if (max_id[0]):
        next_id = max_id[0] + 1
    else:
        next_id = 1

    c.execute("SELECT id FROM Word_Types WHERE word_type=?", (word_type,))
    word_type_id = c.fetchone()

    if (word_type_id):
        with conn:
            c.execute("INSERT INTO Words VALUES (?, ?, ?)",
                      (next_id, word, word_type_id[0]))
        return True
    else:
        return False

    conn.close()


def add_word_type(word_type):
    '''
    auto generates and ID and adds the word_type
    '''
    word_type = word_type.lower()

    conn = sqlite3.connect('wordDB.db')
    c = conn.cursor()

    c.execute("SELECT 1 FROM Word_Types WHERE word_type=?", (word_type,))
    item_exists = c.fetchone()
    if (item_exists):
        return False

    c.execute("SELECT MAX(id) FROM Word_Types")
    max_id = c.fetchone()

    if (max_id[0]):
        next_id = max_id[0] + 1
    else:
        next_id = 1

    with conn:
        c.execute("INSERT INTO Word_Types VALUES (?, ?)", (next_id, word_type))

    conn.close()


def add_state(action, word_type, extremity_level):
    '''
    Grabs the state from the database associated with the word type and extremity provided.
    '''
    action = action.lower()
    word_type = word_type.lower()
    extremity_level = extremity_level.lower()

    conn = sqlite3.connect('wordDB.db')
    c = conn.cursor()

    c.execute("SELECT 1 FROM STATES WHERE state=?", (action,))
    item_exists = c.fetchone()
    if (item_exists):
        return False

    c.execute("SELECT MAX(id) FROM STATES")
    max_id = c.fetchone()

    if (max_id[0]):
        next_id = max_id[0] + 1
    else:
        next_id = 1

    c.execute("SELECT id FROM Word_Types WHERE word_type=?", (word_type,))
    word_type_id = c.fetchone()

    if (word_type_id):
        with conn:
            c.execute("INSERT INTO STATES VALUES (?, ?, ?, ?)",
                      (next_id, action, word_type_id[0], extremity_level))
    else:
        print("Word type not found in database")

    conn.close()


def check_word(word):
    '''
    returns the context of the given word
    if word = freezing
    return = cold
    '''
    word = word.lower()
    conn = sqlite3.connect('wordDB.db')
    c = conn.cursor()

    c.execute("SELECT word_type_id FROM Words WHERE word=?", (word,))
    word_type_id = c.fetchone()

    if (word_type_id):
        c.execute("SELECT word_type FROM Word_Types WHERE id=?",
                  (word_type_id[0],))
        word_type = c.fetchone()
        return word_type[0]

    else:
        return None


def check_words(words):
    '''
    Function for grabbing contexts associated with the words provided.
    '''
    contexts = []
    for word in words:
        context = check_word(word)
        if (context not in contexts and context != False):
            contexts.append(context)
    return contexts


def get_words(word_type):
    '''returns all words of specific word_type'''
    word_type = word_type.lower()

    conn = sqlite3.connect('wordDB.db')
    c = conn.cursor()

    c.execute("SELECT id FROM Word_Types WHERE word_type=?", (word_type,))
    word_type_id = c.fetchone()

    if (word_type_id):
        c.execute("SELECT word FROM Words WHERE word_type_id=?",
                  (word_type_id[0],))
        words = c.fetchall()
    else:
        return False

    if (words):
        return words
    else:
        return False


def get_state(context, extremity):
    '''
    Function for grabbing the state associated with the context and extremity provided.
    '''
    conn = sqlite3.connect('wordDB.db')
    c = conn.cursor()
    c.execute(
        "SELECT STATES.STATE FROM STATES JOIN WORD_TYPES ON STATES.WORD_TYPE_ID = WORD_TYPES.ID WHERE WORD_TYPES.WORD_TYPE = ? AND EXTREMITY_LEVEL = ?",
        (context, extremity))
    return c.fetchone()
'''******************************************************************************************************************************************************************************************************
Copyright (c) 2019, Missouri State University
All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
*Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
*Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.
*Neither the name of the Missouri State University nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, 
THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. 
IN NO EVENT SHALL MISSOURI STATE UNIVERSITY BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, 
PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, 
STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

Created By Context-based-device-suggestion (Majordomo) - Group 3 CSC 450 Fall 2019 
Instructor: Dr. Razib Iqbal
Group Members: 
    Keven McDowell
    Hailey Martinelli
    Brandon Norman
    Julie Sweeney
    Brett Largent
    Lauren Tallerico

This program allows us to simulate a machine listening to make changes to the environment prompted by particular phrases.
The user will input a phrase such as "I'm cold"
Please remember to use quotes around your input so that python knows it's a string
The program will evalute if the sentence contains a trigger word.
If the word matches a phrase, an adjustment will be chosen by the program.
The program will continue prompting for another sentence until the user says "stop listening"
note:
listenFor is a seperate function from selectAdjustment because it requires less processing power
and does not call selectAdjustment unless a context word is found. The user should not
be given the choice of whether to turn on the fan or lower the temperature because the machine
will make the optimal decision for the user once permission is given.
***The user will be allowed to say "cancel" once Major Domo makes an adjustment if
they do not desire a change in state. The program will then return to main and continue listening
for another context word.

******************************************************************************************************************************************************************************************************'''
import sqlite3
import database_manager as DB
import json


def listenFor(userInput):
    '''Compares the words in userInput to the words in tempPhrases and lightPhrases.
        If a match is found, call selectAdjustment.
        Otherwise, return to main'''
    context = {"Temperature_Hot": True, "Temperature_Cold": True,
               "Light_Bright": True, "Light_Dark": True}
    type_res = {"Temperature_Hot": {"change": "context", "value": "Temperature_Hot"},
                "Light_Dark": {"change": "context", "value": "Light_Dark"},
                "Light_Bright": {"change": "context", "value": "Light_Bright"},
                "Temperature_Cold": {"change": "context", "value": "Temperature_Cold"},
                "Extremity": {"change": "extremity", "value": True},
                "Positive": {"change": "positive", "value": True},
                "Negative": {"change": "negative", "value": True},
                "Location_Elsewhere": {"change": "location_elsewhere", "value": True},
                "State_Of_Being": {"change": "state", "value": True},
                "Location_Here": {"change": "location_here", "value": True}}
    result = {"context": None, "extremity": False,
              "negative": False, "positive": False, "desire": None,
              "state": False, "in": False, "location_here": False, "location_elsewhere": False}
    for word in userInput:
        res = DB.check_word(word)
        print("Word Type: ", res)
        if result.get("in"):
            if res != "Location_Here" and not result.get("location_here"):
                result["context"] = None
                break
            if res == "Location_Elsewhere":
                result["context"] = None
                break
            else:
                if res != None:
                    result[type_res[res]["change"]] = type_res[res]["value"]
        else:
            if res != None:
                w_type = res
                print(w_type)
                if context.get(res) and result.get("context"):
                    result["extremity"] = False
                result[type_res[w_type]["change"]] = type_res[w_type]["value"]
        if word == "in" or word == "In":
            result["in"] = True

    if result["context"] != None:
        print("Context found: processing....")
        result["desire"] = determineDesire(result)
        result["desire"] = processState(result)
        if not bool(result["desire"]) and not result["state"]:
            print("No desire or state.")
            return
        if result["desire"] == None:
            print("No desire found....")
            return
        if result["location_elsewhere"]:
            print("Talking about somewhere else....")
            return
        state = getState(result)
        if state != None:
            return state
        else:
            print("Could not resolve action....")
            return None
    else:
        print("No context was able to be resolved from the current speech...")
        return None


def getState(result):
    '''
     Function for grabbing the state from the database that corresponds with the processed result.
    '''
    dbQueryParams = {"Temperature_Hot": "Temperature_Cold" if result["desire"] == "positive" else "Temperature_Hot",
                     "Temperature_Cold": "Temperature_Hot" if result["desire"] == "positive" else "Temperature_Cold",
                     "Light_Bright": "Light_Dark" if result["desire"] == "positive" else "Light_Bright",
                     "Light_Dark": "Light_Bright" if result["desire"] == "positive" else "Light_Dark"}
    dbres = DB.get_state(
        dbQueryParams[result["context"]], "High" if result["extremity"] else "Low")
    if dbres != None:
        return {"state": dbres[0]}  # The actual action to be done.
    else:
        return dbres


def executeCommand(command):
    '''
    Function for grabbing and returning a command.
    '''
    commands = commandConfigs
    print("Current Command: ", command)
    currCommand = commands.get(command)
    if currCommand:
        return currCommand
    else:
        return None


def determineDesire(result):
    '''Uses rules of the English dialect to determine if the user has a positive or
        negative connotation towards the temperature or light word used.'''
    negative = result["negative"]
    positive = result["positive"]
    if (negative == True and positive == True):
        # if the user says a negative word or (no negative or positive words)
        # the desire towards the environmental word is negative
        # example: It wish it weren't cold.  weren't == negative  wish == positive
        desire = "negative"

    elif positive == True and negative == False:
        # if the user says a positive word with no negative words
        # the desire towards the environmental word is positive
        # example: I want it cold.  want == positive
        desire = "positive"

    else:
        desire = None
        # example: I am not cold.
        # example: I was not cold.
    print(desire)

    return desire


def processState(res):
    '''
    Function for changing the desire based on the presence of state of being words.
    '''
    desire = res["desire"]
    if res["state"]:
        if not res["negative"]:
            desire = "negative"
    return desire


def checkString(dataForDomo):
    '''
    Function for taking in a string and executing a command if it matches a command, or processing it using
    context processing otherwise.
    '''
    # if userInput resolved to a command
    # go directly to execute command

    if dataForDomo.get("command"):
        print("The command exists")
        return executeCommand(dataForDomo["phrase"])

    # elif see if userInput can resolve by context
    else:
        userInput = dataForDomo["phrase"].split()
        return listenFor(userInput)


def getCommandConfigs():
    '''
    Function for loading in the command configurations.
    '''
    with open("commandConfig.json", "r") as commandConf:
        configs = json.load(commandConf)
        commandConf.close()
        return configs


def saveCommandConfigs(configs):
    '''
    Function for saving the command configurations.
    '''
    with open("commandConfig.json", "w") as commandConf:
        json.dump(configs, commandConf)
        commandConf.close()
        return getCommandConfigs()


commandConfigs = getCommandConfigs()
'''******************************************************************************************************************************************************************************************************
Copyright (c) 2019, Missouri State University
All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
*Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
*Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.
*Neither the name of the Missouri State University nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, 
THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. 
IN NO EVENT SHALL MISSOURI STATE UNIVERSITY BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, 
PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, 
STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

Used By Context-based-device-suggestion (Majordomo) - Group 3 CSC 450 Fall 2019 
Instructor: Dr. Razib Iqbal
Group Members: 
    Keven McDowell
    Hailey Martinelli
    Brandon Norman
    Julie Sweeney
    Brett Largent
    Lauren Tallerico

This code was written by Dr. Iqbal and one of his graduate students and was repurposed by our group for this project.

This code is responsible for recording audio that comes in through the microphone. Whenever two seconds of silence is detected, the audio buffer is sent to the Majordomo server for
context processing.  The program detects ambient noise on startup and determines the threshold at which it will start recording.  It keeps track of the sound levels by maintaining s queue that is constantly
updated with sound values.  Once it finishes recording after two seconds of silence, it sends the audio stream to the Majordomo server, where it is processed.
******************************************************************************************************************************************************************************************************'''

# Importing needed modules
import pyaudio
import audioop
from collections import deque
import requests
import socket
import math
import json
import base64
import time

# Function for grabbing speech input and sending it to the Majordomo server for processing.


def postJson(list_of_byte_stream, sample_size):
    """
    list_of_byte_stream: byte stream in a list to be sent to middleware after packaging.
    sample_size: length of sample in seconds; class variable that is neeeded to be used on the middleware for the decoding.
    """

    b = b"".join(list_of_byte_stream)   # joining into one byte stream
    encoded = base64.b64encode(b)       # encoding byte stream to base 64.
    # Change IP to match where Majordomo server is running.
    # url = "http://192.168.86.185:5000/processSpeech"      # Server URL
    #url = "http://localhost:5000/processSpeech"
    url = "http://169.254.20.68:5000/processSpeech"

    payload = {'raw audio': encoded.decode("utf-8"),
               'sample size': sample_size}

    # Location to be added here
    headers = {'content-type': 'application/json'}

    try:
        r = requests.post(url, data=json.dumps(payload), headers=headers)
        print("stream successfully sent")
    except requests.exceptions.ConnectionError:
        print("Connection to the middleware failed...")


class SpeechDetector:
    def __init__(self):
        # Microphone stream config.
        self.CHUNK = 1024  # CHUNKS of bytes to read each time from mic
        self.FORMAT = pyaudio.paInt16
        self.CHANNELS = 1
        self.RATE = 16000

        self.SILENCE_LIMIT = 2  # Silence limit in seconds. The max ammount of seconds where
        # only silence is recorded. When this time passes the
        # recording finishes and the file is decoded

        # Previous audio (in seconds) to prepend. When noise
        self.PREV_AUDIO = 0.5
        # is detected, how much of previously recorded audio is
        # prepended. This helps to prevent chopping the beginning
        # of the phrase.

        self.MAX_AUDIO = 5  # Max time audio will record in seconds. If listening
        # longer than 5 seconds, recording will stop and
        # audio will be sent to middleware.

        self.THRESHOLD = 1000
        self.num_phrases = -1

    def setup_mic(self, num_samples=50):
        """ Gets average audio intensity of your mic sound. You can use it to get
            average intensities while you're talking and/or silent. The average
            is the avg of the .2 of the largest intensities recorded.
        """

        print("Getting intensity values from mic.")
        p = pyaudio.PyAudio()
        stream = p.open(format=self.FORMAT,
                        channels=self.CHANNELS,
                        rate=self.RATE,
                        input=True,
                        frames_per_buffer=self.CHUNK)

        values = [math.sqrt(abs(audioop.avg(stream.read(self.CHUNK), 4)))
                  for x in range(num_samples)]
        values = sorted(values, reverse=True)
        r = sum(values[:int(num_samples * 0.2)]) / int(num_samples * 0.2)
        print(" Finished ")
        # higher this value is, the higher intensity it needs to start recording
        print(" Average audio intensity is ", r)
        stream.close()
        p.terminate()

        if r < 400:
            self.THRESHOLD = 500
        else:
            self.THRESHOLD = r + 200

    def run(self):
        """
        Listens to Microphone, stores the byte stream information to be sent to middleware for the decoding.
        """

        self.setup_mic()

        # Open stream
        p = pyaudio.PyAudio()
        stream = p.open(format=self.FORMAT,
                        channels=self.CHANNELS,
                        rate=self.RATE,
                        input=True,
                        frames_per_buffer=self.CHUNK)
        print("* Mic set up and listening. ")

        time_info = []
        audio2send = []
        cur_data = ''  # current chunk of audio data
        rel = self.RATE/self.CHUNK
        slid_win = deque(maxlen=int(self.SILENCE_LIMIT * rel))
        max_audio = deque(maxlen=int(self.MAX_AUDIO * rel))

        # Prepend audio from 0.5 seconds before noise was detected
        prev_audio = deque(maxlen=int(self.PREV_AUDIO * rel))
        started = False

        start = 0
        elapsed = 0
        while True:
            cur_data = stream.read(self.CHUNK)
            slid_win.append(math.sqrt(abs(audioop.avg(cur_data, 4))))
            max_audio.append(math.sqrt(abs(audioop.avg(cur_data, 4))))
            if not start == 0:
                elapsed = time.time() - start
            if elapsed >= 5:
                start = 0
                elapsed = 0
                # Sending the request over to middleware
                postJson(list(prev_audio) + audio2send,
                         p.get_sample_size(pyaudio.paInt16))
                print("Finished recording, sending phrase\n")

                # Reset all
                started = False
                slid_win = deque(maxlen=int(self.SILENCE_LIMIT * rel))
                prev_audio = deque(maxlen=int(0.5 * rel))
                max_audio = deque(maxlen=int(self.MAX_AUDIO * rel))
                audio2send = []
                print("Listening ...")
            if sum([x > self.THRESHOLD for x in slid_win]) > 0:
                if started == False:
                    print("Starting recording of phrase")
                    started = True
                    start = time.time()

                audio2send.append(cur_data)

            elif started:
                start = 0
                elapsed = 0
                # Sending the request over to middleware
                postJson(list(prev_audio) + audio2send,
                         p.get_sample_size(pyaudio.paInt16))
                print("Finished recording, sending phrase\n")

                # Reset all
                started = False
                slid_win = deque(maxlen=int(self.SILENCE_LIMIT * rel))
                prev_audio = deque(maxlen=int(0.5 * rel))
                max_audio = deque(maxlen=int(self.MAX_AUDIO * rel))
                audio2send = []
                print("Listening ...")

            else:
                prev_audio.append(cur_data)

        print("* Done listening")
        stream.close()
        p.terminate()


if __name__ == "__main__":
    sd = SpeechDetector()
    sd.run()
'''******************************************************************************************************************************************************************************************************
Copyright (c) 2019, Missouri State University
All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
*Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
*Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.
*Neither the name of the Missouri State University nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, 
THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. 
IN NO EVENT SHALL MISSOURI STATE UNIVERSITY BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, 
PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, 
STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

Written by Dr. Iqbal and one of his graduate students.
Used By Context-based-device-suggestion (Majordomo) - Group 3 CSC 450 Fall 2019 
Instructor: Dr. Razib Iqbal
Group Members: 
    Keven McDowell
    Hailey Martinelli
    Brandon Norman
    Julie Sweeney
    Brett Largent
    Lauren Tallerico

This module handles semantic analysis of audio that comes in using the natural language tool kit library for python.
******************************************************************************************************************************************************************************************************'''
import nltk
import math
import numpy as np

from nltk.corpus import wordnet as wn
from nltk.corpus import brown

nltk.download('brown', download_dir="nltk_data")
nltk.download('wordnet', download_dir="nltk_data")
nltk.download('averaged_perceptron_tagger', download_dir="nltk_data")
nltk.download('punkt', download_dir="nltk_data")

ALPHA = 0.2
BETA = 0.45
ETA = 0.4
PHI = 0.2
DELTA = 0.85
SIMILARITY_THRESHOLD = 80

brown_freqs = dict()
N = 0


def get_best_synset_pair(word_1, word_2):
    """ 
    Choose the pair with highest path similarity among all pairs. 
    Mimics pattern-seeking behavior of humans.
    """

    #print("starting get best synset pair")
    max_sim = -1.0
    synsets_1 = wn.synsets(word_1)
    synsets_2 = wn.synsets(word_2)
    if len(synsets_1) == 0 or len(synsets_2) == 0:
        return None, None
    else:
        max_sim = -1.0
        best_pair = None, None
        for synset_1 in synsets_1:
            for synset_2 in synsets_2:
                sim = wn.path_similarity(synset_1, synset_2)
                if sim != None:
                    if sim > max_sim:
                        max_sim = sim
                        best_pair = synset_1, synset_2
        return best_pair


def hierarchy_dist(synset_1, synset_2):
    """
    Return a measure of depth in the ontology to model the fact that 
    nodes closer to the root are broader and have less semantic similarity
    than nodes further away from the root.
    """

    #print("starting hierarchy dist")
    # h_dist = sys.maxint
    h_dist = float("inf")
    if synset_1 is None or synset_2 is None:
        return h_dist
    if synset_1 == synset_2:
        # Return the depth of one of synset_1 or synset_2
        h_dist = max([x[1] for x in synset_1.hypernym_distances()])
    else:
        # Find the max depth of least common subsumer
        hypernyms_1 = {x[0]: x[1] for x in synset_1.hypernym_distances()}
        hypernyms_2 = {x[0]: x[1] for x in synset_2.hypernym_distances()}
        lcs_candidates = set(hypernyms_1.keys()).intersection(
            set(hypernyms_2.keys()))
        if len(lcs_candidates) > 0:
            lcs_dists = []
            for lcs_candidate in lcs_candidates:
                lcs_d1 = 0
                if lcs_candidate in hypernyms_1:
                    lcs_d1 = hypernyms_1[lcs_candidate]
                lcs_d2 = 0
                if lcs_candidate in hypernyms_2:
                    lcs_d2 = hypernyms_2[lcs_candidate]
                lcs_dists.append(max([lcs_d1, lcs_d2]))
            h_dist = max(lcs_dists)
        else:
            h_dist = 0
    return ((math.exp(BETA * h_dist) - math.exp(-BETA * h_dist)) /
            (math.exp(BETA * h_dist) + math.exp(-BETA * h_dist)))


def length_dist(synset_1, synset_2):
    '''
    Return a measure of the length of the shortest path in the semantic 
    ontology (Wordnet in our case as well as the paper's) between two 
    synsets.
    '''

    #print("starting length dist")
    #l_dist = sys.maxint
    l_dist = float("inf")
    if synset_1 is None or synset_2 is None:
        return 0.0
    if synset_1 == synset_2:
        # If synset_1 and synset_2 are the same synset return 0
        l_dist = 0.0
    else:
        wset_1 = set([str(x.name()) for x in synset_1.lemmas()])
        wset_2 = set([str(x.name()) for x in synset_2.lemmas()])
        if len(wset_1.intersection(wset_2)) > 0:
            # If synset_1 != synset_2 but there is word overlap, return 1.0
            l_dist = 1.0
        else:
            # Just compute the shortest path between the two
            l_dist = synset_1.shortest_path_distance(synset_2)
            if l_dist is None:
                l_dist = 0.0
    # Normalize path length to the range [0,1]
    return math.exp(-ALPHA * l_dist)


def word_similarity(word_1, word_2):
    #print("starting word similarity")
    synset_pair = get_best_synset_pair(word_1, word_2)
    return (length_dist(synset_pair[0], synset_pair[1]) *
            hierarchy_dist(synset_pair[0], synset_pair[1]))

    #####---------- Sentence Similarity ----------#####


def info_content(lookup_word):
    """
    Uses the Brown corpus available in NLTK to calculate a Laplace
    smoothed frequency distribution of words, then uses this information
    to compute the information content of the lookup_word.
    """

    #print("starting info content")
    global N
    if N == 0:
        # Poor man's lazy evaluation
        for sent in brown.sents():
            for word in sent:
                word = word.lower()
                if word not in brown_freqs:
                    brown_freqs[word] = 0
                brown_freqs[word] = brown_freqs[word] + 1
                N = N + 1
    lookup_word = lookup_word.lower()
    n = 0 if lookup_word not in brown_freqs else brown_freqs[lookup_word]
    return 1.0 - (math.log(n + 1) / math.log(N + 1))


def most_similar_word(word, word_set):
    """
    Find the word in the joint word set that is most similar to the word
    passed in. We use the algorithm above to compute word similarity between
    the word and each word in the joint word set, and return the most similar
    word and the actual similarity value.
    """

    #print("starting msot similar word")
    max_sim = -1.0
    sim_word = ""
    for ref_word in word_set:
        sim = word_similarity(word, ref_word)
        if sim > max_sim:
            max_sim = sim
            sim_word = ref_word
    return sim_word, max_sim


def semantic_similarity(sentence_1, sentence_2, info_content_norm):
    """
    Computes the semantic similarity between two sentences as the cosine
    similarity between the semantic vectors computed for each sentence.
    """

    #print("starting semantic similarity")
    words_1 = nltk.word_tokenize(sentence_1)
    words_2 = nltk.word_tokenize(sentence_2)
    joint_words = set(words_1).union(set(words_2))
    vec_1 = semantic_vector(words_1, joint_words, info_content_norm)
    vec_2 = semantic_vector(words_2, joint_words, info_content_norm)
    return np.dot(vec_1, vec_2.T) / (np.linalg.norm(vec_1) * np.linalg.norm(vec_2))


def semantic_vector(words, joint_words, info_content_norm):
    """
    Computes the semantic vector of a sentence. The sentence is passed in as
    a collection of words. The size of the semantic vector is the same as the
    size of the joint word set. The elements are 1 if a word in the sentence
    already exists in the joint word set, or the similarity of the word to the
    most similar word in the joint word set if it doesn't. Both values are 
    further normalized by the word's (and similar word's) information content
    if info_content_norm is True.
    """

    #print("starting semantic vector")
    sent_set = set(words)
    semvec = np.zeros(len(joint_words))
    i = 0
    for joint_word in joint_words:
        if joint_word in sent_set:
            # If word in union exists in the sentence, s(i) = 1 (unnormalized)
            semvec[i] = 1.0
            if info_content_norm:
                semvec[i] = semvec[i] * math.pow(info_content(joint_word), 2)
        else:
            # Find the most similar word in the joint set and set the sim value
            sim_word, max_sim = most_similar_word(joint_word, sent_set)
            semvec[i] = PHI if max_sim > PHI else 0.0
            if info_content_norm:
                semvec[i] = semvec[i] * \
                    info_content(joint_word) * info_content(sim_word)
        i = i + 1
    return semvec

    #####---------- Word Order Similarity ----------######


def word_order_similarity(sentence_1, sentence_2):
    """
    Computes the word-order similarity between two sentences as the normalized
    difference of word order between the two sentences.
    """

    #print("Starting word order similarity")
    words_1 = nltk.word_tokenize(sentence_1)
    words_2 = nltk.word_tokenize(sentence_2)
    joint_words = []
    for word in words_1:
        joint_words.append(word)
    for word in words_2:
        if word not in joint_words:
            joint_words.append(word)
    windex = {}
    for x in range(1, len(joint_words)+1):
        windex[joint_words[x-1]] = x
        # print(windex)
    #joint_words = list(set(words_1).union(set(words_2)))
    #windex = {x[1]: x[0] for x in enumerate(joint_words)}
    r1 = word_order_vector(words_1, joint_words, windex)
    r2 = word_order_vector(words_2, joint_words, windex)
    return 1 - (np.linalg.norm(r1 - r2) / np.linalg.norm(r1 + r2))


def word_order_vector(words, joint_words, windex):
    """
    Computes the word order vector for a sentence. The sentence is passed
    in as a collection of words. The size of the word order vector is the
    same as the size of the joint word set. The elements of the word order
    vector are the position mapping (from the windex dictionary) of the 
    word in the joint set if the word exists in the sentence. If the word
    does not exist in the sentence, then the value of the element is the 
    position of the most similar word in the sentence as long as the similarity
    is above the threshold ETA.
    """

    #print("starting word order vector")
    wovec = np.zeros(len(joint_words))
    i = 0
    wordset = set(words)
    for joint_word in joint_words:
        if joint_word in wordset:
            # Word in joint_words found in sentence, just populate the index
            wovec[i] = windex[joint_word]
        else:
            # Word not in joint_words, find most similar word and populate
            # Word_vector with the thresholded similarity
            sim_word, max_sim = most_similar_word(joint_word, wordset)
            if max_sim > ETA:
                wovec[i] = windex[sim_word]
            else:
                wovec[i] = 0
        i = i + 1
    return wovec

    #####---------- Overall Similarity ----------#####


def get_synonyms(word):
    '''
    Function used by phrase_library_creation to get a list of synonyms for a word.
    '''

    synonyms = []
    s = wn.synsets(word)
    #
    #print("synonym from " + word + ":", s)
    for synset in wn.synsets(word):
        #print("current synset:", synset)
        #print("hyponyms of current synset:",synset.hyponyms())
        if '.v.' in synset.name():
            for lemma in synset.lemmas():
                #print("current lemma:",lemma)
                name = lemma.name()
                # print("name:",name)
                # if (name not in synonyms):
                if (name not in synonyms and name != word and "_" not in name):
                    #print("added to syn list")
                    synonyms.append(name)
    return synonyms


def phrase_library_creation(CLASSIFIERS):
    '''
    phrase_library_creation() takes classifiers and creates a possible input
    phrases using synonyms and stores them in a variable. The variable will be
    used to initially populate the cache with the goal of reducing time for
    an active run cycle.
    '''

    cache = {}
    for classifier in CLASSIFIERS:
        #print("current classifier:",classifier)
        words = classifier.split()
        #print("splitted words:",words)
        keyword = words[0]
        non_keyword_part = " ".join(str(word) for word in words[1:])
        #print("non_keyword partk:",non_keyword_part)
        # print("keyword:",keyword)
        synonyms = get_synonyms(keyword)
        #print("current synonyms:",synonyms)
        for syn in synonyms:
            #print("current synonym:", syn)
            phrase = syn + " " + non_keyword_part
            #print("new phrase:",phrase)
            # phrase_list.append(phrase.rstrip())
            cache[phrase] = "Lab_mic1" + ",," + classifier
    #PHRASE_LIBRARY = phrase_list

    # print(PHRASE_LIBRARY)                                                 #DEBUG
    return cache
'''******************************************************************************************************************************************************************************************************
Copyright (c) 2019, Missouri State University
All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
*Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
*Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.
*Neither the name of the Missouri State University nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, 
THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. 
IN NO EVENT SHALL MISSOURI STATE UNIVERSITY BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, 
PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, 
STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

Created By Context-based-device-suggestion (Majordomo) - Group 3 CSC 450 Fall 2019 
Instructor: Dr. Razib Iqbal
Group Members: 
    Keven McDowell
    Hailey Martinelli
    Brandon Norman
    Julie Sweeney
    Brett Largent
    Lauren Tallerico

This module is responsible for handling loading, saving, editing, and deleting configurations, as well as changing device states.
An AcChanger class is implemented here, which contains methods for turning devices on and off specific to breadboard and smartplugs.
On startup this class is instantiated and held in memory so that it can be referenced and used throughout execution. The class is responsible for
reading configurations from json files and holding them in memory so they can be changed or deleted and used for manipulating devices.  It is also responsible for saving configurations in memory back into
the json files. Users can manipulate the json files directly for configuration or use the UI exposed from the Raspberry PI server.
This module exposes functions that are called from the Raspberry Pi server. These functions then immediately interact with the AcChanger class.

******************************************************************************************************************************************************************************************************'''
# Importing needed modules
from pyHS100 import Discover, SmartPlug
import RPi.GPIO as GPIO
import time
import datetime
import json
import copy

# Class definition for the Actuator Changer class.


class AcChanger():
    # Constructor method called when the class is instantiated.
    def __init__(self):
        # Initializing variables.
        self._configFiles = {
            "deviceConfig": "actuatorConfig.json", "changesConfig": "changesConfig.json"}
        self._rawConfigs = {}
        self._actuators = {}
        self._lastChange = {}
        self._changes = {}

        # Loading in Configurations from JSON files.
        self.loadConfigurations()

    # Method for loading in configurations from json files.
    def loadConfigurations(self):
        with open(self._configFiles.get("deviceConfig"), "r") as devConf:
            self._actuators = json.load(devConf)
            devConf.close()

        with open(self._configFiles.get("changesConfig"), "r") as changeConf:
            self._changes = json.load(changeConf)
            changeConf.close()

        self._rawConfigs = self._actuators
    # Initializing SmartPlugs

    # Method for saving device configurations into json files.
    def saveConfigurations(self):
        with open(self._configFiles.get("deviceConfig"), "w") as devConf:
            json.dump(self._actuators, devConf)
            devConf.close()

        with open(self._configFiles.get("changesConfig"), "w") as changeConf:
            json.dump(self._changes, changeConf)
            changeConf.close()

    # Save device configurations whenever a config is added or changed.
    def saveConfigEdits(self, config):
        device = config.get("device")
        devConfig = config.get("config")
        commands = config.get("commands")
        self._actuators[device] = devConfig
        changes = config.get("states")

        # Loops through each state sent in with a configuration and saves it to the self._changes object
        for change in changes:
            # If there is a change set for the current state.
            if change.get(list(change.keys())[0]) != None:
                currChangeSet = self._changes.get(
                    change.get(list(change.keys())[0])).get("devices")  # Current change set is the array of device changes associated with the current state.
                foundDev = False
                # For each device change in the current change set.
                for ch in currChangeSet:
                    if len(list(ch.keys())) and list(ch.keys())[0] == device:
                        # The device was found in the current array.
                        foundDev = True
                        # Deletes the change from the change set if the new configured state is none.
                        if change.get("status") == "None":
                            del currChangeSet[currChangeSet.index(ch)]
                        else:
                            # Otherwise replaces it with the new configured state.
                            if ch.get(list(ch.keys())[0]) != change.get(list(change.keys())[0]):
                                ch[list(ch.keys())[0]] = change.get("status")

                # If the device is not already present in the change set.
                if not foundDev and change.get("status") != "None" and change.get("status") != None:
                    status = change.get("status")
                    # Appends if the state is off to appease sibling/opposite device logic.
                    if status == "OFF":
                        self._changes[change.get(list(change.keys())[0])]["devices"].append(
                            {device: status})
                    # Prepends if the state is on to appease sibling/opporsite device logic.
                    if status == "ON":
                        self._changes[change.get(list(change.keys())[0])]["devices"].insert(0,
                                                                                            {device: status})

                # Filters out empty dictionaries from the change sets.
                filter(None, currChangeSet)

        # For each command sent in with the configuration to be saved.
        for comm in commands:
            state = None
            if comm.get("state") != "Stable":  # Stable == Off, otherwise the state is On
                state = comm.get("device") + " On"

            if state != None:
                if self._changes.get(state) == None:
                    # Builds a new change config object for the command "state"
                    self._changes[state] = {}
                self._changes[state]["devices"] = []
                autoTurnOff = config.get("offDevices")
                for dev in autoTurnOff:
                    self._changes[state]["devices"].append({dev: "OFF"})
                self._changes[state]["devices"].append({device: "ON"})

        # Saves and updates the configurations in memory.
        self.saveConfigurations()
        self.loadConfigurations()

    # Method for handling deleteing a configuration for a device.
    def deleteConfig(self, device):
        del self._actuators[device]

        # Deletes references to the device from sibling/opposite devices
        for dev in self._actuators:
            config = self._actuators.get(dev)
            if config.get("oppositeDevice") == device:
                self._actuators[dev]["oppositeDevice"] = None
            if config.get("siblingDevice") == device:
                self._actuators[dev]["siblingDevice"] = None

        # Deletes commands and removes the device from state change sets.
        for key in list(self._changes.keys()):
            if key.find(device) > -1:
                del self._changes[key]
        for changeSet in self._changes:
            devices = self._changes.get(changeSet).get("devices")
            for dev in devices:
                if list(dev.keys())[0] == device:
                    del devices[devices.index(dev)]

            # Removes empty dictionaries from change sets.
            filter(None, devices)

        self.saveConfigurations()  # Saves configurations and reloads them.
        self.loadConfigurations()

    # Method for changing smart plug device to be ON or OFF.
    def changeSmartPlug(self, deviceName, state, command=False):
        # Logic for handling sibling devices and turning the current device on or off through a smart plug.
        siblingDevice = acChanger.getActuators().get(deviceName).get("siblingDevice")
        if state == "ON":
            # Logic for substituting sibling devices when the current device has too many consecutive uses
            device = acChanger.checkCount(deviceName, siblingDevice, command)
        else:
            device = deviceName

        # If the device is substituted and is on the breadboard,function for handling breadboard devices is called.
        if self._actuators.get(device).get("type") != "SmartPlug":
            return acChanger.changeBreadBoard(device, state)
        else:
            # Changing the smart plug state.
            try:
                if state == "ON":
                    SmartPlug(self._actuators.get(
                        device).get("device")).turn_on()
                    self._actuators.get(device)["ON"] = True
                else:
                    SmartPlug(self._actuators.get(
                        device).get("device")).turn_off()
                    self._actuators.get(device)["ON"] = False
                return True
            except:
                return False

    # Method for sending power to a pin for a breadboard device.
    def powerPin(self, pin, power):
        # Needed to prevent changes getting lost because they are happening too fast.
        time.sleep(0.1)
        # Must set the board mode to set pins, and must set the pin to output mode.
        GPIO.setmode(GPIO.BOARD)
        GPIO.setup(int(pin), GPIO.OUT)

        if power == "high":  # Provide power to the pin to actually turn it on.
            GPIO.output(int(pin), GPIO.HIGH)
        else:
            GPIO.output(int(pin), GPIO.LOW)

    # Function for turning off a device on the breadboard.
    def killPin(self, pin):  # Change pin back to input mode to turn off.
        GPIO.setmode(GPIO.BOARD)
        GPIO.setup(int(pin), GPIO.IN)

    # Method for handling changing devices connected to the breadboard.
    def changeBreadBoard(self, deviceName, desiredState, command=False):
        siblingDevice = acChanger.getActuators().get(deviceName).get("siblingDevice")
        if desiredState == "ON":
            # Logic for substituting the sibling device when the current device has too many consecutive uses.
            device = acChanger.checkCount(deviceName, siblingDevice, command)
        else:
            device = deviceName

        # If the device was substituted with a smart plug device, smart plug logic is called.
        if self._actuators.get(device).get("type") != "BreadBoard":
            return acChanger.changeSmartPlug(device, desiredState)
        else:
            # Logic for turning on/off a device on the breadboard.
            pin = self._actuators.get(device).get("pin")
            power = self._actuators.get(device).get("power")
            if desiredState == "OFF":
                if self._actuators.get(device)["ON"] is True:
                    self._actuators.get(device)["ON"] = False
                    self.killPin(pin)
                    return True
                else:
                    return False
            else:
                isOn = self._actuators.get(device).get("ON")
                if isOn is False:
                    self._actuators.get(device)["ON"] = True
                    self.powerPin(pin, power)
                    return True
                else:
                    return False

    # Function for checking the number of consecutive uses a device has gotten
    # in order to determine whether the sibling should be substituted
    # so that no device is ever completely ignored.
    def checkCount(self, device, siblingDevice, command):
        deviceCount = self._actuators.get(device).get("consecutiveUses")
        if deviceCount == 10:
            if command == True:
                return device
            else:
                self._actuators.get(device)["consecutiveUses"] = 0
                # siblingDevice should be incremented in its associated type
                # changeType function (changeSmartPlug() or changeBreadBoard())
                if self._actuators.get(device).get("type") == self._actuators.get(siblingDevice).get("type"):
                    self._actuators.get(siblingDevice)["consecutiveUses"] = 1
                return siblingDevice

        else:
            self._actuators.get(device)["consecutiveUses"] = deviceCount + 1
            return device

    # Getter method for getting the list of acturator states.
    def getActuators(self):
        return self._actuators

    def getRawConfigs(self):
        return self._rawConfigs

    # Getter method for getting the change configurations for each device.
    def getChange(self, stateObj):
        return self._changes.get(stateObj.get("state"))

    # Getter method for returning the current change configuration set for all devices.
    def getChanges(self):
        return self._changes

    # Getter method for getting the type associated with a device.
    def getDeviceType(self, device):
        return self._actuators.get(device).get("type")

    # Getter method for getting a device from self._lastChange
    def getLastChangeState(self):
        return self._lastChange.get("devices")

    # Getter method for getting the timestamp from self._lastChange
    def getLastChangeTimestamp(self):
        return self._lastChange.get("timestamp")

    # Setter method for updating whether device is on in self._lastChange
    def setLastChangeState(self):
        self._lastChange["devices"] = copy.deepcopy(self._actuators)

    # Setter method for updating the timestamp in self._lastChange
    def setLastChangeTimestamp(self):
        self._lastChange["timestamp"] = datetime.datetime.now()


########################### This is the code ran when this file is imported.#########################################
# Turn off everything when the device turns on.
acChanger = AcChanger()
acChanger.loadConfigurations()
GPIO.cleanup()
for ac in acChanger.getActuators():
    if acChanger.getActuators().get(ac).get("type") == "SmartPlug":
        SmartPlug(acChanger.getActuators().get(ac).get("device")).turn_off()
    else:
        acChanger.killPin(acChanger.getActuators().get(ac).get("pin"))

# Establish self._lastChange devices on startup
acChanger.setLastChangeState()
# Establish timestamp in self._lastChange on startup
acChanger.setLastChangeTimestamp()
#####################################################################################################################

# -------------------- Functions exposed from the module ----------------------------

# Function called by the raspberry pi server to toggle a device on or off when a request
# comes in from the UI.


def toggleDevice(dev, status):
    state = dev + " " + status if status != "Stable" else "Stable"
    return changeState({"device": dev, "state": state, "command": True})

# Function called by the raspberry pi server for saving configuration edits
# or new device configurations that are being added.


def saveConfigEdits(configs):
    acChanger.saveConfigEdits(configs)

# Function for grabbing the current configurations loaded.


def getConfigs():
    return acChanger.getActuators()

# Function for grabbing the current changes associated with a device that
# have been configured.


def getChanges(device):
    allChanges = acChanger.getChanges()
    deviceChanges = []

    for state in allChanges:
        if allChanges.get(state).get("context"):
            found = False
            for dev in allChanges.get(state).get("devices"):
                if dev.get(device):
                    found = True
                    change = {"state": state, "status": dev.get(device)}
                    deviceChanges.append(change)
            if not found:
                change = {"state": state, "status": "None"}
                deviceChanges.append(change)

    return deviceChanges

# Function for grabbing devices that should automatically turn off when
# a specific device is turned on.


def getOffDevices(commands):
    offDevices = []
    for command in commands:
        changes = acChanger.getChanges().get(command.get("state"))
        if changes:
            devices = acChanger.getChanges().get(command.get("state")).get("devices")
            if devices:
                for dev in devices:
                    if len(list(dev.keys())):
                        device = list(dev.keys())[0]
                        if dev.get(device) == "OFF":
                            offDevices.append(device)

    return offDevices

# Function for deleting a device configuration.


def deleteConfig(device):
    acChanger.deleteConfig(device)

# Function called by the raspberryPi server that takes in the desired state and changes
# and manipulates devices in order to enact the changes.
# Also returns the alert to be read to the user.


def changeState(stateObj):
    # Functions are first class citizens in python!
    changes = {"SmartPlug": acChanger.changeSmartPlug,
               "BreadBoard": acChanger.changeBreadBoard}
    state = stateObj.get("state")
    alertString = ""
    devicesTurnedOff = {}
    devicesTurnedOn = {}
    if state == "Stable":  # Handles stable state for turning off a device.
        acChanger.setLastChangeState()
        deviceType = acChanger.getActuators().get(stateObj.get("device")).get("type")
        if (changes.get(deviceType)(stateObj.get("device"), "OFF", True)):
            alertString = ("I'm turning off the {}".format(
                stateObj.get("device")))
    elif state == "Cancel":  # Handles cancel state
        actuatorList = acChanger.getActuators()
        lastChange = acChanger.getLastChangeState()
        lastChangeHMS = (acChanger.getLastChangeTimestamp().hour*60*60) + (
            acChanger.getLastChangeTimestamp().minute*60) + (acChanger.getLastChangeTimestamp().second)
        currentTime = datetime.datetime.now()
        currentHMS = (currentTime.hour*60*60) + \
            (currentTime.minute*60) + (currentTime.second)

        if ((currentTime.year == acChanger.getLastChangeTimestamp().year) and
            (currentTime.month == acChanger.getLastChangeTimestamp().month) and
            (currentTime.day == acChanger.getLastChangeTimestamp().day) and
                (currentHMS - lastChangeHMS <= 300)):
            for dev in lastChange:
                if lastChange.get(dev).get("ON") != actuatorList.get(dev).get("ON"):
                    deviceType = acChanger.getDeviceType(dev)
                    if lastChange.get(dev).get("ON"):
                        change = "ON"
                    else:
                        change = "OFF"
                    changes.get(deviceType)(dev, change)
            alertString = "Reverted to previous state"
    else:
        change = acChanger.getChange(stateObj)

        # Update self._lastChange
        acChanger.setLastChangeState()
        acChanger.setLastChangeTimestamp()

        counter = 0
        # For each change that needs to happen for a state.
        for dev in change.get("devices"):
            # Get name of device that needs to be changed.
            deviceName = list(dev.keys())[0]
            # Get ON or OFF from the _changes dictionary associated with the state passed.
            newState = dev.get(deviceName)
            # Get the device type from the _actuators dictionary.
            deviceType = acChanger.getDeviceType(deviceName)

            # Reference to the list of actuators
            actuatorList = acChanger.getActuators()

            # Opposite and sibling devices for the current device.
            oppositeDevice = actuatorList.get(deviceName).get("oppositeDevice")
            siblingDevice = actuatorList.get(deviceName).get("siblingDevice")

            # If the opposite device is on, we want it to just turn off the first time. Next time this context resolution happens and the
            # opposite device is off, the original device will turn on.
            # Ex. if Very cold, first time space header and central heating turn off.
            # Next time air conditioner turns on.
            if stateObj.get("command"):
                if actuatorList.get(deviceName).get("ON") == True:
                    alertString = ("The {} is already on.".format(
                        deviceName))
                else:
                    alertString = ("I'm turning {} the {}".format(
                        newState, deviceName))
                changes.get(actuatorList.get(deviceName).get("type"))(
                    deviceName, newState, True)

            else:
                # Handles device changes for devices in change sets for states that are not cmomands.
                # Changes the state of the device and then sets the alert to be read to the user based on the change.
                if newState == "ON":
                    # Handles turning on a device in a change set.
                    if oppositeDevice:
                        oppositeSibling = actuatorList.get(
                            actuatorList.get(oppositeDevice).get("siblingDevice"))

                    # Opposite Device and Opposite sibling alert logic.
                    if (oppositeDevice and actuatorList.get(oppositeDevice).get("ON") == True) or (oppositeDevice and (oppositeSibling and oppositeSibling.get("ON") == True)):
                        if actuatorList.get(oppositeDevice).get("ON") == True:
                            print("Should announct opposite device")
                            alertString = ("The {} is on. Turning that off first".format(
                                actuatorList.get(oppositeDevice)))
                        elif oppositeSibling and oppositeSibling.get("ON") == True:
                            print("Should announce opposite sibling")
                            alertString = ("The {} is on. Turning that off first".format(
                                actuatorList.get(oppositeDevice).get("siblingDevice")))
                        # do nothing
                    else:
                        print(
                            "Opposite device and opposite sibling not detected to be on.")
                        isOn = actuatorList.get(deviceName).get("ON")
                        if isOn == False:
                            if actuatorList.get(deviceName).get("consecutiveUses") >= 10:
                                if (changes.get(deviceType)(deviceName, newState)):
                                    alertString = ("I'm turning on the {}".format(
                                        actuatorList.get(deviceName).get("siblingDevice")))

                            elif (changes.get(deviceType)(deviceName, newState)):
                                alertString = (
                                    "I'm turning on the {}".format(deviceName))
                                devicesTurnedOn[deviceName] = True
                        else:
                            if (changes.get(actuatorList.get(siblingDevice).get("type"))(siblingDevice, newState)):
                                alertString = ("{} is already on. I'm turning on the {}".format(
                                    deviceName, siblingDevice))
                                devicesTurnedOn[siblingDevice] = True
                if newState == "OFF":
                    # Handles turning off a device in a change set.
                    counter += 1
                    if not actuatorList.get(deviceName).get("ON"):
                        if siblingDevice and actuatorList.get(siblingDevice).get("ON"):
                            if (changes.get(actuatorList.get(siblingDevice).get("type"))(siblingDevice, newState)):
                                alertString = ("{} is already off, turning off the {}".format(
                                    deviceName, siblingDevice))
                                devicesTurnedOff[siblingDevice] = True
                    else:
                        if (changes.get(actuatorList.get(deviceName).get("type"))(deviceName, newState)):
                            alertString = (
                                "Turning off the {}".format(deviceName))
                            devicesTurnedOff[deviceName] = True
    if len(list(devicesTurnedOn.keys())) > 1 or len(list(devicesTurnedOff.keys())) > 1:
        alertString = ""
    if len(list(devicesTurnedOff.keys())) > 1:
        devicesStr = ""
        for device in devicesTurnedOff:
            if device != list(devicesTurnedOff.keys())[len(list(devicesTurnedOff.keys()))-1]:
                devicesStr += device + ", "
            else:
                devicesStr += "and " + device
        alertString += (
            "The" + devicesStr + "were turned off.")

    if len(list(devicesTurnedOn.keys())) > 1:
        devicesStr = ""
        for device in devicesTurnedOn:
            if device != list(devicesTurnedOn.keys())[len(list(devicesTurnedOn.keys()))-1]:
                devicesStr += device + ", "
            else:
                devicesStr += "and " + device
        alertString += (
            "The" + devicesStr + "were turned on.")

    return alertString
'''******************************************************************************************************************************************************************************************************
Copyright (c) 2019, Missouri State University
All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
*Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
*Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.
*Neither the name of the Missouri State University nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, 
THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. 
IN NO EVENT SHALL MISSOURI STATE UNIVERSITY BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, 
PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, 
STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

Created By Context-based-device-suggestion (Majordomo) - Group 3 CSC 450 Fall 2019 
Instructor: Dr. Razib Iqbal
Group Members: 
    Keven McDowell
    Hailey Martinelli
    Brandon Norman
    Julie Sweeney
    Brett Largent
    Lauren Tallerico

This server functions as the server used to recieve states and manipulate devices.  It runs on the raspberry pi that is being used to manipulate devices.  It takes in requests from the majordomo
server and grabs the state out of the request.  It then takes the state and sends it to the actuator changer module for device manipulation.  It also exposes endpoints for the various UI views 
that the system has for adding / editting and deleting devices from the system. along with the api endpoints those functionalities use.  This server also makes communications back the majordomo server
whenever it needs to grab the commands associated with devices during device adding and editing.
******************************************************************************************************************************************************************************************************'''
from flask import Flask, request, render_template, url_for, jsonify, make_response
from flask_socketio import SocketIO, send, emit
import requests
import ActuatorChanger as ac
import json

app = Flask(__name__)
app.config['SECRET _KEY'] = 'majordomo'
socketio = SocketIO(app)
sid = None


def getCommands(device):
    '''
    Function for grabbing the commands for a device from the Majordomo server.
    '''
    # get commands from majordomo server
    headers = {"content-type": "application/json"}
    payload = {"device": device}
    # Change to ip address of device running Majordomo
    #url = "http://192.168.86.185:5000/getCommands"
    #url = "http://localhost:5000/getCommands"
    url = "http://169.254.20.68:5000/getCommands"
    try:
        req = requests.post(url, data=json.dumps(payload), headers=headers)
    except:
        print("Failed to obtain commands.")

    return req.json()


def getChanges(device):
    '''
    Function for grabbing changes associated with a device from the actuator changer module.
    '''
    # get changes associated with this device
    return ac.getChanges(device)

# Endpoint for initializing the web socket connection between the UI and the raspberry pi server.
@socketio.on("connect", namespace="/websocket")
def websocket():
    sid = request.sid
    emit("Connected")

# Endpoint for serving the home page for the web interface.
@app.route("/")
def webInterfaceHome():
    return render_template("index.html")

# Endpoint for serving the configuration page.
@app.route("/configure")
def webInterfaceConfigure():
    return render_template("configuration.html")

# Endpoint for serving the new device configuration page.
@app.route("/newDevice")
def webInterfaceNewDevice():
    return render_template("newDeviceconfiguration.html")

# Endpoint for serving the edit configuration page.
@app.route("/editConfigs")
def webInterfaceEditConfigs():
    return render_template("editConfigs.html")

# Endpoint for serving the help page.
@app.route("/help")
def webInterfaceHelp():
    return render_template("help.html")

# Endpoint for grabbing all device configurations.
@app.route("/getConfigs")
def getConfigs():
    return jsonify(ac.getConfigs())

# Endpoint for toggling devices between on and off from the UI
@app.route("/toggleDevice", methods=["POST"])
def toggleDevice():
    data = request.json
    ac.toggleDevice(data.get("device"), data.get("state"))
    request.sid = sid
    send("update", namespace="/websocket", sid="majordomo")
    return "OK"

# Endpoint for sending states from the Majordomo server.
@app.route("/sendState", methods=["POST"])
def getAction():
    state = request.json
    print("Pi Server Received State: ", state)
    alertString = ac.changeState(state)
    request.sid = sid
    send("update", namespace="/websocket", sid="majordomo")
    # change ip to device running majordomo server
    #url = "http://192.168.86.185:5000/alertUser"
    #url = "http://localhost:5000/alertUser"
    url = "http://169.254.20.68:5000/alertUser"
    payload = alertString
    headers = {"content-type": "application/json"}
    try:
        req = requests.post(url, data=json.dumps(payload), headers=headers)
        print("Alert String sent to Majordomo Successfully.")
    except Exception as e:
        print(e)
        print("Failed to Send alert string to Majordomo.")

    return "OK"

# Endpoint for grabbing the configuration for a specific device.
@app.route("/getDevConfig", methods=["POST"])
def getDevConfig():
    device = request.json.get("device")
    commands = getCommands(device)
    offDevices = ac.getOffDevices(commands)
    deviceConfig = {"device": device,
                    "config": ac.getConfigs().get(device),
                    "states": getChanges(device),
                    "commands": commands,
                    "offDevices": offDevices
                    }

    return jsonify(deviceConfig)

# Endpoint for saving a configuration
@app.route("/saveConfig", methods=["POST"])
def saveConfig():
    headers = {"content-type": "application/json"}
    # Change to ip of device running majordomo server.
    #url = "http://localhost:5000/editCommands"
    #url = "http://192.168.86.185:5000/editCommands"
    url = "http://169.254.20.68:5000/editCommands"
    payload = request.json.get("commands")
    try:
        requests.post(url, data=json.dumps(payload), headers=headers)
    except:
        return make_response(500)

    ac.saveConfigEdits(request.json)
    return "OK"

# Endpoint for deleteing a configuration.
@app.route("/deleteConfig", methods=["POST"])
def deleteConfig():
    headers = {"content-type": "application/json"}
    # Change to ip of device running majordomo server.
    #url = "http://localhost:5000/deleteCommands"
    #url = "http://192.168.86.185:5000/deleteCommands"
    url = "http://169.254.20.68:5000/deleteCommands"
    payload = {"device": request.json.get("device")}
    try:
        requests.post(url, data=json.dumps(payload), headers=headers)
    except:
        return make_response(500)

    ac.deleteConfig(request.json.get("device"))
    return "OK"


if __name__ == "__main__":
    # Change host to ip address of raspberry Pi.
    #socketio.run(app, host="192.168.86.177", port=5001)
    #socketio.run(app, host="localhost", port=5001)
    socketio.run(app, host="169.254.29.8", port=5001)
    #app.run(host="169.254.29.8", port=5001)
'''******************************************************************************************************************************************************************************************************
Copyright (c) 2019, Missouri State University
All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
*Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
*Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.
*Neither the name of the Missouri State University nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, 
THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. 
IN NO EVENT SHALL MISSOURI STATE UNIVERSITY BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, 
PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, 
STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

Written By: Dr. Iqbal and one of his graduate students.
Used By Context-based-device-suggestion (Majordomo) - Group 3 CSC 450 Fall 2019 
Instructor: Dr. Razib Iqbal
Group Members: 
    Keven McDowell
    Hailey Martinelli
    Brandon Norman
    Julie Sweeney
    Brett Largent
    Lauren Tallerico

This file is responsible for taking in an audio stream and processing it using pocketsphinx and the google speech api. After processing, it returns a string that contains either a command that is closely
associated with the literal speech, or it returns the literal speech itself.
******************************************************************************************************************************************************************************************************'''

from SemanticAnalysis import semantic_similarity
from pocketsphinx.pocketsphinx import Decoder
from SemanticAnalysis import phrase_library_creation

import time
import os
import pyaudio
import wave
import audioop
import speech_recognition as sr
import json
import base64
import shutil
import subprocess
from subprocess import call
from collections import deque
from flask import Flask, request

measures = []

# These will need to be modified according to where the pocketsphinx folder is
# Original Directories
# MODELDIR = "C:/Users/jun5/Google Drive/MSU/1. Spring 2018/SeMICtic v2. (CSC 798)/working directory/trainingDirectoryV2"
# MODELDIR_RAW = r"C:/Users/jun5/Google Drive/MSU/1. Spring 2018/SeMICtic v2. (CSC 798)/working directory/trainingDirectoryV2"

MODELDIR = "semicticV2/working directory/trainingDirectoryV2"
MODELDIR_RAW = r"semicticV2/'working directory'/trainingDirectoryV2"


# Create a decoder configuration with certain model
config = Decoder.default_config()
config.set_string('-hmm', os.path.join(MODELDIR, 'en-us-v2'))
config.set_string('-lm', os.path.join(MODELDIR, 'corpus.txt.lm'))
config.set_string('-dict', os.path.join(MODELDIR, 'corpus.txt.dic'))

# Creates decoder object for streaming data.
decoder = Decoder(config)

##### Classifiers setup #####
CLASSIFIERS = []
with open('classifiers_30.txt') as f:
    for line in f:
        CLASSIFIERS.append(line.strip())
print("classifiers:", CLASSIFIERS)

##### List of objects setup #####
LIST_OF_OBJECTS = []
for classifier in CLASSIFIERS:
    tokens = classifier.split(" ")
    LIST_OF_OBJECTS.append(tokens[-1])
LIST_OF_OBJECTS = set(LIST_OF_OBJECTS)
print("list of objects:", LIST_OF_OBJECTS)

##### Primary Cache setup #####
PRIMARY_CACHE = phrase_library_creation(
    CLASSIFIERS)   # populating initial cache

DUMP_CACHE = []   # cache that stores the tag that did not go through


def getText(req):
    """
    Receives JSON that contains 1) raw data and 2) sample length
    to be used for the decoding.
    """

    text = ''
    print("byte stream received...")
    # encodes utf-8 format before decoded with base 64.
    raw_audio_64 = req.json["raw audio"].encode("utf-8")
    # decoding with base64; this is the actual raw data
    raw_audio_bin = base64.b64decode(raw_audio_64)

    sample_size = req.json['sample size']  # sample length from the client
    mw = middleware()
    text = mw.decode(raw_audio_bin, sample_size)
    #text = decode(raw_audio_bin, sample_size)
    print("text received:", text)
    if(text == None):
        print("no text received...")
        return ''
    print("starting semantic analysis...")
    dataForDomo = mw.run_cycle(text)

    return dataForDomo


class middleware():
    def __init__(self):

        pass

    ######################### DECODING START #################

    def setup_corpus_cache(self, corpus_file):
        """
        corpus_file: .txt file that stores the trained phrases.
        Returns the list of phrases.
        """

        phrases = [phrase.strip() for phrase in open(corpus_file, "r")]
        # print(phrases)
        return phrases

    def save_speech(self, data, sample_size, trained_phrases_size):
        """
        data: raw byte stream that will create .wav file.
        sample_size: length of sample that comes from the client.
        creates a .wav file in the same directory as the .py file based on the raw data.
        """

        filename = str(trained_phrases_size+1)
        # writes data to WAV file
        # data = b"".join(data)   # this needs to be used when data is not in byte format.
        wf = wave.open(filename + '.wav', 'wb')
        wf.setnchannels(1)
        wf.setsampwidth(sample_size)
        wf.setframerate(16000)
        wf.writeframes(data)
        wf.close()
        return filename + '.wav'

    def trim(self, words):
        """
        words: a list of words that represents the speech with all the metadata. (content in the list below)
        removes any string that is inside of the list below and concatnates it.
        returns the string of spoken speech.
        """

        words_trimmed = ""
        words = [word for word in words if word not in [
            '<s>', '<sil>', '[SPEECH]', '[NOISE]', '</s>']]
        for word in words:
            if word[-3:] == '(2)':
                words_trimmed += word[:-3]+" "
            else:
                words_trimmed += word+" "
        #words_trimmed = ' '.join(words)
        # print(words_trimmed)
        return words_trimmed[:-1]

    def decode_phrase_PX(self, wav_file):
        """
        wav_file: .wav file created from save_speech function.
        decode using Pocketsphinx module.
        returns the string after it is formatted by trim function.
        """

        decoder.start_utt()
        stream = open(wav_file, "rb")
        while True:
            buf = stream.read(1024)
            if buf:
                decoder.process_raw(buf, False, False)
            else:
                break
        decoder.end_utt()
        words = []
        [words.append(seg.word) for seg in decoder.seg()]
        # print(words)
        return self.trim(words)

    def decode_phrase_GS(self, wav_file):
        """
        wav_file: .wav file created from save_speech function.
        decode using Google Speech API module.
        returns the formmated string.
        """

        r = sr.Recognizer()
        with sr.AudioFile(wav_file) as source:
            audio = r.record(source)
        try:
            return r.recognize_google(audio)
        except sr.UnknownValueError:
            print("Google Speech Recognition could not understand audio")
            return None
        except sr.RequestError as e:
            print(
                "Could not request results from Google Speech Recognition service; {0}".format(e))
            return None

    def decode(self, raw_audio, sample_size):
        """
        raw_audio: byte stream taken from the JSON file.
        sample_size: length of the sample.
        creates .wav file and use it for the decodnig. Attempts to decode with PX first,
        if the string is NOT in trained phrase, Google Speech API will be used for the backup.
        removes the .wav file after the process is finished.
        returns the final result.
        """

        RATE = 16000
        CHUNK = 1024
        result = ""
        trained_phrases = self.setup_corpus_cache(MODELDIR+"/corpus.txt")
        rel = RATE/CHUNK

        filename = self.save_speech(
            raw_audio, sample_size, len(trained_phrases))  # saves audio

        result = self.decode_phrase_PX(
            filename).lower()  # decode by PocketSphinx
        print("PX: ", result)
        if result.lower() not in trained_phrases:
            print("Google Speech API")
            try:
                result = self.decode_phrase_GS(filename)
            except AttributeError:
                print("No audio detected")
                result = ""
            return result
        else:
            return result
        # os.remove(filename)
        # return result

    def training_PX(self, new_phrase):
        '''
        new_phrase: a phrase that was sent to hub but not trained by pocketsphinx.
        copies an audio to the model directory
        removes an audio from the current directory
        updates corpus.txt, commands.fields, commands.transcription
        then runs the .batch script to update .dic and .lm files.
        '''

        print("training in progress...")
        trained_phrases = [phrase.strip()
                           for phrase in open(MODELDIR+"/corpus.txt", "r")]
        shutil.copy(str(len(trained_phrases)+1)+".wav", MODELDIR)
        self.remove_wav()
        with open(MODELDIR+"/corpus.txt", 'a+') as f:
            f.write('\n'+new_phrase)
        with open(MODELDIR+"/commands.fields", 'a+') as f:
            f.write('\n'+str(len(trained_phrases)+1))
        with open(MODELDIR+"/commands.transcription", 'a+') as f:
            f.write('\n<s> ' + new_phrase +
                    ' </s> (' + str(len(trained_phrases)+1) + ')')
        # function to call .batch script.
        #rc = call(MODELDIR_RAW+"/training_batch.bat", cwd=MODELDIR_RAW, shell=True)
        print("training completed...")

    def remove_wav(self):
        filelist = [f for f in os.listdir('.') if f.endswith(".wav")]
        for f in filelist:
            try:
                os.remove(f)
            except:
                print("Could not remove: ", f)

    ######################### DECODING END #################

    ########################## SEMANTIC ANALYSIS START #########################

    def run_cycle(self, phrase):
        px_phrase = False
        global measures
        trained_phrases = [phrase.strip()
                           for phrase in open(MODELDIR+"/corpus.txt", "r")]
        isFound = False
        print("current phrase being tested: ", phrase)
        current_object = phrase.split(" ")[-1]
        #print("current object being tested: ", current_object)
        if (phrase in CLASSIFIERS):
            print("Existing phrase, tag sent: ", "Lab_mic1" + ",," + phrase)
            if (phrase not in trained_phrases):
                self.training_PX(phrase)
            px_phrase = phrase
        elif (phrase in PRIMARY_CACHE.keys()):
            print("Existing phrase, tag sent: ", PRIMARY_CACHE[phrase])
            if (phrase not in trained_phrases):
                self.training_PX(phrase)
            px_phrase = PRIMARY_CACHE[phrase]
        elif (phrase in DUMP_CACHE):
            print("Phrase not added to the cache, no tag sent... reason: in dump cache")
        # elif (current_object not in LIST_OF_OBJECTS):
         #   print(
          #      "Phrase not added to the cache, no tag sent... reason: object not available")
           # DUMP_CACHE.append(phrase)
        else:
            for classifier in CLASSIFIERS:
                start = time.time()
                current_classifier_object = classifier.split(" ")[-1]
                # if (current_object == current_classifier_object):
                if (semantic_similarity(classifier, phrase, False) >= .75):
                    PRIMARY_CACHE[phrase] = "Lab_mic1" + ",," + classifier
                    print("Phrase added to the cache, tag sent: ",
                          PRIMARY_CACHE[phrase])
                    print("tag sent to hub...")
                    measures.append(time.time()-start)
                    print(measures)
                    self.tag_processing()   # call function to send a tag
                    if (phrase not in trained_phrases):
                        self.training_PX(phrase)
                    px_phrase = classifier
                    isFound = True
                elif (isFound):
                    break
            if(not isFound):
                print(
                    "Phrase not added to the cache, no tag sent... reason: no similar classifier")
                DUMP_CACHE.append(phrase)
                self.remove_wav()
        if px_phrase:
            command = True
            dataForDomo = {"phrase": px_phrase, "command": command}
            return dataForDomo
        else:
            command = False
            dataForDomo = {"phrase": phrase, "command": command}
            return dataForDomo

    ########################## SEMANTIC ANALYSIS END #########################

    ########################## CONNECTION TO THE HUB START #########################

    def tag_processing(self):
        pass
    ########################## CONNECTION TO THE HUB END #########################
'''******************************************************************************************************************************************************************************************************
Copyright (c) 2019, Missouri State University
All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
*Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
*Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.
*Neither the name of the Missouri State University nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, 
THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. 
IN NO EVENT SHALL MISSOURI STATE UNIVERSITY BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, 
PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, 
STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

Used By Context-based-device-suggestion (Majordomo) - Group 3 CSC 450 Fall 2019 
Instructor: Dr. Razib Iqbal
Group Members: 
    Keven McDowell
    Hailey Martinelli
    Brandon Norman
    Julie Sweeney
    Brett Largent
    Lauren Tallerico

This module was created to write words inside the word text files into the database and remove any possible duplicated words from the files.  It simply loops through each file, removes duplicates using a hash
table, and then writes the words into the database.

******************************************************************************************************************************************************************************************************'''
#############################################################
# Author: Keven McDowell
# Project: CSC 450 Fall 2019
# Description: File for pulling in words from text files, removing duplicates,
# and populating the word database with words and device actions.
############################################################
import threading
import sqlite3

dbConnection = sqlite3.connect(r"../wordDB.db")
dbCursor = dbConnection.cursor()

directory = r"./thesaurus/"
fileNames = ["brightness_dark.txt", "brightness_bright.txt", "extremity.txt",
             "negative.txt", "positive.txt", "temperature_hot.txt", "temperature_cold.txt",
             "state_of_being.txt", "location_elsewhere.txt", "location_here.txt"]

wordTypes = {"brightness_dark.txt": "Light_Dark", "brightness_bright.txt": "Light_Bright",
             "temperature_cold.txt": "Temperature_Cold", "temperature_hot.txt": "Temperature_Hot",
             "extremity.txt": "Extremity", "positive.txt": "Positive", "negative.txt": "Negative",
             "state_of_being.txt": "State_Of_Being", "location_elsewhere.txt": "Location_Elsewhere", "location_here.txt": "Location_Here"}

deviceActions = {"Light_Dark": [("Dark", 3, "Low"), ("Very Dark", 3, "High")], "Light_Bright": [("Bright", 4, "Low"), ("Very Bright", 4, "High")],
                 "Temperature_Hot": [("Hot", 2, "Low"), ("Very Hot", 2, "High")],
                 "Temperature_Cold": [("Cold", 1, "Low"), ("Very Cold", 1, "High")]}


# Since we have the ability to append to the text files, This will remove duplicates if any.
def removeDuplicates(fName):
    print("Removing duplicates in: " + fName + "...")
    singleWords = []  # Array for holding the individual words
    with open(directory + fName, "r") as fp:  # Reading words from file.
        lines = fp.readlines()
        wordDict = {}  # Dictionary for storing unique words
        for line in lines:
            # Dictionary will only have one key for a word, removing duplicates.
            wordDict[line] = line
        for word in wordDict:
            singleWords.append(word)  # Adding keys to array for writing.
        fp.close()
    # Writing back to files without duplicates.
    with open(directory + fName, "w") as fp:
        fp.writelines(singleWords)
        fp.close()


# Function for populating the database.
def populateDB():
    for name in fileNames:  # Loops through each file and adds each word to the database.
        print("Populating " + wordTypes[name] + " words...")
        with open(directory + name, "r") as fp:
            dbCursor.execute("SELECT WORD_TYPES.ID FROM WORD_TYPES WHERE WORD_TYPE=?;", [
                             wordTypes[name]])  # Grabs ID for current word type.
            wordTypeId = dbCursor.fetchone()[0]
            fileContents = fp.readlines()
            for word in fileContents:  # Inserts each word into the database.
                dbCursor.execute(
                    "INSERT INTO WORDS (WORD, WORD_TYPE_ID) VALUES (?, ?)", (word.rstrip(), wordTypeId))
        # If there are device actions, populate them.
        if deviceActions.get(wordTypes[name]):
            print("Adding Device Actions for: ", wordTypes[name])
            dbCursor.executemany(
                "INSERT INTO STATES (STATE, WORD_TYPE_ID, EXTREMITY_LEVEL) VALUES (?, ?, ?)", deviceActions[wordTypes[name]])
    dbConnection.commit()


# Main function.
def main():
    threads = []
    # Checking for duplicates is threaded to make it faster and because it can be.
    for name in fileNames:
        threads.append(threading.Thread(target=removeDuplicates, args=(name,)))
    for thread in threads:
        thread.start()
    for thread in threads:
        thread.join()
    # Populate the database.
    populateDB()
    # Close the connection.
    dbConnection.close()
    print("Done populating database. :)")


# Calling main.
main()
'''******************************************************************************************************************************************************************************************************
Copyright (c) 2019, Missouri State University
All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
*Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
*Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.
*Neither the name of the Missouri State University nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, 
THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. 
IN NO EVENT SHALL MISSOURI STATE UNIVERSITY BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, 
PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, 
STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

Used By Context-based-device-suggestion (Majordomo) - Group 3 CSC 450 Fall 2019 
Instructor: Dr. Razib Iqbal
Group Members: 
    Keven McDowell
    Hailey Martinelli
    Brandon Norman
    Julie Sweeney
    Brett Largent
    Lauren Tallerico

This module was created to grab words from the datamuse api and put them in text files to try and automate our database population process. It simply makes api calls to the datamuse api for all of the different
word types and writes each result word to text files associated with the type of word that was queried.

******************************************************************************************************************************************************************************************************'''
# Author: Brett Largent

################## Important #######################
# Point everything back at ./thesaurus/ to overwrite / append to existing files
import json
import requests
import threading

####################################################################################################
#
#   getData(wordInput, topics, file)
#
#   Params:
#       wordInput - keyword to find synonyms for
#       topics - context to provide the api with for sorting results
#       file - file name to be written to
#
####################################################################################################


def getData(wordInput, topics, file):
    # Prepare word input as query param
    queryParam = wordInput.replace(' ', '+').lower()
    topics = ",".join(topics)                           # Comma separate topics

    req = ("https://api.datamuse.com/words" +   # Prepare Get request url
           "?topics=" + topics +       # provided context
           "&ml=" + queryParam +       # means like
           "&rel_syn=" + queryParam +
           "&max=1000")   # synonyms

    response = requests.get(req)                # Get JSON
    responseList = json.loads(response.text)    # Convert JSON to useable state

    dataList = []                               # Empty list for data extraction
    for word in responseList:                   # Extract words into list
        dataList.append(word["word"] + "\n")

    file.writelines(dataList)

    # print(("queryParam: " + queryParam +        # Print query info
    #     "\nreq: " + req +
    #     "\nnumber of results: " +
    #         str(len(responseList)) + "\n"))
    # print(dataList, "\n\n")                     # Print Data

####################################################################################################
#
#   Temperature queries
#
####################################################################################################


temperatureHotInputList = ["hot", "boiling",
                           "warm", "I am too hot"]  # Keywords
temperatureHotTopicList = ["temperature"]  # Context

queryFile = open(r"./" + "temperature_hot.txt", "a")
for query in temperatureHotInputList:
    getData(query, temperatureHotTopicList, queryFile)

queryFile.close()

temperatureColdInputList = ["cold", "freezing",
                            "chilly", "I am cold"]  # Keywords
temperatureColdTopicList = ["temperature"]  # Context

queryFile = open(r"./" + "temperature_cold.txt", "a")
for query in temperatureColdInputList:
    getData(query, temperatureColdTopicList, queryFile)

queryFile.close()

####################################################################################################
#
#   Brightness queries
#
####################################################################################################

brightnessBrightInputList = ["bright", "light"]    # Keywords
brightnessBrightTopicList = ["brightness"]        # Context

queryFile = open(r"./" + "brightness_bright.txt", "a")
for query in brightnessBrightInputList:
    getData(query, brightnessBrightTopicList, queryFile)

queryFile.close()

brightnessDarkInputList = ["dark", "dim", "the light is dim"]    # Keywords
brightnessDarkTopicList = ["brightness"]        # Context

queryFile = open(r"./" + "brightness_dark.txt", "a")
for query in brightnessDarkInputList:
    getData(query, brightnessDarkTopicList, queryFile)

queryFile.close()

####################################################################################################
#
#   Extremity Queries
#
####################################################################################################

extremityInputList = ["extremely", "super", "really"]    # Keywords
extremityTopicList = ["extremity"]        # Context

queryFile = open(r"./" + "extremity.txt", "a")
for query in extremityInputList:
    getData(query, extremityTopicList, queryFile)

queryFile.close()

####################################################################################################
#
#   Positive Queries
#
####################################################################################################

positiveInputList = ["wish", "want"]    # Keywords
positiveTopicList = ["want"]        # Context

queryFile = open(r"./" + "positive.txt", "a")
for query in positiveInputList:
    getData(query, positiveTopicList, queryFile)

queryFile.close()

####################################################################################################
#
#   Negative Words
#
####################################################################################################

# Just an array of words since the thesaurus api did not seem to like giving back negative words.

negativeWords = ["weren't", "wasn't", "didn't", "not", "isn't"]
fileInput = []

file = open(r"./" + "negative.txt", "a")
fileInput = []
for word in negativeWords:                   # Extract words into list
    fileInput.append(word + "\n")

file.writelines(fileInput)
file.close()

print("Done downloading words into text files.")
#!/usr/bin/env python3

# Imports that dont need to be installed via pip
import math
import os
import glob
import time
import tkinter as tk
import threading as thr
import numpy as np

#--------------------------------------------#

# Imports that need to be installed via pip:
import cv2 as cv  # opencv-python
import openpyxl
import openpyxl.styles  # openpyxl

#--------------------------------------------#

# GUI Imports
import GUI
import calendarPicker as cp

#--------------------------------------------#

# Specific functionality imports
from pathlib import Path as pth
from tkinter.filedialog import askopenfilename, asksaveasfilename
from tkinter import messagebox

#--------------------------------------------#


# Author(s): Kyle Sargent, Connor Jansen, Colton Eddy, Alex Wilson, Emily Box
# Version: 1
# Submitted May 9th, 2019
# Submitted to
# Dr. Razib Iqbal
# Assistant Professor of Computer Science
# Missouri State University
# in partial fulfillment of the
# CSC450 Course Project
# Spring 2019

# -------------------------------------------------------------------------------------------------
# Copyright: Copyright (c) 2019, Missouri State University
# All rights reserved.
# Redistribution and use in source and binary forms, with or without modification, are permitted provided that the
# following conditions are met:
# * Redistributions of source code must retain the above copyright notice, this list of conditions and the following
# disclaimer.
# * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the
# following disclaimer in the documentation and/or other materials provided with the distribution.
# * Neither the name of the organization nor the names of its contributors may be used to endorse or promote
# products derived from this software without specific prior written permission.
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY
# EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT
# SHALL MISSOURI STATE UNIVERSITY BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
# EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
# HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
# OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
# SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
# -------------------------------------------------------------------------------------------------------------------

thrLock = thr.Lock()


def writeToExcel(value, workbookName, sheet, date, picNum,):  # phenoNum):
    """

    This function will handle any writing to the spreadsheet document that is required.
    It uses openpyxl to load in a workbook and write the data obtained from the analysis to spreadsheets in selected workbooks.

    Input(s): value (int), workbookName (string), sheet (string), date (string), picNum (int)
    Output(s): Data written to sheet in workbook
    Local Variable(s):  wb (excel workbook that is opened), ws (worksheet from opened workbook), startCol/startRow (int), 

    """

    wb = openpyxl.load_workbook(workbookName)
    ws = wb[sheet]
    startCol, startRow = 1, 1
    dateCol, dateRow = 0, 0
    foundDate = False
    pic = "Picture: " + str(picNum)

    for cell in ws[1]:
        if cell.value == date:
            dateCol = cell.column
            dateRow = cell.row
            foundDate = True
            break

    if foundDate == True:
        ratioRow = picNum + 1
        ratioCol = dateCol
        ratioCell = ws.cell(ratioRow, ratioCol, value=pic +
                            ", Ratio: " + str(value))
        wb.save(workbookName)
        return

    elif foundDate == False:
        if ws.cell(startRow, startCol).value == None:
            dateCell = ws.cell(startRow, startCol, value=date)
            dateCell.alignment = openpyxl.styles.Alignment(
                horizontal='center', vertical='center')
            dateCol = startCol
            dateRow = startRow
            ws.merge_cells(dateCell.coordinate + ':' +
                           ws.cell(dateRow, dateCol + 3).coordinate)
            wb.save(workbookName)

        else:
            for i in range(startCol, 200, 6):
                if ws.cell(row=startRow, column=i).value != None:
                    continue
                else:
                    dateCell = ws.cell(startRow, i, value=date)
                    dateCell.alignment = openpyxl.styles.Alignment(
                        horizontal='center', vertical='center')
                    dateCol = i
                    dateRow = startRow
                    ws.merge_cells(dateCell.coordinate + ':' +
                                   ws.cell(dateRow, dateCol + 3).coordinate)
                    wb.save(workbookName)
                    break

        ratioRow = picNum + 1
        ratioCol = dateCol
        ratioCell = ws.cell(ratioRow, ratioCol, value=pic +
                            ", Ratio: " + str(value))

    wb.save(workbookName)
    return


def backgroundRemove(img):
    height, width = img.shape[:2]

    # Create a mask holder
    mask = np.zeros(img.shape[:2], np.uint8)

    # Grab Cut the object
    bgdModel = np.zeros((1, 65), np.float64)
    fgdModel = np.zeros((1, 65), np.float64)

    # create Rect The object must lie witin
    rect = (2, 0, width-5, height)
    cv.grabCut(img, mask, rect, bgdModel, fgdModel, 4, cv.GC_INIT_WITH_RECT)
    mask = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')
    img1 = img*mask[:, :, np.newaxis]

    # Get the background
    background = img - img1

    # Change all pixels in the background to what ever color you want
    # I went with Red because of high contast with the green leaf disk
    background[np.where((background > [0, 0, 0]).all(axis=2))] = [0, 0, 0]

    # Add the background and the image
    final = background + img1
    return final


def calculateMildew(path):
    """

    Area finding function, Will utilize HoughCircle method to detect circles
    within the photo or hard coded method to detect circles. After finding the circle, the image is cropped down and then hsv detection is ran on 
    it. After the hsv is completed, Edge Detection is ran on the newly hsv filtered photo. After Edge detection, contouring is performed for  

    Input(s): path (String)
    Output(s): mildewRatio (int)
    Local Variable(s): img/cimg/hsv/mask/res/edges (numpy ndarray), height/width/area/rad/channel/mildewRatio/cont/contArea (int), hsvValues (array of ints), 
                       lower_green/upper_green/contours/hierarchy (nparray

    """

    img = cv.imread(path, 1)
    h, w = img.shape[:2]

    if h < 280 and w < 423:
        print("Image Resolution too small for analyzing! Image passed is too small for analyzing, please resize or retry with a different image.")
        return -1
    if h > 280 and w > 423:
        # resize image, for easier reading and faster execution.
        img = cv.resize(img, (423, 280))

    img = cv.medianBlur(img, 5)  # add blur to reduce noise on photo.
    cimg = cv.cvtColor(img, cv.COLOR_BGR2GRAY)

    img = backgroundRemove(img)

    center = (int(w / 2), int(h / 2))
    rad = 205
    cv.circle(cimg, center, rad, (0, 0, 255), 2)

    area = math.pi * rad ** 2

    img = img[0:h, 0:w]

    hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)

    height, width, channel = hsv.shape

    # adding hsv values to list
    hsvValues = []
    for x in range(0, width):
        for y in range(0, height):
            pixel = hsv[y, x]
            # print(pixel)
            hsvValues.append(pixel)

    # darker colors (to mask out)
    lower_green = np.array([0, 0, 165])
    # lighter colors
    upper_green = np.array([255, 255, 255])

    # masking pixels to remove irrelevant data
    mask = cv.inRange(hsv, lower_green, upper_green)
    res = cv.bitwise_and(img, img, mask=mask)

    hsvMask = cv.inRange(hsv, lower_green, upper_green)
    res = cv.bitwise_and(img, img, mask=hsvMask)

    edges = cv.Canny(res, 350, 700)

    ret, edges = cv.threshold(edges, 130, 255, cv.ADAPTIVE_THRESH_MEAN_C)
    mask = np.zeros(edges.shape, np.uint8)

    contours, hierarchy = cv.findContours(
        edges, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)

    mildewRatio = 0
    for cont in contours:
        contArea = cv.contourArea(cont)
        mildewRatio += contArea

    return mildewRatio / area * 100


def threadHandler(date, trayNum, picNum, spreadsheet):
    """

    This Function accepts the three user inputs from the main function/GUI as arguments.
    It then builds a valid filepath based on the arguments. Once a valid path is created,
    this function sends that path to the findCircleArea and cannyEdgeDetection functions. 
    This function validates the file extension of the file selected to make sure that the selection is a valid image format.
    Supported file extensions: .png, .jpeg, .jpg, .tiff, .tif

    Input(s): date (String) , tray (int), picNum (int)
    Output(s): None
    Local Variable(s): path (String), dirName (String) , fName (String), circArea (int), mildewRatio (int), mildewRatio (int)

    """

    print(thr.current_thread())

    date = glob.glob("../photos/" + date + "*", recursive=True)[0]
    tray = '/tray ' + str(trayNum)
    dirName = date + tray + "/"
    try:
        photo = glob.glob(dirName + str(picNum) +
                          "-160x271_" + "*", recursive=True)[0]
    except:
        print("Path cannot be found! A path cannot be found for photo: " + str(picNum) +
              " in tray: " + str(trayNum) + " from the date: " + date[10:] + ".")
        return

    path = os.path.abspath(photo)

    if os.path.exists(path):
        startTime = time.perf_counter()
        mildewRatio = calculateMildew(path)
        endTime = time.perf_counter()
        totalTime = endTime - startTime

        if mildewRatio < -1:
            return

        if totalTime > 10:
            return print("Timeout in: " + thr.current_thread().getName() + " with runtime of: " + str(totalTime) + "s.")

        thrLock.acquire()
        writeToExcel(mildewRatio, spreadsheet, tray[1:], date[10:], picNum)
        print(thr.current_thread().getName() + " returning.")
        print("Mildew to leaf ratio is: " + str(mildewRatio) + "%")
        thrLock.release()
        return

    else:
        print("Invalid path detected, No file or directory resides in: \n" + path)
        return


def findOccurrences(s, ch):
    """

    Function to find occurances of a character in a string. only useful for when ',' is used in an entry field.

    Input(s): s (String), ch (Character)
    Output(s): a list of indicies in which ch was found in s.
    Local Variable(s): None

    """
    return [i for i, letter in enumerate(s) if letter == ch]


def getNumbers(input):
    """

    Function to extract the numbers from the entry fields after they've been validated. 
    This will grab the numbers found surrounding a '-' or multiple ',' in an entry field. 
    Then will place either the range of numbers or sequence of numbers in a list
    and return that to the Analyzer.

    Input(s): input (String)
    Output(s): nums[] (list of ints)
    Local Variables: idx (int), n1/n2 (int), nums[] (list of ints), comms [] (list of indicies where ',' is found)

    """

    nums, comms = [], []

    if '-' in input and ',' in input:
        comms = findOccurrences(input, ',')
        splitInput = input.split(',', len(comms))
        for splitStr in splitInput:
            if '-' in splitStr:
                splitSubStr = splitStr.split("-", 2)
                n1 = splitSubStr[0]
                n2 = splitSubStr[1]

                if n1 == '':
                    # return nums here because invalid format found. do error handling in the sendToAnalyzer function.
                    return nums
                elif n2 == '':
                    return nums  # same as for n1.

                n1 = int(n1)
                n2 = int(n2)
                if n1 > n2:
                    return messagebox.showwarning("Entry Warning!", "Left Hand Side of '-' is greater than Right Hand Side. Please fix the order and retry.")
                else:
                    for i in range(n1, n2+1):
                        nums.append(i)
            else:
                n = int(splitStr)
                if n in nums:
                    continue
                else:
                    nums.append(n)
        return nums

    if '-' in input:
        splitInput = input.split("-", 2)
        n1 = splitInput[0]
        n2 = splitInput[1]
        if n1 == '':
            # return nums here because invalid format found. do error handling in the sendToAnalyzer function.
            return nums
        elif n2 == '':
            return nums  # same as for n1.

        n1 = int(n1)
        n2 = int(n2)
        if n1 > n2:
            return messagebox.showwarning("Entry Warning!", "Left Hand Side of '-' is greater than Right Hand Side. Please fix the order and retry.")
        else:
            for i in range(n1, n2+1):
                nums.append(i)
            return nums

    if ',' in input and len(input) >= 3:
        comms = findOccurrences(input, ',')
        splitInput = input.split(',', len(comms))
        for splitNum in splitInput:
            n = int(splitNum)
            if n in nums:
                continue
            else:
                nums.append(n)
        return nums

    if '-' not in input and ',' not in input:
        n1 = int(input)
        nums.append(n1)
        return nums


def date():
    global datePicker
    datePicker = cp.DatePicker(format_str="%01d-%02d-%02d")


def returnDate():
    return datePicker.date


def main():
    root = tk.Tk()

    root.geometry('350x300')  # set size of window
    root.title("LDA GUI v1.0")

    root.resizable(False, False)  # make window not able to be resized

    def exitWindow(e):
        if messagebox.askyesnocancel("Exit", "Are you sure you want to close this application?"):
            root.destroy()

    root.bind("<Escape>", exitWindow)
    # create new instance of the analyzerGUI with root as master.
    gui = GUI.analyzerGUI(root)

    trays, pics, threads = [], [], []
    workbook = ""

    gui.calendarBtn.config(command=date)

    def newOrExisting(trays):
        """

        Function for determining whether a new spreadsheet or an existing spreadsheet will be used to hold data from the analyzing process.
        We get the option selected from the radio buttons on the GUI and return True if one was selected, otherwise we show a 
        messagebox warning letting the user know neither button was picked, and return false

        Input(s): trays (list of trays gained from user input)
        Output(s): True or False Boolean
        Local Variable(s): value (String), new (Boolean)

        """
        value = gui.option.get()
        if value == "True":
            print("Creating New Spreadsheet")
            wb = openpyxl.Workbook()
            rm = wb['Sheet']
            wb.remove(rm)

            for tray in trays:
                ws = wb.create_sheet("tray " + str(tray))

            # creates new workbook (currently creates a single placeholder book in the current directory
            file = asksaveasfilename(initialdir=".", title="Save As", filetypes=(
                ("xlsx", "*.xlsx"), ("All Files", "*.*")), defaultextension='.xlsx',)
            wb.save(file)
            return file

        elif value == "False":
            print("Going to Existing")
            file = askopenfilename(initialdir=".", title="Open File", filetypes=(
                ("xlsx", "*.xlsx"), ("All Files", "*.*")))  # lets user browse for what spreadsheet they want to open
            wb = openpyxl.load_workbook(file)
            wsheets = wb.sheetnames
            for tray in trays:
                if "tray " + str(tray) not in wsheets:
                    ws = wb.create_sheet("tray " + str(tray))

            wb.save(file)
            return file

    def validateTP(x, y):
        """

        Function to validate the Tray/Picture entries. We initialize countx and county for counting correct or 
        valid characters found from the inputs.
        Then we loop over each string and check if the character is valid (e.g. digit, '-' or ','). 
        If so we increment count, if not we show a warning with the invalid character 
        and clear the entry field in which the invalid character was found. 
        After character validation, we check if countx and county 
        are equal to the length of the strings passed in, meaning that each character was valid.

        Input(s): x (String), y (String)
        Output(s): boolean value based on whether or not both strings are valid.
        Local Varaible(s): countx (int), county (int)

        """

        if x == "" and y == "":
            messagebox.showwarning(
                "No Entry Warning!", "No entry found in the Tray and Picture Entry Fields. Please enter data in the following format: '1-3' or '1,2,3'.")
            return False

        elif x == "":
            messagebox.showwarning(
                "No Entry Warning!", "No entry found in the Tray Entry Field. Please enter data in the following format: '1-3' or '1,2,3'.")
            return False
        elif y == "":
            messagebox.showwarning(
                "No Entry Warning!", "No entry found in the Picture Entry Field. Please enter data in the following format: '1-3' or '1,2,3'.")
            return False

        countx, county = 0, 0
        for i in x:
            if i.isdigit() or i == '-' or i == ',':
                countx += 1
            else:
                messagebox.showwarning("Entry warning!", "Incorrect character of: '" + i +
                                       "' in Tray Entry Field. Please enter in the following format: '1-3' or '1,2,3'.")
                gui.trayEntry.delete(0, tk.END)

                return False
        for o in y:
            if o.isdigit() or o == '-' or o == ',':
                county += 1
            else:
                messagebox.showwarning("Entry warning!", "Incorrect character of: '" + o +
                                       "' in Picture Entry Field. Please enter in the following format: '1-3' or '1,2,3'.")
                gui.picEntry.delete(0, tk.END)
                return False

        if countx == len(x) and county == len(y):
            return True

    def validateDate(date):
        """
        Function to validate the date input by the user. We check if date is less than 6 because it allows for folders to be structured 
        as d-mm-yy as well.

        Input(s): date (String)
        Output(s): path found from global search with date
        Local Variable(s):

        """
        dateLen = len(date)
        count = 0

        for i in date:
            if i.isdigit() or i == '-':
                count += 1
            else:
                break

        if count == dateLen:
            try:
                return glob.glob("../photos/" + date + "*", recursive=True)[0]
            except:
                messagebox.showerror(
                    "No Associated Folder Found!", "No Folder was found for the date of: " + date + " please try again.")
        else:
            messagebox.showwarning("Incorrect Date Found", "An incorrect date of: " +
                                   date + " has been found. Please retry with the following format: mm-dd-yy.")
            return

    def disableAll(gui):
        gui.trayEntry.config(state='disabled')
        gui.picEntry.config(state='disabled')
        gui.calendarBtn.config(state='disabled')
        gui.r1.config(state='disabled')
        gui.r2.config(state='disabled')
        return

    def enableAll(gui):
        gui.trayEntry.config(state='normal')
        gui.picEntry.config(state='normal')
        gui.calendarBtn.config(state='normal')
        gui.r1.config(state='normal')
        gui.r2.config(state='normal')
        return

    def sendToAnalyzer():
        """
        Function to send data from GUI fields to diskAnalyzer. We grab the GUI fields' values and strip any 
        whitespace from the front/back so that it doesnt mess up with our validation methods. 
        Then we validate the fields and upon them returning true, 
        we disable all buttons and then run the analyzer methods with the validated data gained.

        Input(s): None
        Output(s) None
        Local Varaible(s): trayStr/picStr/dateStr (str), numTrays/numPics (int), t (thread obj), threads (list of threads), t/elapsedTime (float)

        """

        disableAll(gui)

        trayStr = gui.trayEntry.get().rstrip().lstrip().replace(" ", "")
        picStr = gui.picEntry.get().rstrip().lstrip().replace(" ", "")
        date = returnDate().rstrip().lstrip()

        print("Selected date: " + date)

        if validateTP(trayStr, picStr) and validateDate(date):
            trays = getNumbers(trayStr)
            pics = getNumbers(picStr)

            numTrays = len(trays)
            numPics = len(pics)

            if numPics == 0 and numTrays == 0:
                enableAll(gui)
                return messagebox.showerror("Invalid Format Detected!", "An Invalid format was found in both the picture and tray numbers entry fields. Please retry with the following format: '1-3' or '1,2,3'.")
            elif numTrays == 0:
                enableAll(gui)
                return messagebox.showerror("Invalid Format Detected!", "An Invalid format was found in the tray numbers entry field. Please retry with the following format: '1-3' or '1,2,3'.")

            elif numPics == 0:
                enableAll(gui)
                return messagebox.showerror("Invalid Format Detected!", "An Invalid format was found in the tray numbers entry field. Please retry with the following format: '1-3' or '1,2,3'.")

            try:
                workbook = newOrExisting(trays)
            except:
                enableAll(gui)
                return messagebox.showerror("Selection Cancelled!", "Selection of existing sheet cancelled. Please try again.")

            if workbook == ".xlsx":  # if saving the workbook filename is cancelled, file will become ".xlsx" and still create a spreadsheet and run the analyzing. This will prevent that.
                os.remove(workbook)
                enableAll(gui)
                return messagebox.showwarning("No Save/Existing Spreadsheet Name Warning!", "No name has been selected for the spreadsheet you wish to use. Please retry.")

            if numPics * numTrays > 8:
                enableAll(gui)
                return messagebox.showwarning("Input Warning!", "Current inputs from Tray/Pictures entry fields will spawn too many threads. Use the following as a guide for entering data into tray/pictures entry fields: trays * pictures <= 8.")

            messagebox.showinfo("Successful Verification!",
                                "Data has been successfully verified. The analyzing process will now begin.")

            for i in range(len(trays)):
                for j in range(len(pics)):
                    t = thr.Thread(target=threadHandler, args=[
                                   date, trays[i], pics[j], workbook])
                    threads.append(t)
                    t.start()

            for t in threads:
                t.join()

        enableAll(gui)

        print("Analyzing Complete.")
        return

    uploadBtn = tk.Button(root, text="Analyze",
                          command=sendToAnalyzer, height=1, width=10)
    uploadBtn.grid(row=5, column=0)

    root.mainloop()


main()
# !/usr/bin/env python
# -*- coding: utf-8 -*-
# Author: Rambarun Komaljeet
# License: Freeware
# Edited by: Kyle Sargent
# Submitted May 9th, 2019
# Submitted to
# Dr. Razib Iqbal
# Assistant Professor of Computer Science
# Missouri State University
# in partial fulfillment of the
# CSC450 Course Project
# Spring 2019

# ------------------------------------------------------------------------------------------------------------
# Copyright: Copyright (c) 2019, Missouri State University
# All rights reserved.
# Redistribution and use in source and binary forms, with or without modification, are permitted provided that the
# following conditions are met:
# * Redistributions of source code must retain the above copyright notice, this list of conditions and the following
# disclaimer.
# * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the
# following disclaimer in the documentation and/or other materials provided with the distribution.
# * Neither the name of the organization nor the names of its contributors may be used to endorse or promote
# products derived from this software without specific prior written permission.
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY
# EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT
# SHALL MISSOURI STATE UNIVERSITY BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
# EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
# HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
# OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
# SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
# ------------------------------------------------------------------------------------------------------------------

import calendar
import tkinter as tk
import time
from tkinter import ttk


class DatePicker(tk.Toplevel):
    """
    Description:
        A tkinter GUI date picker.
    """

    def __init__(self, widget=None, format_str=None):
        """
        :param widget: widget of parent instance.

        :param format_str: print format in which to display date.
        :type format_str: string

        Example::
            a = MyDatePicker(self, widget=self.parent widget,
                             format_str='%02d-%s-%s')
        """

        super().__init__()
        self.widget = widget
        self.str_format = format_str
        self.date = ""

        self.title("Date Picker")
        self.resizable(0, 0)
        self.geometry("+630+390")

        self.init_frames()
        self.init_needed_vars()
        self.init_month_year_labels()
        self.init_buttons()
        self.space_between_widgets()
        self.fill_days()
        self.make_calendar()

    def init_frames(self):
        self.frame1 = tk.Frame(self)
        self.frame1.pack()

        self.frame_days = tk.Frame(self)
        self.frame_days.pack()

    def init_needed_vars(self):
        self.month_names = ["", "01", "02", "03", "04",
                            "05", "06", "07", "08", "09", "10", "11", "12"]
        self.day_names = tuple(calendar.day_abbr)
        self.year = time.strftime("%Y")
        self.month = time.strftime("%m")

    def init_month_year_labels(self):
        self.year_str_var = tk.StringVar()
        self.month_str_var = tk.StringVar()

        self.year_str_var.set(self.year)
        self.year_lbl = tk.Label(self.frame1, textvariable=self.year_str_var,
                                 width=3)
        self.year_lbl.grid(row=0, column=5)

        self.month_str_var.set(self.month)
        self.month_lbl = tk.Label(self.frame1, textvariable=self.month_str_var,
                                  width=8)
        self.month_lbl.grid(row=0, column=1)

    def init_buttons(self):
        self.left_yr = ttk.Button(self.frame1, text="←", width=5,
                                  command=self.prev_year)
        self.left_yr.grid(row=0, column=4)

        self.right_yr = ttk.Button(self.frame1, text="→", width=5,
                                   command=self.next_year)
        self.right_yr.grid(row=0, column=6)

        self.left_mon = ttk.Button(self.frame1, text="←", width=5,
                                   command=self.prev_month)
        self.left_mon.grid(row=0, column=0)

        self.right_mon = ttk.Button(self.frame1, text="→", width=5,
                                    command=self.next_month)
        self.right_mon.grid(row=0, column=2)

    def space_between_widgets(self):
        self.frame1.grid_columnconfigure(3, minsize=40)

    def prev_year(self):
        self.prev_yr = int(self.year_str_var.get()) - 1
        self.year_str_var.set(self.prev_yr)

        self.make_calendar()

    def next_year(self):
        self.next_yr = int(self.year_str_var.get()) + 1
        self.year_str_var.set(self.next_yr)

        self.make_calendar()

    def prev_month(self):
        index_current_month = self.month_names.index(self.month_str_var.get())
        index_prev_month = index_current_month - 1

        #  index 0 is empty string, use index 12 instead,
        # which is index of December.
        if index_prev_month == 0:
            self.month_str_var.set(self.month_names[12])
        else:
            self.month_str_var.set(self.month_names[index_current_month - 1])

        self.make_calendar()

    def next_month(self):
        index_current_month = self.month_names.index(self.month_str_var.get())

        try:
            self.month_str_var.set(self.month_names[index_current_month + 1])
        except IndexError:
            #  index 13 does not exist, use index 1 instead, which is January.
            self.month_str_var.set(self.month_names[1])

        self.make_calendar()

    def fill_days(self):
        col = 0
        #  Creates days label
        for day in self.day_names:
            self.lbl_day = tk.Label(self.frame_days, text=day)
            self.lbl_day.grid(row=0, column=col)
            col += 1

    def make_calendar(self):
        #  Delete date buttons if already present.
        #  Each button must have its own instance attribute for this to work.
        try:
            for dates in self.m_cal:
                for date in dates:
                    if date == 0:
                        continue

                    self.delete_buttons(date)

        except AttributeError:
            pass

        year = int(self.year_str_var.get())
        month = int(self.month_str_var.get())
        self.m_cal = calendar.monthcalendar(year, month)

        #  build dates buttons.
        for dates in self.m_cal:
            row = self.m_cal.index(dates) + 1
            for date in dates:
                col = dates.index(date)

                if date == 0:
                    continue

                self.make_button(str(date), str(row), str(col))

    def make_button(self, date, row, column):
        """
        Description:
            Build a date button.

        :param date: date.
        :type date: string

        :param row: row number.
        :type row: string

        :param column: column number.
        :type column: string
        """
        exec(
            "self.btn_" + date + " = ttk.Button(self.frame_days, text=" + date
            + ", width=5)\n"
            "self.btn_" + date + ".grid(row=" + row + " , column=" + column
            + ")\n"
            "self.btn_" + date + ".bind(\"<Button-1>\", self.get_date)"
        )

    def delete_buttons(self, date):
        """
        Description:
            Delete a date button.

        :param date: date.
        :type: string
        """
        exec(
            "self.btn_" + str(date) + ".destroy()"
        )

    def get_date(self, clicked):
        """
        Description:
            Get the date from the calendar on button click.

        :param clicked: button clicked event.
        :type clicked: tkinter event
        """

        clicked_button = clicked.widget
        year = int(self.year_str_var.get()[2:])
        month = int(self.month_str_var.get())
        date = clicked_button['text']

        self.date = self.str_format % (month, date, year)
        #  Replace with parent 'widget' of your choice.

        try:
            self.widget.delete(0, tk.END)
            self.widget.insert(0, self.date)
        except AttributeError:
            pass
        return
#!/usr/bin/python3
# Author(s): Kyle Sargent, Connor Jansen, Colton Eddy, Alex Wilson, Emily Box
# Version: 1
# Submitted May 9th, 2019
# Submitted to
# Dr. Razib Iqbal
# Assistant Professor of Computer Science
# Missouri State University
# in partial fulfillment of the
# CSC450 Course Project
# Spring 2019

# -------------------------------------------------------------------------------------------------------------------
# Copyright: Copyright (c) 2019, Missouri State University
# All rights reserved.\
# Redistribution and use in source and binary forms, with or without modification, are permitted provided that the
# following conditions are met:
# * Redistributions of source code must retain the above copyright notice, this list of conditions and the following
# disclaimer.
# * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the
# following disclaimer in the documentation and/or other materials provided with the distribution.
# * Neither the name of the organization nor the names of its contributors may be used to endorse or promote
# products derived from this software without specific prior written permission.
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY
# EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT
# SHALL MISSOURI STATE UNIVERSITY BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
# EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
# HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
# OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
# SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
# ---------------------------------------------------------------------------------------------------------------------

import tkinter as tk
from tkinter import *
from tkinter import messagebox
from tkinter import ttk


class analyzerGUI:
    def __init__(self, master):
        """ 
        Initialization of all entry fields, labels, buttons, etc that are necessary for the GUI. 
        we use self.___(name) for all because then we can access their values outside of the class and thus allow for 
        manipulation/capturing/checking

        Input(s): self, master
        Output(s): None
        Local Variable(s): c (Canvas), menu (Menu), fileMenu (Menu), option (StringVar), r1/r2 (RadioButton),
                           trayLabel/picLabel/dateLabel (Label), trayEntry/picEntry/dateEntry (Entry)

        """
        # a blank canvas for our GUI
        self.c = Canvas(master, height=300, width=300)
        self.menu = Menu(master)
        master.config(menu=self.menu)
        self.helpmenu = Menu(self.menu)

        def showAbout():
            messagebox.showinfo(
                title="About", message="This software is for the examining of Leaf Disks, obtained from grape leaves, to determine whether or not specific leaf disks are resistant to the growth of Downy Mildew.")

        def showCopyright():
            messagebox.showinfo(title="Copyright", message="""Copyright (c) 2019, Missouri State University
All rights reserved.
Redistribution and use in source and binary forms, with or without modification, are permitted provided that the
following conditions are met:
* Redistributions of source code must retain the above copyright notice, this list of conditions and the following
disclaimer.
* Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the
following disclaimer in the documentation and/or other materials provided with the distribution.
* Neither the name of the organization nor the names of its contributors may be used to endorse or promote
products derived from this software without specific prior written permission.
THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY
EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT
SHALL MISSOURI STATE UNIVERSITY BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.""")

        def on_exit():
            if messagebox.askyesnocancel("Exit", "Are you sure you want to close this application?"):
                master.destroy()

        master.protocol("WM_DELETE_WINDOW", on_exit)

        self.menu.add_cascade(label='About', menu=self.helpmenu)
        self.helpmenu.add_command(label='About LDA', command=showAbout)
        self.helpmenu.add_command(label='Copyright', command=showCopyright)

        self.option = StringVar(value="1")
        self.r1 = Radiobutton(
            master, text="Create New Spreadsheet", value="True", var=self.option)
        self.r1.grid(row=0, column=0, padx=(0, 10))
        self.r2 = Radiobutton(
            master, text="Use Existing Spreadsheet", value="False", var=self.option)
        self.r2.grid(row=0, column=1)

        def clearTrayEntry(event):
            """
            Function to clear entry field. Upon the event passed in, we execute this function.
            Input(s): event
            Output(s): None

            """
            self.trayEntry.delete(0, tk.END)

        def clearPicEntry(event):
            self.picEntry.delete(0, tk.END)

        def clearDateEntry(event):
            self.dateEntry.delete(0, tk.END)

        self.trayLabel = Label(master, text="Tray Number(s):")
        self.trayLabel.grid(row=1, column=0, pady=(0, 10))
        self.trayEntry = Entry(master)
        self.trayEntry.insert(0, "Placeholder: '1-3'")
        self.trayEntry.grid(row=1, column=1, pady=(0, 10))
        self.trayEntry.bind("<Button-1>", clearTrayEntry)

        self.picLabel = Label(master, text="Picture Number(s):")
        self.picLabel.grid(row=2, column=0, pady=(0, 10))
        self.picEntry = Entry(master)
        self.picEntry.grid(row=2, column=1, pady=(0, 10))
        self.picEntry.insert(0, "Placeholder: '1-3'")
        self.picEntry.bind("<Button-1>", clearPicEntry)

        # self.phenoLabel = Label(master, text = "Phenotype(s):")
        # self.phenoLabel.grid(row = 3 , column = 0, pady = (0,10))
        # self.phenoEntry = Entry(master)
        # self.phenoEntry.insert(0, "Placeholder: '1-3'")
        # self.phenoEntry.grid(row = 3, column = 1, pady = (0,10))

        self.dateLabel = Label(master, text="Date:")
        self.dateLabel.grid(row=3, column=0, pady=(0, 60))
        self.calendarBtn = tk.Button(master, text="Pick a Date")
        self.calendarBtn.grid(row=3, column=1, pady=(0, 60))
        # self.dateEntry = Entry(master)
        # self.dateEntry.insert(0, "Placeholder: 'mm-dd-yy'")
        # self.dateEntry.grid(row = 4, column = 1, pady = (0,60))
        # self.dateEntry.bind("<Button-1>", clearDateEntry)
from flask import Flask, Response, request, redirect, render_template, session, url_for
from flask_admin import Admin, BaseView, expose
from flask_sqlalchemy import SQLAlchemy
from flask_admin.contrib.sqla import ModelView
from flask_wtf import FlaskForm
from wtforms import StringField, SelectField, IntegerField, SubmitField
from wtforms.validators import DataRequired
from wtforms.ext.sqlalchemy.fields import QuerySelectField
from apscheduler.schedulers.background import BackgroundScheduler

from lib.img_proc import ImgProcessor
from storage.database.models import *
from lib.cam import Camera

import storage.database.models
import numpy as np
import requests
import atexit
import datetime
import json
import yaml
import cv2
import os
import os.path

#   Global Variables [TODO: REMOVE IF POSSIBLE]

object_id = None
timestamp = datetime.datetime.now().time()
location = None

#   Flask server initialization
#   Flask configuration handling

application = Flask(__name__)

application.config.from_object(__name__)
application.config.update(dict(
    SQLALCHEMY_DATABASE_URI='sqlite:///' +
    os.path.join(application.root_path + '/storage/database', 'database.db'),
    SQLALCHEMY_TRACK_MODIFICATIONS=False,
    SECRET_KEY='UHu9qUw9SLgKvneuJXmsQRfV',
    JSONIFY_MIMETYPE='application/json',
    APPLICATION_ROOT='/',
    TESTING=False,
    DEBUG=True,
))

#   Database Configuration

db.init_app(application)
application.app_context().push()
db.create_all()

''' ------------------------------------------------------------------------
	Administrator Portal
	
	Configuration form view takes input for camera_id [to retrieve camera object]
	and Lot record. Additional views allow admin to manipulate database,
	including create new records, edit records, and delete records.
	------------------------------------------------------------------------ '''

#   Lot Configuration Flask Form


class ConfigurationForm(FlaskForm):
    camera_id = StringField(
        'Video Stream ID',
        validators=[DataRequired()])

    lot_information = QuerySelectField(
        'Video Stream Location',
        query_factory=lambda: Lot.query,
        allow_blank=False)

    submit = SubmitField('Submit')

#   Admin Portal Views [TODO: HTML/CSS]


class ConfigurationView(BaseView):
    @expose(url='/', methods=('GET', 'POST'))
    def index(self):
        global object_id, location
        form = ConfigurationForm()
        if form.validate_on_submit():
            object_id = form.camera_id.data
            location = form.lot_information.data
            return redirect('/admin/configuration/display')
        return self.render('configuration.html', form=form)


admin = Admin(application, name='Admin Portal', template_mode='bootstrap3')

admin.add_view(ConfigurationView(
    name='Configuration', endpoint='configuration'))
admin.add_view(ModelView(Lot, db.session, category="Database"))
admin.add_view(ModelView(Spot, db.session, category="Database"))

''' ------------------------------------------------------------------------
	Vehicle Detection Process:
	
	APScheduler object runs update_availability function every 30 seconds.
	System verifies that camera object and configuration file exists. If so,
	ImgProcessor() class detects availability and returns results as a list.
	The list and Lot ID are stored in database to be displayed on GUI.
	------------------------------------------------------------------------ '''

#   Database insert function


def database_import(avail_list, lot_id):
    # Calculate total spots, total available spots, and percentage of available spots
    spot_num = len(avail_list)
    avail_num = avail_list.count('Available')
    unavail_num = avail_list.count('Unavailable')
    percent_spots = str(int((unavail_num / spot_num)*100)) + '%'

    with application.app_context():
        # Update Lot table totals based on availability information
        update = Lot.query.get(lot_id)
        update.total_spots = spot_num
        update.available_spots = avail_num
        update.percentage = percent_spots

        # Delete previous availability data based on Lot ID
        db.session.query(Spot).filter(Spot.lot_location == lot_id).delete()
        for x in avail_list:
            # Insert availability data and Lot ID into Spot table
            imported = Spot(availability=x, lot_location=lot_id)
            db.session.add(imported)
        db.session.commit()

#   Scheduler Configuration


def update_availability():
    # Global variables [TODO: REMOVE IF POSSIBLE]
    global timestamp

    # Update scheduler timestamp
    timestamp = datetime.datetime.now().time()
    detection_process = ImgProcessor()
    availability_information = detection_process.process_frame()
    #availability_information = detection_process.process_frame()
    database_import(availability_information, 1)
    '''configuration_path = application.root_path + "/storage/config"
	if os.listdir(application.root_path + "/storage/config"):
		file_num = len([f for f in os.listdir(configuration_path)if os.path.isfile(os.path.join(configuration_path, f))])
		for x in range(file_num):
			# Retrive frame from video stream via ID
			camera_id = 'id' + str(x+1)
			r = requests.get('http://127.0.0.1:8080/get_frame', headers = {'cam_id': 'id1'})
			data = r.content
			frame = json.loads(data.decode("utf8"))
			frame = np.asarray(frame, np.uint8)
			frame = cv2.imdecode(frame, cv2.IMREAD_COLOR)
			
			# Process frame and return availability information as list
			detection_process = ImgProcessor()
			availability_information = detection_process.process_frame()
			database_import(availability_information[0], 0)
	else:
		pass'''


scheduler = BackgroundScheduler()
scheduler.add_job(func=update_availability, trigger="interval", seconds=10)
scheduler.start()
# Shutdown scheduler object when server is shutdown
atexit.register(lambda: scheduler.shutdown())

''' ------------------------------------------------------------------------
	Server Routes:
	
	Index will display contents of Lot tables, including total number of
	spots, total number of available spots, and the percentage of available
	spots. Info will display spot availability for each respective lot
	using URL parameters. Get_frame returns a frame based on camera_id.
	------------------------------------------------------------------------ '''

#   index Route


@application.route('/')
@application.route('/index')
def index():
    # Query Lot table and store records into data variable
    # Push data variable to HTML template
    data = db.session.execute("SELECT * FROM Lot").fetchall()
    return render_template('index.html', data=data, timestamp=timestamp)

#   info Route
#   Uses 'location' URL parameter to determine records to fetch


@application.route('/info/<location>')
def info(location):
    # Query Spot table and store records into data variable
    # Push data variable to HTML template
    data = db.session.execute(
        "SELECT * FROM Spot WHERE lot_location = :lot_location;", {"lot_location": location}).fetchall()
    return render_template('info.html', data=data, timestamp=timestamp)

#   get_frame Route


@application.route('/get_frame', methods=['GET'])
def get_frame():
    # Retrieve frame object via object_id variable
    # Encode frame and return it
    r = requests.get('http://127.0.0.1:8080/get_frame',
                     headers={"cam_id": object_id}).content
    frame = json.loads(r)
    frame = np.asarray(frame, np.uint8)
    frame = cv2.imdecode(frame, cv2.IMREAD_COLOR)
    r, jpg = cv2.imencode('.jpg', frame)
    return Response(b'--frame\r\n' b'Content-Type: image/jpeg\r\n\r\n' + jpg.tobytes() + b'\r\n\r\n', mimetype='multipart/x-mixed-replace; boundary=frame')

#   Lot Configuration Route


@application.route('/admin/configuration/display', methods=['GET', 'POST'])
def display():
    # Global variables [TODO: REMOVE IF POSSIBLE]
    global location

    id_increment = 0
    config_information = {'id': 0, 'lot': None, 'points': []}
    arr = []
    # Get data from Javascript function
    # If data doesn't equal None [boundary box has been drawn],
    # Create YAML file named after object_id variable
    # Dump box coordinates into YAML file
    data = request.json
    if data != None:
        config_information['points'] = [list(data[0]), list(
            data[1]), list(data[2]), list(data[3])]
        config_information['id'] = id_increment
        config_information['lot'] = location.id
        id_increment = id_increment + 1
        arr.append(config_information)
        with open('./storage/config/' + object_id + '.yml', 'a') as yamlfile:
            yaml.dump(arr, yamlfile)
    return render_template("test.html")

#   Run server on 'localhost:8090'


if __name__ == '__main__':
    application.run(host='127.0.0.1', port='8090', debug=False)
from setuptools import find_packages, setup

setup(
    name='flaskr',
    version='1.0.0',
    packages=find_packages(),
    include_package_data=True,
    zip_safe=False,
    install_requires=[
        'flask', 'flask-admin', 'flask-wtf', 'flask-sqlalchemy', 'opencv-python', 'matplotlib', 'pyyaml', 'requests', 'apscheduler'
    ],
)
from flask import Flask, render_template, request, Response
from lib.cam import Camera
import json
import numpy as np
import cv2
FEEDS = {}  # Format: {"<ID>: Camera Object"}
app = Flask(__name__)


@app.route('/')
def cam_index():
    return render_template('cam_index.html')


@app.route('/get_frame', methods=['GET'])
def get_frame():
    print(request.headers)

    # STEP-1: Locate specific camera
    cam_id = request.headers['cam_id']

    # STEP-2: Pull-norm-package frame
    frame = FEEDS[cam_id].get_frame()
    print(frame)
    if np.shape(frame) == ():
        # make a blue frame for camera object
        frame = np.zeros([480, 640], dtype=np.uint8)
        frame.fill(100)
        label = str(cam_id) + ' is OFFLINE'
        cv2.putText(frame, label, (240, 320), cv2.FONT_HERSHEY_SIMPLEX,
                    0.7, (255, 255, 255), 2, cv2.LINE_AA)
        frame = FEEDS[cam_id].package((FEEDS[cam_id].norm_frame(frame)))
    else:
        frame = FEEDS[cam_id].package((FEEDS[cam_id].norm_frame(frame)))

    # STEP-3: return frame
    return frame


def init():
    global FEEDS
    # STEP-01: Build the Feeds Dict from user input
    x = True
    num = 1
    while x:
        i = 'id'
        mode = input('Is the video feed from camera "live" or from a "file": ')
        if mode == 'live':
            addr = input('Enter the address of the live video as a integer: ')
            addr = int(addr)
        else:
            addr = input('Enter the file name of the video: ')
        cam_id = input('Enter in camera ID for video feed: ')
        print(mode)
        print(addr)
        FEEDS[i+str(num)] = Camera(mode, addr, cam_id)
        print(FEEDS)
        ans = input('Enter "q" to quit: ')
        if ans == 'q':
            x = False
        num += 1

    # STEP-02: Check video feeds
    if len(FEEDS) == 2:
        video_feeds = np.hstack(
            (FEEDS['id1'].get_frame(), FEEDS['id2'].get_frame()))
    else:
        video_feeds = FEEDS['id1'].get_frame()
    while(True):
        cv2.imshow("frame", video_feeds)
        #cv2.imshow("frame", FEEDS['id2'].get_frame())
        if cv2.waitKey(1) == ord('q'):
            break
    cv2.destroyAllWindows()

    # STEP-03: return True/False if setup failed
    input('Press Enter to continue...')


if __name__ == '__main__':
    init()
    app.run(host='127.0.0.1', port='8080', debug=False)
from flask_sqlalchemy import SQLAlchemy

db = SQLAlchemy()


class Lot(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    location = db.Column(db.String(64), index=True)
    total_spots = db.Column(db.Integer, index=True)
    available_spots = db.Column(db.Integer, index=True)
    percentage = db.Column(db.String(64), index=True)

    spots = db.relationship('Spot', backref='Location', lazy='dynamic')

    def __repr__(self):
        return '{}'.format(self.location)


class Spot(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    availability = db.Column(db.String(64), index=True)
    lot_location = db.Column(db.Integer, db.ForeignKey('lot.id'))

    def __repr__(self):
        return '<Spot {}>'.format(self.id)
import requests
import json
import cv2
import numpy as np
while True:
    r = requests.get('http://127.0.0.1:8080/get_frame',
                     headers={'cam_id': 'id1'})
    r2 = requests.get('http://127.0.0.1:8080/get_frame',
                      headers={'cam_id': 'id2'})

    data = r.content
    frame = json.loads(data.decode("utf8"))
    frame = np.asarray(frame, np.uint8)
    frame = cv2.imdecode(frame, cv2.IMREAD_COLOR)

    data2 = r2.content
    frame2 = json.loads(data2.decode("utf8"))
    frame2 = np.asarray(frame2, np.uint8)
    frame2 = cv2.imdecode(frame2, cv2.IMREAD_COLOR)

    video_feeds = np.hstack((frame, frame2))
    cv2.imshow('im', video_feeds)
    if cv2.waitKey(1) == ord('q'):
        break
cv2.destroyAllWindows()
import cv2
import yaml
import numpy as np
import requests
import json
#from camera_client import Camera

file_path = 'storage\config\id1.yml'
r = requests.get('http://127.0.0.1:8080/get_frame', headers={'cam_id': 'id1'})
data = r.content
frame = json.loads(data.decode("utf8"))
frame = np.asarray(frame, np.uint8)
img = cv2.imdecode(frame, cv2.IMREAD_COLOR)
refPt = []
data = []
i = 1
cropping = False


def yaml_loader(file_path):
    with open(file_path, "r") as file_descr:
        data = yaml.load(file_descr)
        return data


def yaml_dump(file_path, data):
    with open(file_path, "a") as file_descr:
        yaml.dump(data, file_descr)


def click_and_crop(event, x, y, flags, param):
    info = {'id': 0, 'points': []}
    global refPt, cropping, i

    if event == cv2.EVENT_LBUTTONDBLCLK:
        refPt.append((x, y))
        cropping = False

    if len(refPt) == 4:

        cv2.line(image, refPt[0], refPt[1], (0, 0, 255), 1)
        cv2.line(image, refPt[1], refPt[2], (0, 0, 255), 1)
        cv2.line(image, refPt[2], refPt[3], (0, 0, 255), 1)
        cv2.line(image, refPt[3], refPt[0], (0, 0, 255), 1)

        corner_1 = list(refPt[2])
        corner_2 = list(refPt[3])
        corner_3 = list(refPt[0])
        corner_4 = list(refPt[1])

        info['points'] = [corner_1, corner_2, corner_3, corner_4]
        info['id'] = i
        data.append(info)
        refPt = []
        i += 1


image = img.copy()
clone = image.copy()
cv2.namedWindow("Click to mark points")
cv2.imshow("Click to mark points", image)
cv2.setMouseCallback("Click to mark points", click_and_crop)

while True:
    cv2.imshow("Click to mark points", image)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# data list into yaml file
if data != []:
    yaml_dump(file_path, data)
cv2.destroyAllWindows()
import yaml
import numpy as np
import cv2
import os.path
import time
import json
import requests


class ImgProcessor(object):

    def __init__(self):
        self.car = 'storage\car.xml'

    def process_frame(self):
        car = self.car
        if os.path.exists(".\storage\config\id1.yml"):
            parking_data = self.parking_datasets(".\storage\config\id1.yml")
        else:
            import lib.datasets
            parking_data = self.parking_datasets("storage\config\id1.yml")
        parking_contours, parking_bounding_rects, parking_mask, parking_data_motion = self.get_parking_info(
            parking_data)
        kernel_erode = self.set_erode_kernel()
        kernel_dilate = self.set_dilate_kernel()
        parking_status = [False]*len(parking_data)
        parking_buffer = [None]*len(parking_data)
        available_spots = self.main(car, parking_contours, parking_bounding_rects, parking_mask, parking_data_motion,
                                    kernel_erode, kernel_dilate, parking_status, parking_buffer, parking_data)
        return available_spots

    def main(self, car, parking_contours, parking_bounding_rects, parking_mask, parking_data_motion,
             kernel_erode, kernel_dilate, parking_status, parking_buffer, parking_data):

        avail = []
        frame_pos = 0
        pos = 0.0

        car_cascade = cv2.CascadeClassifier(car)

        fgbg = cv2.createBackgroundSubtractorMOG2(
            history=300, varThreshold=16, detectShadows=True)

        while True:
            start = time.time()
            r = requests.get('http://127.0.0.1:8080/get_frame',
                             headers={'cam_id': 'id1'})
            data = r.content
            frame = json.loads(data.decode("utf8"))
            frame = np.asarray(frame, np.uint8)
            frame = cv2.imdecode(frame, cv2.IMREAD_COLOR)
            first_frame = frame
            frame_pos += 1

            # Smooth out the image, then convert to grayscale
            blurImg = cv2.GaussianBlur(frame.copy(), (5, 5), 3)
            grayImg = cv2.cvtColor(blurImg, cv2.COLOR_BGR2GRAY)
            line_img = frame.copy()
            vpl = np.copy(line_img) * 0  # Virtual Parking Lot

            # Drawing the Overlay. Text overlay at the left corner of screen
            str_on_frame = "%d" % (frame_pos)
            cv2.putText(line_img, str_on_frame, (5, 30), cv2.FONT_HERSHEY_SIMPLEX,
                        0.8, (0, 255, 255), 2, cv2.LINE_AA)

            fgmask = fgbg.apply(blurImg)
            bw = np.uint8(fgmask == 255)*255
            bw = cv2.erode(bw, kernel_erode, iterations=1)
            bw = cv2.dilate(bw, kernel_dilate, iterations=1)

            (cnts, _) = cv2.findContours(bw.copy(),
                                         cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            # loop over the contours
            for c in cnts:
                if cv2.contourArea(c) < 500:
                    continue
                (x, y, w, h) = cv2.boundingRect(c)
                cv2.rectangle(line_img, (x, y), (x + w, y + h), (255, 0, 0), 1)

        # Use the classifier to detect cars and help determine which parking spaces are available and unavailable
            avail = self.detection(parking_bounding_rects, parking_data, parking_status,
                                   parking_buffer, grayImg, start, parking_mask, line_img, car_cascade, vpl)

            # Display video
            cv2.imshow('frame', line_img)

            k = cv2.waitKey(1)
            if k == ord('q'):
                break

        cv2.waitKey(0)
        cv2.destroyAllWindows()
        return avail

    def run_classifier(self, img, id, car_cascade):
        cars = car_cascade.detectMultiScale(img, 1.1, 1)
        if cars == ():
            return False
        else:
            return True

    def parking_datasets(self, fn_yaml):
        with open(fn_yaml, 'r') as stream:
            parking_data = yaml.load(stream)
        return parking_data

    def yaml_loader(self, file_path):
        with open(file_path, "r") as file_descr:
            data = yaml.load(file_descr)
            return data

    def yaml_dump(self, file_path, data):
        with open(file_path, "a") as file_descr:
            yaml.dump(data, file_descr)

    def get_parking_info(self, parking_data):
        parking_contours = []
        parking_bounding_rects = []
        parking_mask = []
        parking_data_motion = []
        if parking_data != None:
            for park in parking_data:
                points = np.array(park['points'])
                rect = cv2.boundingRect(points)
                points_shifted = points.copy()
                # shift contour to region of interest
                points_shifted[:, 0] = points[:, 0] - rect[0]
                points_shifted[:, 1] = points[:, 1] - rect[1]
                parking_contours.append(points)
                parking_bounding_rects.append(rect)
                mask = cv2.drawContours(np.zeros((rect[3], rect[2]), dtype=np.uint8), [points_shifted], contourIdx=-1,
                                        color=255, thickness=-1, lineType=cv2.LINE_8)
                mask = mask == 255
                parking_mask.append(mask)
        return parking_contours, parking_bounding_rects, parking_mask, parking_data_motion

    def set_erode_kernel(self):
        kernel_erode = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        return kernel_erode

    def set_dilate_kernel(self):
        kernel_dilate = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 19))
        return kernel_dilate


''' ------------------------------------------------------------------------
	Parking Status Lines
	
	This function will take the results from the detection function and draw the 
	lines of available parking spaces in green and the unavailable parking spaces
	in red. Each spot will be labeled with an id in the order that they were drawn by the admin.
	------------------------------------------------------------------------ '''


def print_parkIDs(self, park, points, line_img, car_cascade,
                  parking_bounding_rects, grayImg, parking_data, parking_status, vpl):

        spots_change = 0
        total_spots = len(parking_data)
        avail = []
        for ind, park in enumerate(parking_data):
            points = np.array(park['points'])
            if parking_status[ind]:
                color = (0, 255, 0)
                spots_change += 1
                spot = 'Available'
                rect = parking_bounding_rects[ind]
                roi_gray_ov = grayImg[rect[1]:(rect[1] + rect[3]),
                                      rect[0]:(rect[0] + rect[2])]  # crop roi for faster calcluation
                cars = car_cascade.detectMultiScale(roi_gray_ov, 1.1, 1)
                if cars == ():
                    res = False
                else:
                    res = True
                if res:
                    parking_data_motion.append(parking_data[ind])

                    color = (0, 0, 255)
            else:
                color = (0, 0, 255)
                spot = 'Unavailable'
            avail.append(spot)

            cv2.drawContours(line_img, [points], contourIdx=-1,
                             color=color, thickness=2, lineType=cv2.LINE_8)
            cv2.drawContours(vpl, [points], contourIdx=-1,
                             color=color, thickness=2, lineType=cv2.LINE_8)

            moments = cv2.moments(points)
            centroid = (int(moments['m10']/moments['m00'])-3,
                        int(moments['m01']/moments['m00'])+3)
            # putting numbers on marked regions
            cv2.putText(line_img, str(park['id']), (centroid[0]+1, centroid[1]+1),
                        cv2.FONT_HERSHEY_DUPLEX, 0.5, (0, 255, 255), 1, cv2.LINE_AA)
            cv2.putText(line_img, str(park['id']), (centroid[0]-1, centroid[1]-1),
                        cv2.FONT_HERSHEY_DUPLEX, 0.5, (0, 255, 255), 1, cv2.LINE_AA)
            cv2.putText(line_img, str(park['id']), (centroid[0]+1, centroid[1]-1),
                        cv2.FONT_HERSHEY_DUPLEX, 0.5, (0, 255, 255), 1, cv2.LINE_AA)
            cv2.putText(line_img, str(park['id']), (centroid[0]-1, centroid[1]+1),
                        cv2.FONT_HERSHEY_DUPLEX, 0.5, (0, 255, 255), 1, cv2.LINE_AA)
            cv2.putText(line_img, str(
                park['id']), centroid, cv2.FONT_HERSHEY_DUPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)

            cv2.putText(vpl, str(park['id']), (centroid[0]+1, centroid[1]+1),
                        cv2.FONT_HERSHEY_DUPLEX, 0.5, (0, 255, 255), 1, cv2.LINE_AA)
            cv2.putText(vpl, str(park['id']), (centroid[0]-1, centroid[1]-1),
                        cv2.FONT_HERSHEY_DUPLEX, 0.5, (0, 255, 255), 1, cv2.LINE_AA)
            cv2.putText(vpl, str(park['id']), (centroid[0]+1, centroid[1]-1),
                        cv2.FONT_HERSHEY_DUPLEX, 0.5, (0, 255, 255), 1, cv2.LINE_AA)
            cv2.putText(vpl, str(park['id']), (centroid[0]-1, centroid[1]+1),
                        cv2.FONT_HERSHEY_DUPLEX, 0.5, (0, 255, 255), 1, cv2.LINE_AA)
            cv2.putText(vpl, str(
                park['id']), centroid, cv2.FONT_HERSHEY_DUPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)

        # Display number of available parking spaces on video for each frame change.
        spots_on_frame = "%d/%d" % (spots_change, total_spots)
        cv2.putText(line_img, spots_on_frame + ' spaces are available', (6, 61), cv2.FONT_HERSHEY_COMPLEX,
                    0.7, (255, 255, 255), 2, cv2.LINE_AA)
        cv2.putText(line_img, spots_on_frame + ' spaces are available', (4, 59), cv2.FONT_HERSHEY_COMPLEX,
                    0.7, (255, 255, 255), 2, cv2.LINE_AA)
        cv2.putText(line_img, spots_on_frame + ' spaces are available', (6, 59), cv2.FONT_HERSHEY_COMPLEX,
                    0.7, (255, 255, 255), 2, cv2.LINE_AA)
        cv2.putText(line_img, spots_on_frame + ' spaces are available', (4, 61), cv2.FONT_HERSHEY_COMPLEX,
                    0.7, (255, 255, 255), 2, cv2.LINE_AA)
        cv2.putText(line_img, spots_on_frame + ' spaces are available', (5, 60), cv2.FONT_HERSHEY_COMPLEX,
                    0.7, (0, 0, 0), 2, cv2.LINE_AA)

        return avail


''' ------------------------------------------------------------------------
	Parking Spot Detection
	
	The parking spots will be detected as a available or unavailable by a boolean
	varaiable that will either be true or false. The results of each detection will be
	sent to the Parking Status Lines Function to be outlined in either red or green.
	------------------------------------------------------------------------ '''


def detection(self, parking_bounding_rects, parking_data, parking_status,
              parking_buffer, grayImg, start, parking_mask, line_img, car_cascade, vpl):

        avail = []

        # detecting cars and vacant spaces
        for ind, park in enumerate(parking_data):
            points = np.array(park['points'])
            rect = parking_bounding_rects[ind]

            # crop roi for faster calcluation
            roi_gray = grayImg[rect[1]:(
                rect[1]+rect[3]), rect[0]:(rect[0]+rect[2])]

            laplacian = cv2.Laplacian(roi_gray, cv2.CV_64F)

            points[:, 0] = points[:, 0] - rect[0]  # shift contour to roi
            points[:, 1] = points[:, 1] - rect[1]
            delta = np.mean(np.abs(laplacian * parking_mask[ind]))

            pos = time.time()

            status = delta < 2.2
            # If detected a change in parking status, save the current time
            if status != parking_status[ind] and parking_buffer[ind] == None:
                parking_buffer[ind] = pos

            # If status is still different than the one saved and counter is open
            elif status != parking_status[ind] and parking_buffer[ind] != None:
                if pos - parking_buffer[ind] > 1:
                    parking_status[ind] = status
                    parking_buffer[ind] = None
            # If status is still same and counter is open
            elif status == parking_status[ind] and parking_buffer[ind] != None:
                parking_buffer[ind] = None

    # changing the color on the basis on status change occured in the above section and putting numbers on areas

            avail = self.print_parkIDs(park, points, line_img, car_cascade,
                                       parking_bounding_rects, grayImg, parking_data, parking_status, vpl)
        return avail
import numpy as np
import json
import requests
import cv2


class Camera(object):
    def __init__(self, mode, addr, id):
        self.id = id
        self.video = None
        if(mode == "file" and type(addr) == type("hi")):
            self.video = cv2.VideoCapture(addr)
        elif(mode == "live" and type(addr) == type(0)):
            self.video = cv2.VideoCapture(addr)
        else:
            print(
                "ERROR: Camera class given either an incorrect mode or an address of the wrong type.")

    def __del__(self):
        self.video.release()

    def get_cam_id(self):
        return self.id

    def get_frame(self):
        ret, frame = self.video.read()
        if(ret == True):
            return frame
        else:
            return None

    # Normalizing image to be 0.6 of the original width and height
    def norm_frame(self, frame):
        frame = cv2.resize(frame, None, fx=0.6, fy=0.6)
        return frame

    # Encoding frame from OpenCV format to JPEG compression format
    def package(self, frame):
        frame = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 70])[
            1].tolist()
        frame = json.dumps(frame)
        return frame

    def cam_open(self):
        opened = self.video.isOpened()
        return opened
import requests
import json
import cv2
import numpy as np
from img import ImgProcessor
#from storage.database import app
#from storage.database.models import Lot, Spot

r = requests.get('http://127.0.0.1:8080/get_frame', headers={'cam_id': 'id1'})
data = r.content
frame = json.loads(data.decode("utf8"))
frame = np.asarray(frame, np.uint8)
frame = cv2.imdecode(frame, cv2.IMREAD_COLOR)

car_dect = ImgProcessor()
car = car_dect.process_frame()
print(car)
# for x in car:
#stuff = Spot(availability = x, lot_id = 1)
# app.session.add(x)
# app.session.commit()
import numpy as np

# loop over each of the individual class IDs in the image
for classID in np.unique(classMap):
    # build a binary mask for the current class and then use the mask
    # to visualize all pixels in the image belonging to the class
    print("[INFO] class: {}".format(CLASSES[classID]))
    classMask = (mask == COLORS[classID]).astype("uint8") * 255
    classMask = classMask[:, :, 0]
    classOutput = cv2.bitwise_and(image, image, mask=classMask)
    classMask = np.hstack([image, classOutput])

    # show the output class visualization
    cv2.imshow("Class Vis", classMask)
    cv2.waitKey(0)
import numpy as np
import cv2 as cv
import os
import yaml
import random
import requests
import json

confThreshold = 0.3
maskThreshold = 0.3

image = cv.imread('cars.jpg')


# Load names of classes
classesFile = "mscoco_labels.names"
classes = None
with open(classesFile, 'rt') as f:
    classes = f.readlines()

# Load the colors
colorsFile = "colors.txt"
with open(colorsFile, 'rt') as f:
    colorsStr = f.readlines()
colors = []
for i in range(len(colorsStr)):
    rgb = colorsStr[i].split(', ')
    color = np.array([float(rgb[0]), float(rgb[1]), float(rgb[2])])
    colors.append(color)

winName = 'Detected Car'
cv.namedWindow(winName, cv.WINDOW_NORMAL)


# Load the network
net = cv.dnn.readNetFromTensorflow(
    'frozen_inference_graph.pb', 'mask_rcnn_inception_v2_coco_2018_01_28.pbtxt')
net.setPreferableBackend(cv.dnn.DNN_BACKEND_OPENCV)
net.setPreferableTarget(cv.dnn.DNN_TARGET_CPU)

# Getting the inputs
outputFile = "maskedImage.jpg"

#cap = cv.VideoCapture(0)
cap = cv.VideoCapture('parkinglot3.jpg')

# Get the video writer initialized to save the output video
if (not image.any()):
    vid_writer = cv.VideoWriter(outputFile, cv.VideoWriter_fourcc('M', 'J', 'P', 'G'), 28, (round(
        cap.get(cv.CAP_PROP_FRAME_WIDTH)), round(cap.get(cv.CAP_PROP_FRAME_HEIGHT))))

# Draw the predicted bounding box, colorize and show the mask on the image


def drawBox(frame2, classId, conf, left, top, right, bottom, classMask):
    # Draw a bounding box.
    cv.rectangle(frame2, (left, top), (right, bottom), (255, 178, 50), 3)

    # Resize the mask, threshold, color and apply it on the image
    classMask = cv.resize(classMask, (right - left + 1, bottom - top + 1))
    mask = (classMask > maskThreshold)
    roi = frame2[top:bottom+1, left:right+1][mask]

    #color = colors[classId%len(colors)]
    # Comment the above line and uncomment the two lines below to generate different instance colors
    colorIndex = random.randint(0, len(colors)-1)
    color = colors[colorIndex]

    frame2[top:bottom+1, left:right+1][mask] = (
        [0.3*color[0], 0.3*color[1], 0.3*color[2]] + 0.7 * roi).astype(np.uint8)

    # Draw the contours on the image
    mask = mask.astype(np.uint8)
    retr_tree = cv.RETR_TREE
    chain_approx_simp = cv.CHAIN_APPROX_SIMPLE
    im2, contours, hierarchy = cv.findContours(
        mask, retr_tree, chain_approx_simp)
    cv.drawContours(frame2[top:bottom+1, left:right+1],
                    contours, -1, color, 3, cv.LINE_8, hierarchy, 100)

# For each frame, extract the bounding box and mask for each detected object


def postprocess(boxes, masks):
    # Output size of masks is NxCxHxW where
    # N - number of detected boxes
    # C - number of classes (excluding background)
    # HxW - segmentation shape
    numClasses = masks.shape[1]
    numDetections = boxes.shape[2]

    frameH = frame2.shape[0]
    frameW = frame2.shape[1]
    if os.path.exists('coors.yml'):
        os.remove('coors.yml')
    for i in range(numDetections):
        box = boxes[0, 0, i]
        mask = masks[i]
        score = box[2]
        if score > confThreshold:
            classId = int(box[1])

            # Extract the bounding box
            left = int(frameW * box[3])
            top = int(frameH * box[4])
            right = int(frameW * box[5])
            bottom = int(frameH * box[6])

            left = max(0, min(left, frameW - 1))
            top = max(0, min(top, frameH - 1))
            right = max(0, min(right, frameW - 1))
            bottom = max(0, min(bottom, frameH - 1))
            # Extract the mask for the object
            classMask = mask[classId]

            # Draw bounding box, colorize and show the mask on the image
            drawBox(frame2, classId, score, left,
                    top, right, bottom, classMask)
            info = {'coors': []}
            coor = []
            data = []
            carId = i+1
            coor.append((top, left))
            coor.append((bottom, right))
            corner_1 = list(coor[0])
            corner_2 = list(coor[1])
            info['carId'] = carId
            info['coors'] = [corner_1, corner_2]
            data.append(info)

            with open('coors.yml', 'a') as file:
                yaml.dump(data, file)


while True:

    # Get frame from the video
    #hasFrame, frame = cap.read()

    r = requests.get('http://127.0.0.1:8080/get_frame',
                     headers={'cam_id': 'id1'})
    r2 = requests.get('http://127.0.0.1:8080/get_frame',
                      headers={'cam_id': 'id2'})

    data = r.content
    frame = json.loads(data.decode("utf8"))
    frame = np.asarray(frame, np.uint8)
    frame = cv.imdecode(frame, cv.IMREAD_COLOR)

    data2 = r2.content
    frame2 = json.loads(data2.decode("utf8"))
    frame2 = np.asarray(frame2, np.uint8)
    frame2 = cv.imdecode(frame2, cv.IMREAD_COLOR)

    # Stop the program if reached end of video
    if cv.waitKey(1) == ord('q'):
        #print("Done processing !!!")
        #print("Output file is stored as ", outputFile)
        # cv.waitKey(3000)
        break

    # Create a 4D blob from a frame.
    blob = cv.dnn.blobFromImage(frame2, swapRB=True, crop=False)

    # Set the input to the network
    net.setInput(blob)

    # Run the forward pass to get output from the output layers
    boxes, masks = net.forward(['detection_out_final', 'detection_masks'])

    # Extract the bounding box and mask for each of the detected objects
    postprocess(boxes, masks)

    # Put efficiency information.
    t, _ = net.getPerfProfile()
    label = 'Mask-RCNN : Inference time: %.2f ms' % (
        t * 1000.0 / cv.getTickFrequency())
    cv.putText(frame2, label, (0, 15), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0))

    # Write the frame with the detection boxes
    if (image.any()):
        cv.imwrite(outputFile, frame2.astype(np.uint8))
    else:
        vid_writer.write(frame2.astype(np.uint8))

    cv.imshow(winName, frame2)
import yaml
import numpy as np


with open("car_coor.yml", 'r') as car_yaml:
    car_coor = yaml.safe_load(car_yaml)

with open("parking_spots.yml", 'r') as parking_yaml:
    spot_Coor = yaml.safe_load(parking_yaml)


def intersect_over_union(car_coor, spot_Coor):
    # for index in range(len(car_coor)):
    #    for key in car_coor[index]:
    #        print(car_coor[index][key])
    # Assigning each car coordinate to a variable
    carCoor = car_coor[0]['coors']
    carCoor_x1 = car_coor[0]['coors'][0][0]
    carCoor_y1 = car_coor[0]['coors'][0][1]
    carCoor_x2 = car_coor[0]['coors'][1][0]
    carCoor_y2 = car_coor[0]['coors'][1][1]
    # print(carCoor_x1)

    # for i in range(len(spot_Coor)):
    #    for k in spot_Coor[i]:
    # print(spot_Coor[i][k])
    # Assigning each parking spot coordinate to variable
    spotCoor = [spot_Coor[0]['points'][2], spot_Coor[0]['points'][0]]
    spotCoor_x1 = spot_Coor[0]['points'][2][0]
    spotCoor_y1 = spot_Coor[0]['points'][2][1]
    spotCoor_x2 = spot_Coor[0]['points'][0][0]
    spotCoor_y2 = spot_Coor[0]['points'][0][1]
    # print(spotCoor_x2)

    xA = max(carCoor_x1, spotCoor_x1)
    yA = max(carCoor_y1, spotCoor_y1)
    xB = min(carCoor_x2, spotCoor_x2)
    yB = min(carCoor_y2, spotCoor_y2)

    interArea = (xB - xA + 1) * (yB - yA + 1)
    carBoxArea = (carCoor_x2 - carCoor_x1 + 1) * (carCoor_y2 - carCoor_y1 + 1)
    spotBoxArea = (spotCoor_x2 - spotCoor_x1 + 1) * \
        (spotCoor_y2 - spotCoor_y1 + 1)

    iou = interArea / float(carBoxArea + spotBoxArea - interArea)

    return iou


if __name__ == '__main__':
    print(intersect_over_union(car_coor, spot_Coor))
